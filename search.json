[
  {
    "objectID": "14_integracion_numerica.html",
    "href": "14_integracion_numerica.html",
    "title": "Integrales Numéricas",
    "section": "",
    "text": "Incluso para funciones sencillas puede no ser posible obtener una respuesta analítica (“a mano”) para sus integrales. Por eso son importantes los métodos de integración. Empezaremos por los más sencillos.\nimport numpy as np\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Integración Numérica"
    ]
  },
  {
    "objectID": "14_integracion_numerica.html#estabilidad-de-los-métodos-por-polinomios-interpolantes",
    "href": "14_integracion_numerica.html#estabilidad-de-los-métodos-por-polinomios-interpolantes",
    "title": "Integrales Numéricas",
    "section": "Estabilidad de los métodos por polinomios interpolantes",
    "text": "Estabilidad de los métodos por polinomios interpolantes\nEl error de redondeo o intrínseco de estos métodos no cambia al cambiar \\(h\\). Esto quiere decir que el método es estable, pero cuando el error del método es lo comparable con el error intrínseco no se gana nada con reducir \\(h\\) ulteriormente.\nDeduscamos este hecho para la regla de Simpson. Si \\(f(x_i) = \\tilde{f}(x_i) + e_i\\) y si además \\(e_i \\leq \\epsilon\\) tenemos\n\\[\ne(h) = \\left|\\frac{h}{3}\\left[e_o + 2\\sum_{i=1}^{n/2-1} e_{2i} + 4\\sum_{i=1}^{n/2} e_{2i-1} + e_n\\right]\\right| \\leq \\frac{h}{3}\\left|\\epsilon + 2\\left(\\frac{n}{2} - 1\\right)\\epsilon + 4\\frac{n}{2}\\epsilon + \\epsilon\\right| = \\frac{h}{3}3n\\epsilon = (b - a)\\epsilon\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Integración Numérica"
    ]
  },
  {
    "objectID": "14_integracion_numerica.html#método-de-cuadratura-adaptativa",
    "href": "14_integracion_numerica.html#método-de-cuadratura-adaptativa",
    "title": "Integrales Numéricas",
    "section": "Método de cuadratura adaptativa",
    "text": "Método de cuadratura adaptativa\nEl método de paso adaptativo consiste en aproximar la integral como un polinomio interpolante en varios intervalos. El tamaño de cada intervalo es tal que el error cometido allí sea menor que una tolerancia \\(\\epsilon/f\\), donde \\(f\\) es la fracción del rango de integración ocupada por el intervalo \\(f = (b-a)/h\\). De esta forma, la suma de la aproximación en todos los subintervalos tiene un error menor que \\(\\epsilon\\).\nTenemos entonces dos tareas:\n\nEstimar el error cometido en una aproximación dada.\nDividir el rango de integración para lograr el error requerido.\n\nPara estimar el error habría que usar la fórmula de error de las aproximaciones de la clase pasada. El problema es que éstas involucran derivadas de alto orden. Recordemos la regla de simpson\n\\[\n\\int_{a}^{b} dx\\,f(x) = \\frac{h}{3}(f(a) + 4f(a + h) + f(b)) - \\frac{h^5}{90}f^{(4)}(\\xi) \\equiv S_o  - \\frac{h^5}{90}f^{(4)}(\\xi)\n\\]\nEn general es difícil calcular la cuarta derivada, y estimarla numéricamente puede costar muchas evaluaciones de la función (además de ser inestable). Lo que podemos hacer es dividir el rango de integración a la mitad, y luego usar la regla de Simpson en cada mitad para obtener:\n\\[\n\\int_a^b dx\\,f(x) = \\frac{h}{6}(f(a) + 4f(a + h/2) + 2f(a + h) + 4f(a + 3h/2) + f(b)) - \\frac{1}{16}\\frac{h^5}{90}f^{(4)}(\\bar{\\xi}) \\equiv S_1  - \\frac{1}{16}\\frac{h^5}{90}f^{(4)}(\\xi)\n\\]\nSi asumimos que \\(f^{(4)}(\\bar{\\xi}) \\approx f^{(4)}(\\xi)\\), tenemos\n\\[\n\\frac{15}{16}\\frac{h^5}{90}f^{(4)}(\\xi) = S_o - S_1\n\\]\ny entonces el error cometido al usar la aproximación S_1 es\n\\[\nS_1 - \\int_a^b dx\\,f(x) = \\frac{1}{15}(S_o - S_1)\n\\]\nPara determinar los intervalos de integración la estrategia es:\n\nCalcular la integral y el error en un intervalo.\nSi el error es mayor que la tolerancia, dividir el intervalo a la mitad.\nRepetir los pasos 1 y 2 para cada subintervalo.\n\n\nclass MaxIterations(Exception):\n    pass\n\ndef adaptive(f, a, b, tol, N=100_000):\n    \n    # Variables iniciales\n    approx = 0\n    i = 0\n    toli = [10*tol]\n    ai = [a]\n    hi = [(b - a)/2]\n    fai = [f(a)]\n    fbi = [f(b)]\n    fci = [f(a + hi[i])]\n    S0i = [hi[i]*(fai[i] + 4*fci[i] + fbi[i])/3]\n    Li = [1]\n    \n        \n    \n    while i &gt;= 0:\n        \n        fd = f(ai[i] + hi[i]/2)\n        fe = f(ai[i] + 3*hi[i]/2)\n        S1 = hi[i]*(fai[i] + 4*fd + fci[i])/6\n        S2 = hi[i]*(fci[i] + 4*fe + fbi[i])/6\n        ai_prec = ai[i]\n        hi_prec = hi[i]\n        fai_prec = fai[i]\n        fbi_prec = fbi[i]\n        fci_prec = fci[i]\n        toli_prec = toli[i]\n        S0i_prec = S0i[i]\n        Li_prec = Li[i]\n        \n        i -= 1\n        if abs(S1 + S2 - S0i_prec) &lt; toli_prec:\n            approx += S1 + S2\n        else:\n            if Li_prec &gt;= N:\n                raise MaxIterations(\"Alcanzado máximo número de iteraciones.\")\n            \n            # Intervalo derecho\n            i += 1\n            if i &gt;= len(ai): # A veces hay que ampliar la lista\n                ai.append(ai_prec + hi_prec)\n                fai.append(fci_prec)\n                fci.append(fe)\n                fbi.append(fbi_prec)\n                hi.append(hi_prec/2)\n                toli.append(toli_prec/2)\n                S0i.append(S2)\n                Li.append(Li_prec + 1)\n            else:\n                ai[i] = ai_prec + hi_prec\n                fai[i] = fci_prec\n                fci[i] = fe\n                fbi[i] = fbi_prec\n                hi[i] = hi_prec/2\n                toli[i] = toli_prec/2\n                S0i[i] = S2\n                Li[i] = Li_prec + 1\n                \n            # Intervalo izquierdo\n            i += 1\n            if i &gt;= len(ai):\n                ai.append(ai_prec)\n                fai.append(fai_prec)\n                fci.append(fd)\n                fbi.append(fci_prec)\n                hi.append(hi[i-1])\n                toli.append(toli[i-1])\n                S0i.append(S1)\n                Li.append(Li[i-1])\n            else:\n                ai[i] = ai_prec\n                fai[i] = fai_prec\n                fci[i] = fd\n                fbi[i] = fci_prec\n                hi[i] = hi[i-1]\n                toli[i] = toli[i-1]\n                S0i[i] = S1\n                Li[i] = Li[i-1]\n                \n    return approx\n\n\nadaptive(np.cos, 0, 1, 0.00000001)\n\nnp.float64(0.8414709892666887)",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Integración Numérica"
    ]
  },
  {
    "objectID": "14_integracion_numerica.html#tarea-7.1",
    "href": "14_integracion_numerica.html#tarea-7.1",
    "title": "Integrales Numéricas",
    "section": "Tarea 7.1",
    "text": "Tarea 7.1\nEjercicio 4.4.22 del libro de Burden de análisis numérico.\nLa ecuación\n\\[\n\\int_0^x dt\\,\\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2} = 0.45\\,,\n\\]\nse puede resolver para \\(x\\) usando el método de Newton. Para lograrlo es necesario evaluar la función\n\\[\nf(p) = \\int_0^p dt\\,\\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2} - 0.45\\,.\n\\]\nUse el método compuesto del trapecio para evaluar esta función y luego use el método de Newton para encontrar \\(x\\) con una precisión de \\(10^{-5}\\).",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Integración Numérica"
    ]
  },
  {
    "objectID": "14_integracion_numerica.html#tarea-7.2",
    "href": "14_integracion_numerica.html#tarea-7.2",
    "title": "Integrales Numéricas",
    "section": "Tarea 7.2",
    "text": "Tarea 7.2\nUse el método compuesto de Simpson y el método compuesto del trapecio para encontrar la siguiente integral\n\\[\n\\int_0^4 \\frac{dx}{\\sqrt{x^2 + 16}}\n\\]\nCompare con el resultado exacto para obtener el error cometido. Grafique el error en función de \\(h\\) para ambos métodos y compare con las fórmulas de error.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Integración Numérica"
    ]
  },
  {
    "objectID": "14_integracion_numerica.html#tarea-7.3",
    "href": "14_integracion_numerica.html#tarea-7.3",
    "title": "Integrales Numéricas",
    "section": "Tarea 7.3",
    "text": "Tarea 7.3\nSuponga que la medición de un cierto proceso físico da como resultado la siguiente expresión\n\\[\np(x) = \\sin x + n(x)\n\\]\ndonde \\(n\\) es el error experimental que podemos describir como un número aleatorio, para cada valor de \\(x\\), tomado de una distribución gaussiana con media \\(0\\) y desviación estándar \\(10^{-5}\\). Queremos calcular la integral\n\\[\n\\int_0^1 dx\\,p(x)\\,.\n\\]\nUse el método compuesto de Simpson para calcular esta integral. El verdadero valor de esta integral es \\(1-\\cos(1)\\). Grafique el error cometido en función de \\(h\\). ¿Se puede lograr una precisión de \\(10^{-7}\\)? ¿Por qué?",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Integración Numérica"
    ]
  },
  {
    "objectID": "14_integracion_numerica.html#tarea-7.4",
    "href": "14_integracion_numerica.html#tarea-7.4",
    "title": "Integrales Numéricas",
    "section": "Tarea 7.4",
    "text": "Tarea 7.4\nCalcule la integral de la función Gaussiana \\(f(x) = \\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}\\) en el intervalo \\((0, 3)\\). Use el método de cuadratura adaptativa implementado en clase para varias tolerancias. Compare con el valor exacto y grafique el error cometido en función de la tolerancia. ¿Es lo que esperaba?\nPara obtener el valor exacto, busque información sobre la llamada “función de error”.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Integración Numérica"
    ]
  },
  {
    "objectID": "14_integracion_numerica.html#tarea-7.5",
    "href": "14_integracion_numerica.html#tarea-7.5",
    "title": "Integrales Numéricas",
    "section": "Tarea 7.5",
    "text": "Tarea 7.5\nCalcule la integral del seno entre \\(0\\) y \\(1\\). Para ello use el método compuesto de Simpson y la cuadratura adaptativa implementada en clase. Hágalo para varias precisiones y grafique el tiempo que tardan ambos métodos en función de la precisión. (Para la precisión del método de Simpson es necesario usar la fórmula de error para calcular el número \\(n\\) de intervalos).",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Integración Numérica"
    ]
  },
  {
    "objectID": "09_teorema_central_del_limite.html",
    "href": "09_teorema_central_del_limite.html",
    "title": "Teorema central del límite",
    "section": "",
    "text": "import numpy as np\nimport math\nimport matplotlib.pyplot as plt\nfrom scipy.special import comb",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Teorema central del límite"
    ]
  },
  {
    "objectID": "09_teorema_central_del_limite.html#section",
    "href": "09_teorema_central_del_limite.html#section",
    "title": "Teorema central del límite",
    "section": "4.6",
    "text": "4.6\nUn grupo de investigación hace muchas mediciones del número de halos galácticos para cada intervalo de masa. Usando el teorema central del límite y la distribución gaussiana concluyen que hay demasiados halos muy masivos (de los cuales hay muy pocos), tal que es necesario repensar el modelo cosmológico. Comente sobre este resultado.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Teorema central del límite"
    ]
  },
  {
    "objectID": "09_teorema_central_del_limite.html#section-1",
    "href": "09_teorema_central_del_limite.html#section-1",
    "title": "Teorema central del límite",
    "section": "4.7",
    "text": "4.7\nLa distribución de las fluctuaciones de temperatura \\(\\delta T (\\ell, m)\\) de la radiación cósmica de fondo sigue una distribución gaussiana para cada pareja \\((\\ell, m)\\). Aquí \\(\\ell\\) y \\(m\\) corresponden a una descomposición de los ángulos sobre la esfera celeste. Ambos son números enteros y satisfacen \\(\\ell \\geq 0\\) y \\(-\\ell \\leq m \\leq \\ell\\). Normalmente se grafica algo proporcional a \\(\\delta T^2\\) promediado sobre todos los valores de \\(m\\), para diferentes valores de \\(\\ell\\). Explique por qué se usa una gaussiana para modelar los errores sobre \\(\\delta T^2\\) sólo para \\(\\ell &gt; 30\\). Haga una simulación para apoyar su resultado suponiendo que la distribución de cada pareja es uniforme (en realidad es una distribución \\(\\chi^2\\) pero use la uniforme por simplicidad).",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Teorema central del límite"
    ]
  },
  {
    "objectID": "09_teorema_central_del_limite.html#section-2",
    "href": "09_teorema_central_del_limite.html#section-2",
    "title": "Teorema central del límite",
    "section": "4.8",
    "text": "4.8\nUn borracho da un paso a la izquierda con probabilidad \\(0.5\\) y un paso a la derecha con probabilidad \\(0.5\\). Cada paso mide \\(1\\) metro. ¿Cuál es la distancia típica a la cual se encontrará el borracho luego de dar \\(N\\) pasos para \\(N\\) grande?",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Teorema central del límite"
    ]
  },
  {
    "objectID": "09_teorema_central_del_limite.html#section-3",
    "href": "09_teorema_central_del_limite.html#section-3",
    "title": "Teorema central del límite",
    "section": "4.9",
    "text": "4.9\nVeinte números aleatorios se extraen de una distribución uniforme entre \\(0\\) y \\(1\\).\n\nUse monte carlo para estimar la probabilidad de que la suma de los veinte números esté entre \\(9\\) y \\(10\\). Ídem entre \\(15\\) y \\(16\\).\nUse el teorema central del límite para estimar la misma probabilidad.\n\nRecuerde estimar el error de la simulación así como cuantificar con errores relativos la diferencia entre la simulación y la gaussiana.\nComente sobre su resultado.\nPista:\n\\[\n\\int_0^a dx\\,e^{-x^2} = \\frac{\\sqrt{\\pi}}{2}\\text{erf}(a)\\,,\n\\]\ndonde \\(\\text{erf}\\) es la una función especial llamada la función de error. Esta función se puede llamar usando el módulo scipy.special.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Teorema central del límite"
    ]
  },
  {
    "objectID": "09_teorema_central_del_limite.html#section-4",
    "href": "09_teorema_central_del_limite.html#section-4",
    "title": "Teorema central del límite",
    "section": "4.10",
    "text": "4.10\nDiscuta el teorema central del límite en el caso en el cual las variables no son idénticamente distribuidas. Por ejemplo, si tenemos muchas variables \\(x_i\\), ¿cómo podría fallar el teorema si los cumulantes dependen de \\(i\\)?",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Teorema central del límite"
    ]
  },
  {
    "objectID": "15_integrales_multiples_impropias_y_gauss.html",
    "href": "15_integrales_multiples_impropias_y_gauss.html",
    "title": "Cuadratura de Gauss, integrales múltiples e impropias",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.special import factorial",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Quadratura de Gauss, integrales múltiples e impropias"
    ]
  },
  {
    "objectID": "15_integrales_multiples_impropias_y_gauss.html#scipy",
    "href": "15_integrales_multiples_impropias_y_gauss.html#scipy",
    "title": "Cuadratura de Gauss, integrales múltiples e impropias",
    "section": "Scipy",
    "text": "Scipy\n\nfrom scipy import integrate\nx2 = lambda x: x**2\nintegrate.quad(x2, 0, 4)\n\n(21.333333333333336, 2.368475785867001e-13)\n\n\n\nprint(4**3 / 3.)\n\n21.333333333333332\n\n\nTambién tiene argumentos epsrel y epsabs que determinan el error relativo y absoluto requerido. Si se quiere que únicamente alcance el error relativo sin dar importancia al error absoluto, es necesario poner epsabs=0.\n\nfrom scipy import integrate\nf = lambda x: np.cos(10*x)/np.sqrt(x**2 + 16)\nintegrate.quad(f, 0, 2, epsrel=1e-12, epsabs=0)\n\n(0.020326609246501794, 3.4486265738461702e-15)\n\n\nEl algoritmo que usa por defecto es una especie de cuadratura adaptativa, donde en cada intervalo aplica una método similar a la cuadratura gaussiana de orden 21.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Quadratura de Gauss, integrales múltiples e impropias"
    ]
  },
  {
    "objectID": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.6",
    "href": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.6",
    "title": "Cuadratura de Gauss, integrales múltiples e impropias",
    "section": "Tarea 7.6",
    "text": "Tarea 7.6\nCalcule la siguiente integral\n\\[\n\\int_{0.1}^1 dx\\,\\frac{\\ln(x)}{\\sqrt{\\cos^2(x) + \\tanh(x)}}\n\\]\nHágalo usando la cuadratura adaptativa de la clase pasada y el integrador de scipy. Grafique los tiempos que tardan ambos en función de la precisión pedida.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Quadratura de Gauss, integrales múltiples e impropias"
    ]
  },
  {
    "objectID": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.7",
    "href": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.7",
    "title": "Cuadratura de Gauss, integrales múltiples e impropias",
    "section": "Tarea 7.7",
    "text": "Tarea 7.7\nEscriba un código que implemente una cuadratura gaussiana compuesta. Es decir, divide el rango de integración en \\(n\\) subintervalos y aplica una cuadratura gaussiana en cada uno.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Quadratura de Gauss, integrales múltiples e impropias"
    ]
  },
  {
    "objectID": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.8",
    "href": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.8",
    "title": "Cuadratura de Gauss, integrales múltiples e impropias",
    "section": "Tarea 7.8",
    "text": "Tarea 7.8\nUse un método numérico para calcular la siguiente integral\n\\[\n\\int_0^\\infty dx\\,\\frac{\\log(x)}{\\sqrt{x + 5x^3}}\n\\]\nPista: Al aislar la divergencia, escriba \\(\\log(x)f(x)/x^p\\), luego expanda en Taylor \\(f(x)\\) y las integrales resultantes con integrandos del tipo \\(x^n \\log(x)\\) tienen solución analítica.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Quadratura de Gauss, integrales múltiples e impropias"
    ]
  },
  {
    "objectID": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.9",
    "href": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.9",
    "title": "Cuadratura de Gauss, integrales múltiples e impropias",
    "section": "Tarea 7.9",
    "text": "Tarea 7.9\nCalcule la siguiente integral usando el método de Gauss visto en clase:\n\\[\n\\int_1^\\infty dx\\,\\int_1^\\infty dy\\, \\frac{\\tan^{-1}(xy)}{y^2 (x^{3/2}+1)}\n\\]\nPista: La \\(\\tan^{-1}(x)\\) tiende a una constante cuando \\(x \\rightarrow \\infty\\) tal que al aislar la divergencia, se puede reemplazar por la constante.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Quadratura de Gauss, integrales múltiples e impropias"
    ]
  },
  {
    "objectID": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.10",
    "href": "15_integrales_multiples_impropias_y_gauss.html#tarea-7.10",
    "title": "Cuadratura de Gauss, integrales múltiples e impropias",
    "section": "Tarea 7.10",
    "text": "Tarea 7.10\nEscriba un código que calcule integrales triples usando una cuadratura gaussiana, y úselo para calcular en coordenadas cartesianas la carga total al interior de una esfera de radio \\(R = 1\\) con densidad \\(\\rho(x, y, z) = \\sqrt{x^2 + y^2 + z^2}\\). Compare su resultado con el valor exacto.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Quadratura de Gauss, integrales múltiples e impropias"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos Numéricos y Probabilidades 2025",
    "section": "",
    "text": "Motivación\nLas (los) físicas (os) siempre han llevado la punta de lanza del desarrollo tecnológico. Desde la revolución industrial hasta el desarrollo de la computación cuántica, los (las) físicos (as) han tenido un manejo profundo de la tecnología que les permite hacer nuevos descubrimientos o inventos. Esto es aún más cierto en el siglo XXI, en el cual la mayoría de las (los) licenciadas (os) en física de los países de alto desarrollo tecnológico trabajan en el sector privado creando y mejorando las herramientas informáticas, financieras y estadísticas que usamos todos los días. Esto se debe a que a lo largo de sus carreras adquieren un conocimiento íntimo de la tecnología de punta al intentar aplicarla a problemas científicos abiertos.\nSon muy pocos los problemas que admiten una solución sencilla de lápiz y papel. Para la mayoría de nuevos desarrollos es necesario usar el computador. Esto es verdad tanto para analizar los datos obtenidos en los experimentos, como para resolver las ecuaciones diferenciales que aparecen en la física teórica. Incluso quienes hacen un trabajo puramente analítico se apoyan en herramientas computacionales para los cálculos que son cada vez más complejos.\nEn este curso aprenderemos a usar las herramientas numéricas disponibles para atacar problemas físicos y al hacerlo aprenderemos a usar plataformas, paquetes y lenguajes de programación modernos.\n\n\nLecturas Sugeridas\n\nR. L. Burden, D. J. Faires, A. M. Burden, “Numerical Analysis”, 10ma edición, Cengage Learning, 2016 (NA)\nT. A. Driscoll, R. J. Braun, “Funamentals of Numerical Computation”, 2da edición, SIAM, 2022 (FNC)\nB. R. Martin, “Statistics for Physical Sciences”. Elsevier, 2012 (S)\nA. B. Downey, “Think Python,” 2da edición, O’Reilly, 2015. (TP)\n\n\n\nPrograma\nSe indican las fechas y temas de cada clase, junto con las secciones de los libros a las que corresponden.\n1- Introducción\n\n¿Cómo funciona una CPU?, 7 de agosto.\nRepaso de Python, 12 de agosto.\nNumpy y arrays, 14 de agosto.\nRepresentación binaria de números decimales, número de condicionamiento 19 de agosto\nAlgoritmos y estabilidad 21 de agosto\n\n2- Probabilidades\n\nPropiedades básicas de la probabilidad, 26 de agosto\nDistribuciones de probabilidad, 28 de agosto\nVarias variables aleatorias, 2 de septiembre\nSuma de muchas variables aleatorias y teorema central del límite, 4 de septiembre\nInformación y entropía, 9 de septiembre\n\nPrueba: 23 de septiembre\n3- Cálculo numérico\n\nSolución de sistemas de ecuaciones lineales: Inversión de matrices, 11 de septiembre\nBúsqueda de raíces: Métodos de bisección y Newton, 25 de septiembre\nInterpolación, 30 de septiembre\nDerivadas numéricas y autodiferenciación, 2 de octubre\nIntegración numérica simple y adaptativa, 7 de octubre\nIntegración numérica por método de Gauss, 9 de octubre\n\nPrueba: 16 de octubre\n4- Solución numérica de ecuaciones diferenciales ordinarias\n\nMétodos de Euler y Taylor, 14 de octubre\nMétodo de Runge Kutta, 21 de octubre\nMétodo de Runge Kutta adaptativo, 23 de octubre\nMétodos de múltiples pasos y método de Adams, 4 de noviembre\nSistemas de ecuaciones diferenciales y ecuaciones de alto orden, 6 de noviembre\n\nPrueba: 13 de noviembre\n5- Optimización y otros algoritmos importantes\n\nAjuste de curvas y bondad de ajuste, 11 de noviembre\nOptimización por descenso de gradiente, 18 de noviembre\nIntroducción a las redes neuronales, 20 de noviembre\nMétodos de Monte Carlo y/o transformada rápida de Fourier, 25 de noviembre\n\nRecuperativa: 27 de noviembre\nExamen: Definido por Instituto\n\n\nEvaluación\nLa evaluación se hará por tareas y pruebas.\nAl final de cada clase habrán 5 tareas para un total de 10 tareas cada dos clases. De estas 10 tareas se le asignará de forma aleatoria una tarea a cada estudiante. De esta manera el estudiante deberá entregar aproximadamente 11 tareas a lo largo del curso. El 25% de la nota final es el promedio de las notas de las tareas.\nLas tareas se entregan dos clases después de haber sido asignadas.\nSe evaluará lo siguiente:\nEl código funciona (4 puntos): Si el código pedido hace lo que deberíacumplir sin errores en ningún caso, la estudiante obtendrá los 4 puntos. Si existen casos especiales en los cuales el código no funciona, pero funciona en la mayoría de los casos, la estudiante obtendrá 3 puntos. Si el código no funciona pero el error es menor (algún detalle de sintaxis, alguna variable mal nombrada, alguna excepción de Python difícil de prever), el estudiante obtendrá 2 puntos. Si el código no funciona el estudiante obtendrá 1 punto. Si no entrega la tarea el estudiante obtendrá 0 puntos.\nEl código es legible (+2 puntos): Si el código está comentado en cada paso el estudiante obtendrá +1 punto. Si el código es fácil de entender, está bien organizado, las variables tienen nombres que corresponden a lo que representan la estudiante obtendrá +1 punto.\nLa nota de la tarea = # de puntos + 1.\nLa otra mitad de la nota será el promedio de tres pruebas realizadas a lo largo del semestre. Las pruebas consisten en ejercicios sencillos basados en lo visto en clase y en las tareas.\nLas siguientes son las fechas de las pruebas:\nPrueba: 10 de septiembre Prueba: 5 de noviembre Prueba: 25 de noviembre Recuperativa: 26 de noviembre Examen: 10 de diciembre\n\n\nNormas\nLos estudiantes no están obligados a ir a las ayudantías, pero obviamente quien asista estará mejor preparado para las pruebas y los exámenes porque sabrá cuáles son los problemas que entran. Las tareas se entregarán en formato electrónico por medio de la plataforma GitHub. Se usa esta en vez del Aula Virtual dado su uso extenso en el mundo profesional.\nHágale preguntas al profesor a la dirección jorge.norena@pucv.cl, o en el horario de atención. Hacer preguntas ayuda a aprender y hace más ameno el trabajo del profesor. La clase empieza puntual si hay al menos un estudiante presente, por respeto a los que llegan a tiempo.\n\n\nRecomendaciones\nPOR FAVOR HAGAN PREGUNTAS DURANTE LA CLASE, LAS AYUDANTÍAS, POR CORREO ELECTRÓNICO, EN LOS HORARIOS DE ATENCIÓN Y POR CUALQUIER OTRO MEDIO QUE PUEDA.\nSi quiere conversar hágalo por chat en su teléfono para que el ruido no distraiga a los demás. Use el teléfono para tomarle fotos a la pizarra cuando quiera recordar algo.\n\n\nHorarios de atención y contacto\nPuede en cualquier momento hacer preguntas por correo electrónico.\nCorreo electrónico profesor: jorge.norena@pucv.cl Correo electrónico de la ayudante:\nTambién puede pasar por la oficina del profesor en cualquier momento.\nEl horario de atención reservado es una hora después de cada clase."
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html",
    "href": "04_numeros_y_condicionamiento.html",
    "title": "Representación de números y número de condicionamiento",
    "section": "",
    "text": "El computador representa los números usando un sistema binario. Es decir, una lista de 1s y 0s. Las CPUs modernas usan 64 bits, cada uno de los cuales puede ser 0 o 1. Como esto es un número finito de información, la precisión del computador para guardar un número no es infinita y esto puede inducir errores.\nPara entender el problema, hagamos un ejemplo con 16 bits.\n\nimport numpy as np\n\n\npi = np.float16(np.pi)\ndos = np.float16(2)\ncien = np.float16(100)\ncien*np.sin(dos*pi)\n\nnp.float16(-0.1935)\n\n\n\n\nPara guardar un número real en la memoria de un pc se usa la siguiente representación\n\\[\n(-1)^s 2^{n} (1 + f)\\,,\n\\]\ndonde \\(s\\) es el signo, \\(n\\) es el exponente, y la mantisa \\(f\\) es \\(f = \\sum_{i=1}^d b_i 2^{-i}\\).\nEl exponente normalmente se define como \\(n = c - 2^{k-1} + 1\\), donde \\(k\\) es el número de bits en la representación.\n\n\n\nPara ilustrar el tipo de dificultades que esto introduce es engorroso trabajar con números tan grandes. Por eso trabajamos con números de 16 bits (como si estuviéramos en los años 90). Un número de este estilo es\n1 11010 1111000100\nEl primer dígito es \\(s\\), los siguientes cinco forman \\(c\\) y los siguientes diez forman \\(f\\) de manera análoga a la de antes. En nuestro ejemplo tenemos\n\\[\nf = \\left(\\frac{1}{2}\\right)^1 + \\left(\\frac{1}{2}\\right)^2 + \\left(\\frac{1}{2}\\right)^3 + \\left(\\frac{1}{2}\\right)^4 + \\left(\\frac{1}{2}\\right)^8 = 0.94140625\n\\]\n\\[\nc = 2^4 + 2^3 + 2^1 = 26\n\\]\nEl número total está dado por \\[(-1)^s 2^{c - 15} (1 + f)\\]\nEl número de nuestro ejemplo es\n\\[\n(-1)\\times 2^{26 - 15} 1.94140625 = -3976\n\\]\n\nNúmero más grande de 16 bits\n\n0 11110 1111111111\n\nf = sum((1/2.)**(np.arange(1,11)))\nf\n\nnp.float64(0.9990234375)\n\n\n\nc = sum(2**(np.arange(1,5)))\nc\n\nnp.int64(30)\n\n\n\n2**(c - 15)*(1 + f)\n\nnp.float64(65504.0)\n\n\n\nNúmero más pequeño de 16 bits\n\n1 11110 1111111111\n\n-2**(c-15)*(1 + f)\n\nnp.float64(-65504.0)\n\n\n\nNúmero más cercano a cero de 16 bits\n\n0 00000 0000000001\n\n2**(1-15)*((1/2)**10)\n\n5.960464477539063e-08\n\n\n\nCifras decimales de precisión de 16 bits\n\n0 00000 0000000001\n\n(1/2)**(10)\n\n0.0009765625\n\n\nAlgo análogo ocurre para números representados con 64 bits sólo que ahora tenemos más bits disponibles para el exponente y la mantisa, lo que nos da más precisión. En ese caso tenemos 15 cifras de precisión. Hoy en día se usan también números de 32 bits para algunos cálculos, estos tienen aproximadamente 7 cifras de precisión.\nSi el lector está interesado, puede consultar cómo el uso de números aún más pequeños ha resurgido en el contexto de modelos de inteligencia artificial. Esto acelera los modelos. En esos casos se usa una mantisa más pequeña porque lo importante es el orden de magnitud del número.\n\n\n\nPara explorar este problema, ignoremos por ahora el sistema binario y veamos lo que ocurre en el sistema decimal.\n\nnp.pi\n\n3.141592653589793\n\n\nEn este caso, si queremos representar el número \\(\\pi\\) con una cierta cantidad \\(n\\) de cifras significativas podemos hacer dos cosas:\n\nTruncar: Ignoramos las cifras adicionales, más allá de la \\(n\\)-ésima cifra.\n\n\npi_truncado = 3.1415\n\n\nRedondear: Si la cifra \\(n + 1\\) es menor a 5 truncamos, pero si la cifra \\(n + 1\\) es mayor o igual que 5\n\n\npi_redondeado = 3.1416\n\nAl truncar o redondear cometemos un error. Podemos cuantificar el error de varias maneras:\n\nError real: estimación - valor verdadero\n\n\npi_truncado - np.pi\n\n-9.265358979293481e-05\n\n\n\npi_redondeado - np.pi\n\n7.346410206832132e-06\n\n\n\nError absoluto: |estimación - valor verdadero|\n\n\nnp.abs(pi_truncado - np.pi)\n\nnp.float64(9.265358979293481e-05)\n\n\n\nnp.abs(pi_redondeado - np.pi)\n\nnp.float64(7.346410206832132e-06)\n\n\n\nError relativo: |estimación - valor verdadero|/|valor verdadero|\n\n\nnp.abs(pi_truncado - np.pi)/np.abs(np.pi)\n\nnp.float64(2.9492553621508708e-05)\n\n\n\nnp.abs(pi_redondeado - np.pi)/np.abs(np.pi)\n\nnp.float64(2.3384349967961744e-06)\n\n\n\n\n\nEl número más cercano a \\(1\\) por la derecha en \\(16\\) bits es\n0 00000 0000000001\nRestándole \\(1\\), este se llama el \\(\\epsilon\\) de máquina. En el caso de 16 bits es burdamente \\(10^{-3}\\). En el caso de 64 bits es \\(\\sim 10^{-16}\\) y en el caso de 32 bits es \\(\\sim 10^{-8}\\). Esta es la máxima precisión que podemos alcanzar al operar con números representados de esta forma.\n\nnp.finfo(np.float32).eps\n\nnp.float32(1.1920929e-07)\n\n\n\nnp.finfo(np.float64).eps\n\nnp.float64(2.220446049250313e-16)\n\n\nCuidado, el verdadero error cometido es el \\(\\epsilon_{maq}\\) multiplicado por el exponente, tal que el error al usar números en \\([1/2, 1)\\) es en realidad \\(\\epsilon_{maq}/2\\) por ejemplo.\n\neps = np.finfo(float).eps\nx = eps/2\n(1.0 + x) - 1.0\n\nnp.float64(0.0)\n\n\n\n1.0 + (x - 1.0)\n\nnp.float64(1.1102230246251565e-16)\n\n\nSegún el estándar IEEE 754, los resultados de las sumas, restas, multiplicaciones y divisiones de números de punto flotante en el computador deben dar un resultado igual a hacer el cálculo con números reales y luego redondear a la precisión de la representación.\n\n\n\n\n\n\nAdvertencia\n\n\n\nComo vimos con el ejemplo de arriba, todo esto quiere decir que dos resultados matemáticamente equivalentes no dan necesariamente el mismo resultado si se usa aritmética de punto flotante.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html#representación-binaria-de-números-decimales",
    "href": "04_numeros_y_condicionamiento.html#representación-binaria-de-números-decimales",
    "title": "Representación de números y número de condicionamiento",
    "section": "",
    "text": "Para guardar un número real en la memoria de un pc se usa la siguiente representación\n\\[\n(-1)^s 2^{n} (1 + f)\\,,\n\\]\ndonde \\(s\\) es el signo, \\(n\\) es el exponente, y la mantisa \\(f\\) es \\(f = \\sum_{i=1}^d b_i 2^{-i}\\).\nEl exponente normalmente se define como \\(n = c - 2^{k-1} + 1\\), donde \\(k\\) es el número de bits en la representación.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html#números-de-16-bits",
    "href": "04_numeros_y_condicionamiento.html#números-de-16-bits",
    "title": "Representación de números y número de condicionamiento",
    "section": "",
    "text": "Para ilustrar el tipo de dificultades que esto introduce es engorroso trabajar con números tan grandes. Por eso trabajamos con números de 16 bits (como si estuviéramos en los años 90). Un número de este estilo es\n1 11010 1111000100\nEl primer dígito es \\(s\\), los siguientes cinco forman \\(c\\) y los siguientes diez forman \\(f\\) de manera análoga a la de antes. En nuestro ejemplo tenemos\n\\[\nf = \\left(\\frac{1}{2}\\right)^1 + \\left(\\frac{1}{2}\\right)^2 + \\left(\\frac{1}{2}\\right)^3 + \\left(\\frac{1}{2}\\right)^4 + \\left(\\frac{1}{2}\\right)^8 = 0.94140625\n\\]\n\\[\nc = 2^4 + 2^3 + 2^1 = 26\n\\]\nEl número total está dado por \\[(-1)^s 2^{c - 15} (1 + f)\\]\nEl número de nuestro ejemplo es\n\\[\n(-1)\\times 2^{26 - 15} 1.94140625 = -3976\n\\]\n\nNúmero más grande de 16 bits\n\n0 11110 1111111111\n\nf = sum((1/2.)**(np.arange(1,11)))\nf\n\nnp.float64(0.9990234375)\n\n\n\nc = sum(2**(np.arange(1,5)))\nc\n\nnp.int64(30)\n\n\n\n2**(c - 15)*(1 + f)\n\nnp.float64(65504.0)\n\n\n\nNúmero más pequeño de 16 bits\n\n1 11110 1111111111\n\n-2**(c-15)*(1 + f)\n\nnp.float64(-65504.0)\n\n\n\nNúmero más cercano a cero de 16 bits\n\n0 00000 0000000001\n\n2**(1-15)*((1/2)**10)\n\n5.960464477539063e-08\n\n\n\nCifras decimales de precisión de 16 bits\n\n0 00000 0000000001\n\n(1/2)**(10)\n\n0.0009765625\n\n\nAlgo análogo ocurre para números representados con 64 bits sólo que ahora tenemos más bits disponibles para el exponente y la mantisa, lo que nos da más precisión. En ese caso tenemos 15 cifras de precisión. Hoy en día se usan también números de 32 bits para algunos cálculos, estos tienen aproximadamente 7 cifras de precisión.\nSi el lector está interesado, puede consultar cómo el uso de números aún más pequeños ha resurgido en el contexto de modelos de inteligencia artificial. Esto acelera los modelos. En esos casos se usa una mantisa más pequeña porque lo importante es el orden de magnitud del número.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html#redondeo-truncación-error-absoluto-y-relativo",
    "href": "04_numeros_y_condicionamiento.html#redondeo-truncación-error-absoluto-y-relativo",
    "title": "Representación de números y número de condicionamiento",
    "section": "",
    "text": "Para explorar este problema, ignoremos por ahora el sistema binario y veamos lo que ocurre en el sistema decimal.\n\nnp.pi\n\n3.141592653589793\n\n\nEn este caso, si queremos representar el número \\(\\pi\\) con una cierta cantidad \\(n\\) de cifras significativas podemos hacer dos cosas:\n\nTruncar: Ignoramos las cifras adicionales, más allá de la \\(n\\)-ésima cifra.\n\n\npi_truncado = 3.1415\n\n\nRedondear: Si la cifra \\(n + 1\\) es menor a 5 truncamos, pero si la cifra \\(n + 1\\) es mayor o igual que 5\n\n\npi_redondeado = 3.1416\n\nAl truncar o redondear cometemos un error. Podemos cuantificar el error de varias maneras:\n\nError real: estimación - valor verdadero\n\n\npi_truncado - np.pi\n\n-9.265358979293481e-05\n\n\n\npi_redondeado - np.pi\n\n7.346410206832132e-06\n\n\n\nError absoluto: |estimación - valor verdadero|\n\n\nnp.abs(pi_truncado - np.pi)\n\nnp.float64(9.265358979293481e-05)\n\n\n\nnp.abs(pi_redondeado - np.pi)\n\nnp.float64(7.346410206832132e-06)\n\n\n\nError relativo: |estimación - valor verdadero|/|valor verdadero|\n\n\nnp.abs(pi_truncado - np.pi)/np.abs(np.pi)\n\nnp.float64(2.9492553621508708e-05)\n\n\n\nnp.abs(pi_redondeado - np.pi)/np.abs(np.pi)\n\nnp.float64(2.3384349967961744e-06)",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html#aritmética-de-dígitos-finitos",
    "href": "04_numeros_y_condicionamiento.html#aritmética-de-dígitos-finitos",
    "title": "Representación de números y número de condicionamiento",
    "section": "",
    "text": "El número más cercano a \\(1\\) por la derecha en \\(16\\) bits es\n0 00000 0000000001\nRestándole \\(1\\), este se llama el \\(\\epsilon\\) de máquina. En el caso de 16 bits es burdamente \\(10^{-3}\\). En el caso de 64 bits es \\(\\sim 10^{-16}\\) y en el caso de 32 bits es \\(\\sim 10^{-8}\\). Esta es la máxima precisión que podemos alcanzar al operar con números representados de esta forma.\n\nnp.finfo(np.float32).eps\n\nnp.float32(1.1920929e-07)\n\n\n\nnp.finfo(np.float64).eps\n\nnp.float64(2.220446049250313e-16)\n\n\nCuidado, el verdadero error cometido es el \\(\\epsilon_{maq}\\) multiplicado por el exponente, tal que el error al usar números en \\([1/2, 1)\\) es en realidad \\(\\epsilon_{maq}/2\\) por ejemplo.\n\neps = np.finfo(float).eps\nx = eps/2\n(1.0 + x) - 1.0\n\nnp.float64(0.0)\n\n\n\n1.0 + (x - 1.0)\n\nnp.float64(1.1102230246251565e-16)\n\n\nSegún el estándar IEEE 754, los resultados de las sumas, restas, multiplicaciones y divisiones de números de punto flotante en el computador deben dar un resultado igual a hacer el cálculo con números reales y luego redondear a la precisión de la representación.\n\n\n\n\n\n\nAdvertencia\n\n\n\nComo vimos con el ejemplo de arriba, todo esto quiere decir que dos resultados matemáticamente equivalentes no dan necesariamente el mismo resultado si se usa aritmética de punto flotante.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html#tarea-2.1",
    "href": "04_numeros_y_condicionamiento.html#tarea-2.1",
    "title": "Representación de números y número de condicionamiento",
    "section": "Tarea 2.1",
    "text": "Tarea 2.1\nSuponga que usamos 64 bits para representar un número de punto flotante. Queremos resolver un problema numérico con número de condicionamiento \\(\\kappa \\sim 10^6\\). Esto lo llevamos a un laboratorio donde el aparato de medida tiene una precisión relativa de seis cifras decimales.\n\n¿Podemos usar el resultado de este cálculo para comparar con el experimento?\nSi queremos reducir el tamaño que ocupa el número en la memoria RAM, ¿podemos cambiar nuestra representación a una de 32 bits?",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html#tarea-2.2",
    "href": "04_numeros_y_condicionamiento.html#tarea-2.2",
    "title": "Representación de números y número de condicionamiento",
    "section": "Tarea 2.2",
    "text": "Tarea 2.2\nEjercicio 1.2.3 del libro “Fundamentals of Numerical Computation: Julia Edition” de Driscoll y Braun.\nCalcule el número de condicionamiento para cada una de las siguientes funciones e identifique todos los valores de \\(x\\) para los cuales \\(\\kappa_f(x) \\rightarrow \\infty\\) (incluyendo posiblemente los límites \\(x \\rightarrow \\pm \\infty\\))\n\n\\(f(x) = \\tanh(x)\\).\n\\(f(x) = \\frac{e^x - 1}{x}\\).\n\\(f(x) = \\frac{1 - \\cos(x)}{x}\\).",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html#tarea-2.3",
    "href": "04_numeros_y_condicionamiento.html#tarea-2.3",
    "title": "Representación de números y número de condicionamiento",
    "section": "Tarea 2.3",
    "text": "Tarea 2.3\nEn ciertos cálculos importantes en cosmología surge un problema análogo al siguiente. Queremos calcular algunas integrales\n\\[\nI_{1} = \\int_{0}^{q_{max}} q^2\\left(\\frac{1}{q^5} + \\frac{3}{q}\\right)\\,dq\n\\]\n\\[\nI_{2} = \\int_{0}^{q_{max}} q^2\\left(\\frac{-1}{q^5} + \\frac{1}{q}\\right)\\,dq\n\\]\nEstas integrales se pueden aproximar numéricamente por medio de su suma ) \\[\n\\int_0^{q_{max}} f(q)\\,dq \\approx \\frac{q_{max}}{N} \\sum_{i = 1}^{N} f\\left(i\\times\\frac{q_{max}}{N}\\right)\n\\]\nProfundizaremos en el cálculo numérico de integrales más adelante.\nLa cantidad de interés es \\(I = I_{1} + I_{2}\\).\n\nUsando \\(q_{max} = 0.1\\) y \\(N = 500000\\), calcule ambas integrales por separado usando la aproximación, y luego súmelas.\nLa suma de las integrales \\(I\\) se puede escribir como la integral de la suma de los integrandos:\n\n\\[\nI = \\int_0^{q_{max}} q^2 \\frac{4}{q}\\,dq\n\\]\nCalcule \\(I\\) de esta manera usando la aproximación.\n\n¿Por qué son diferentes los resultados? Compare con el resultado exacto de la integral \\(I\\).",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html#tarea-2.4",
    "href": "04_numeros_y_condicionamiento.html#tarea-2.4",
    "title": "Representación de números y número de condicionamiento",
    "section": "Tarea 2.4",
    "text": "Tarea 2.4\nEjercicio 1.3.1 del libro de Burden: Use números de punto flotante de 16 bits para calcular las siguientes sumas. Explique por qué ambos métodos en cada caso dan resultados diferentes y cuál es la más correcta.\n\n\\(\\sum_{n = 1}^{100}\\frac{1}{n^2}\\) primero de la forma \\(1 + \\frac{1}{4} + \\frac{1}{9} + \\dots + \\frac{1}{10^4}\\) y luego en la forma \\(\\frac{1}{10^4} + \\dots + \\frac{1}{9} + \\frac{1}{4} + 1\\).\n\\(\\sum_{n = 1}^{100}\\frac{1}{n^3}\\) primero de la forma \\(1 + \\frac{1}{8} + \\frac{1}{27} + \\dots + \\frac{1}{10^6}\\) y luego en la forma \\(\\frac{1}{10^6} + \\dots + \\frac{1}{27} + \\frac{1}{8} + 1\\).",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "04_numeros_y_condicionamiento.html#tarea-2.5",
    "href": "04_numeros_y_condicionamiento.html#tarea-2.5",
    "title": "Representación de números y número de condicionamiento",
    "section": "Tarea 2.5",
    "text": "Tarea 2.5\nEjercicio 1.2.6 del libro “Fundamentals of Numerical Computation: Julia Edition” de Driscoll y Braun.\nEncuentre el número de condicionamiento para el problema de encontrar las raices del polinomio cuadrático \\(p(x) = ax^2 + bx + c\\) bajo cambios al coeficiente \\(b\\).",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Representación de números y condicionamiento"
    ]
  },
  {
    "objectID": "21_ajuste_de_curvas.html",
    "href": "21_ajuste_de_curvas.html",
    "title": "Ajuste de funciones",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nVimos los métodos de interpolación para los cuales se exige que un polinomio pase por una serie de puntos \\((x_o, y_o), ..., (x_n, y_n)\\). Pero hay situaciones en las que esto no es práctico.\nCuando los datos vienen de una medición, las mediciones vienen con un error, y hacer una interpolación de alto orden puede conllevar a oscilaciones. Además, usar demasiados parámetros libres para ajustar datos experimentales es errado desde un punto de vista estadístico.\nx = np.linspace(0, 1, 10)\nfunc = x**2 + 3*x + 2\nn = np.random.normal(0, 0.02, 10)\nmed = func + n\nplt.scatter(x, med)\ndef difer(puntos):\n    \n    n = len(puntos) - 1\n    Fs = [np.zeros(n + 1)]\n    for i in range(n + 1):\n        Fs[0][i] = puntos[i][1]\n    for i in range(1, n + 1):\n        Fs.append(np.zeros(n + 1 - i))\n        for j in range(1, i + 1):\n            Fs[j][i-j] = (Fs[j-1][i-j+1] - Fs[j-1][i-j])/(puntos[i][0] - puntos[i-j][0])\n    \n    return [Fs[i][0] for i in range(n + 1)]\n\ndef poly(x, coefs, puntos):\n    return sum(coefs[n]*np.prod([(x - puntos[i,0]) for i in range(n)]) for n in range(len(coefs)))\npuntos  = np.array(list(zip(x, med)))\ncoefs = difer(puntos)\nx = np.linspace(0, 1, 100)\nplt.plot(x, [poly(xi, coefs, puntos) for xi in x])\nplt.scatter(puntos[:,0], puntos[:,1], color='red')\ncoefs\n\n[np.float64(1.9660015654510128),\n np.float64(3.5427316674505915),\n np.float64(-1.2206630685780449),\n np.float64(8.649586907131223),\n np.float64(-32.03571506941876),\n np.float64(85.03046692518087),\n np.float64(-92.61731957764148),\n np.float64(-287.46677033300125),\n np.float64(1812.743729169234),\n np.float64(-5574.569417909028)]\nComo vemos, el polinomio de alto orden no es un buen ajuste a estos datos. Y de hecho vemos que tiene coeficientes relativamente grandes hasta de orden 10, cuando sabemos que los datos son una parábola. Podríamos interpolar entre cada par de puntos usando una spline, pero entonces no podemos recuperar el modelo a partir de los datos.\nAdicionalmente, tenemos 10 coeficientes para 10 puntos de datos. Siempre es posible ajustar un número de coeficientes igual al número de datos pero esto tiende a inducir las oscilaciones que vemos arriba, a esto se lo llama “overfitting” o sobreajuste.\nSurge entonces una pregunta: ¿Cuál es el mejor polinomio de orden más bajo que se ajusta a los datos? Es decir, queremos que ese polinomio se “acerque lo más posible a los datos”. Adicionalmente, ¿qué criterio debemos usar para decidir si es un buen ajuste?",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Ajustes de mínimos cuadrados"
    ]
  },
  {
    "objectID": "21_ajuste_de_curvas.html#ajuste-lineal",
    "href": "21_ajuste_de_curvas.html#ajuste-lineal",
    "title": "Ajuste de funciones",
    "section": "Ajuste lineal",
    "text": "Ajuste lineal\nPodemos por ejemplo hacer un ajuste de una recta \\(f(a_o, a_1; x) = a_o + a_1 x\\) y entonces\n\\[\nE(a_o, a_1) =  \\sum_i\\left[\\hat{y}_i - (a_o + a_1 x_i)\\right]^2\\,.\n\\]\nEsta la podemos escribir en forma matricial como\n\\[\nE(\\vec{a}) = (\\vec{y} - X\\vec{a})^T(\\vec{y} - X\\vec{a})\\,,\n\\]\ndonde \\(X\\) es la matriz de características o de Van der Monde y está dada por\n\\[\nX = \\begin{bmatrix}\n1 & x_1\\\\\n1 & x_2\\\\\n\\vdots & \\vdots\\\\\n1 & x_m\n\\end{bmatrix}\\,,\n\\]\nel vector \\(\\vec{y}\\) es \\(\\vec{y}^T = (y_1, y_2, \\ldots, y_m)\\) y el vector \\(\\vec{a}\\) es \\(\\vec{a}^T = (a_o, a_1)\\).\nEscrito de esta manera, podemos encontrar el mínimo tomando la derivada respecto a los parámetros\n\\[\n\\frac{\\partial E(\\vec{a})}{\\partial \\vec{a}} = -2 X^T(\\vec{y} - X\\vec{a})\\,,\n\\]\nIgualando a cero obtenemos las ecuaciones normales:\n\\[\nX^TX \\vec{a} = X^T\\vec{y}\\,.\n\\]\nEste es un sistema de ecuaciones como los que hemos estudiado antes. De hecho, la matriz \\(X^TX\\) es una matriz cuadrada \\(2\\times 2\\) y el vector \\(X^T\\vec{y}\\) es de dimensión \\(2\\). El algoritmo para resolver este tipo de sistemas se llama factorización QR (más información). Superficialmente se parece al algoritmo LU que vimos, pero está optimizado para este tipo de sistemas.\nLo útil de escribir el problema de esta forma es que podemos usarlo para ajustar cualquier polinomio. Por ejemplo, supongamos que queremos ajustar los datos a una parábola \\(f(x) = a_2 x^2 + a_1 x + a_0\\). Entonces el vector \\(\\vec{a}^T = (a_0, a_1, a_2)\\) y la matriz de Van der Monde es\n\\[\nX = \\begin{bmatrix}\n1 & x_1 & x_1^2\\\\\n1 & x_2 & x_2^2\\\\\n\\vdots & \\vdots & \\vdots\\\\\n1 & x_m & x_m^2\n\\end{bmatrix}\\,.\n\\]\nTodo lo demás es igual que antes. Hagamos un ejemplo:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 1, 10)\nfunc = x**2\nn = np.random.normal(0, 0.02, 10)\nmed = func + n\nplt.scatter(x, med)\n\n\n\n\n\n\n\n\n\nvander = np.column_stack((np.ones(10), x, x**2))\n# lstsq(a, b) resuelve el sistema ax = b aproximadamente usando lo descrito arriba.\n# lstsq quiere decir least squares que en espanol significa \"mínimos cuadrados\".\naopt, *_ = np.linalg.lstsq(vander, med, rcond=None)\n\nx_plot = np.linspace(0, 1, 100)\ny_plot = aopt[0] + aopt[1]*x_plot + aopt[2]*x_plot**2\nplt.scatter(x, med)\nplt.plot(x_plot, y_plot, 'r')\nplt.show()\n\n\n\n\n\n\n\n\nEste mismo método se puede usar para cualquier combinación lineal de funciones de \\(x\\) de la forma \\(f(x) = a_1 f_1(x) + a_2 f_2(x) + \\ldots\\). En el ejemplo anterior, \\(f_1(x) = x\\), \\(f_2(x) = x^2\\) y \\(f_3(x) = 1\\). Si quisiéramos ajustar el modelo \\(f(x) = a_0 + a_1 e^x\\) nuestra matriz de Van der Monde sería\n\\[\n\\begin{bmatrix}\n1 & e^{x_1}\\\\\n1 & e^{x_2}\\\\\n\\vdots & \\vdots\\\\\n1 & e^{x_m}\n\\end{bmatrix}\\,.\n\\]\nEste tipo de ajuste se llama ajuste lineal porque es una combinación lineal de funciones, aunque estas no tienen que ser rectas. Muchos problemas que no parecen lineales se pueden convertir en algo lineal, por ejemplo el modelo \\(f(x) = cx^p\\) donde queremos encontrar los mejores \\(c\\) y \\(p\\) se reduce a un ajuste lineal tomando el logaritmo \\(\\ln f(x) = \\ln c + p \\ln x\\). Entonces basta tomar el logaritmo de los \\(\\vec{y}\\) y ajustar con este modelo.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Ajustes de mínimos cuadrados"
    ]
  },
  {
    "objectID": "21_ajuste_de_curvas.html#scipy",
    "href": "21_ajuste_de_curvas.html#scipy",
    "title": "Ajuste de funciones",
    "section": "Scipy",
    "text": "Scipy\nCopiado de: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\nScipy tiene una función muy útil para realizar ajustes de curvas a datos, esta nos permite ajustar una función arbitraria con parámetros libres, incluyendo el caso en el que los puntos de datos tienen errores diferentes.\n\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\ndef func(x, a, b, c):\n    return a * np.exp(-b * x) + c\n\n\nxdata = np.linspace(0, 4, 50)\ny = func(xdata, 2.5, 1.3, 0.5)\nnp.random.seed(1729)\ny_noise = 0.2 * np.random.normal(size=xdata.size)\nydata = y + y_noise\nplt.plot(xdata, ydata, 'b-', label='data')\n\n\n\n\n\n\n\n\n\npopt, pcov = curve_fit(func, xdata, ydata)\npopt\n\narray([2.55423706, 1.35190946, 0.47450617])\n\n\n\nplt.plot(xdata, func(xdata, *popt), 'r-',\n         label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n\n\n\n\n\n\n\n\nSe restringe el rango a \\(0 &lt; a &lt; 3\\), \\(0 &lt; b &lt; 1\\), \\(0 &lt; c &lt; 1/2\\)\n\npopt2, pcov2 = curve_fit(func, xdata, ydata, bounds=(0, [3., 1., 0.5]))\npopt2\n\narray([2.43708906, 1.        , 0.35015434])\n\n\n\nplt.plot(xdata, ydata, 'b-', label='data')\nplt.plot(xdata, func(xdata, *popt), 'r-',\n         label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\nplt.plot(xdata, func(xdata, *popt2), 'g--',\n         label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt2))\nplt.legend()",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Ajustes de mínimos cuadrados"
    ]
  },
  {
    "objectID": "21_ajuste_de_curvas.html#tarea-10.6",
    "href": "21_ajuste_de_curvas.html#tarea-10.6",
    "title": "Ajuste de funciones",
    "section": "Tarea 10.6",
    "text": "Tarea 10.6\nDemiestre (analíticamente) las siguientes propiedades de la matriz \\(X^TX\\) que aparece en el ajuste de mínimos cuadrados:\n\nEs una matriz simétrica para cualquier matriz \\(X\\) real \\(n\\times m\\).\nEs una matriz positiva definida para cualquier matriz \\(X\\) real \\(n\\times m\\).",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Ajustes de mínimos cuadrados"
    ]
  },
  {
    "objectID": "21_ajuste_de_curvas.html#tarea-10.7",
    "href": "21_ajuste_de_curvas.html#tarea-10.7",
    "title": "Ajuste de funciones",
    "section": "Tarea 10.7",
    "text": "Tarea 10.7\nUse scipy para resolver el siguiente problema:\nQueremos medir los parámetros \\(a\\), \\(b\\) y \\(k\\) del siguiente modelo \\(f(x) = a e^{kx} + b\\) a partir de las siguientes mediciones\n\n\n\n\\(x\\)\n\\(f(x)\\)\n\\(\\sigma\\)\n\n\n\n\n\\(1\\)\n\\(6.54\\)\n\\(0.1\\)\n\n\n\\(2\\)\n\\(7.57\\)\n\\(0.3\\)\n\n\n\\(3\\)\n\\(8.83\\)\n\\(0.1\\)\n\n\n\\(4\\)\n\\(10.43\\)\n\\(0.2\\)\n\n\n\\(5\\)\n\\(12.95\\)\n\\(0.05\\)\n\n\n\nEncuentre los valores de los parámetros que mejor se ajustan a los datos. ¿Es un buen ajuste?",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Ajustes de mínimos cuadrados"
    ]
  },
  {
    "objectID": "21_ajuste_de_curvas.html#tarea-10.8",
    "href": "21_ajuste_de_curvas.html#tarea-10.8",
    "title": "Ajuste de funciones",
    "section": "Tarea 10.8",
    "text": "Tarea 10.8\nEn clase vimos cómo ajustar una línea recta a un conjunto de datos cuando el error de todos los datos es el mismo. Repita el ejercicio para los siguientes datos (que tienen todos un error diferente):\n\n\n\n\\(x\\)\n\\(f(x)\\)\n\\(\\sigma\\)\n\n\n\n\n\\(0.1\\)\n\\(5.71\\)\n\\(0.2\\)\n\n\n\\(0.2\\)\n\\(7.21\\)\n\\(0.3\\)\n\n\n\\(0.3\\)\n\\(8.07\\)\n\\(0.2\\)\n\n\n\\(0.4\\)\n\\(9.73\\)\n\\(0.4\\)\n\n\n\\(0.5\\)\n\\(10.06\\)\n\\(0.05\\)\n\n\n\nEs decir, reescriba el sistema de ecuaciones a resolver tomando en cuenta que cada error es diferente. Luego resuélvalo.\n¿Es un buen ajuste?",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Ajustes de mínimos cuadrados"
    ]
  },
  {
    "objectID": "21_ajuste_de_curvas.html#tarea-10.9",
    "href": "21_ajuste_de_curvas.html#tarea-10.9",
    "title": "Ajuste de funciones",
    "section": "Tarea 10.9",
    "text": "Tarea 10.9\nEjercicio 3.1.9 de “Fundamentals of Numerical Computation” de Tobin A. Driscoll y Richard J. Braun, 2023.\nSin escribir código, muestre cómo se podrían ajustar a los datos las constantes \\(a\\) y \\(b\\) de la siguiente ecuación \\(y(t) = t/(at + b)\\) convirtiéndolo antes en un problema de ajuste lineal.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Ajustes de mínimos cuadrados"
    ]
  },
  {
    "objectID": "21_ajuste_de_curvas.html#tarea-10.10",
    "href": "21_ajuste_de_curvas.html#tarea-10.10",
    "title": "Ajuste de funciones",
    "section": "Tarea 10.10",
    "text": "Tarea 10.10\nConsidere los siguientes datos:\n\n\n\n\\(x\\)\n\\(f(x)\\)\n\\(\\sigma\\)\n\n\n\n\n\\(0.1\\)\n\\(0.280\\)\n\\(0.1\\)\n\n\n\\(0.2\\)\n\\(0.472\\)\n\\(0.07\\)\n\n\n\\(0.3\\)\n\\(0.686\\)\n\\(0.05\\)\n\n\n\\(0.4\\)\n\\(0.850\\)\n\\(0.1\\)\n\n\n\\(0.5\\)\n\\(1.263\\)\n\\(0.03\\)\n\n\n\\(0.6\\)\n\\(1.576\\)\n\\(0.01\\)\n\n\n\\(0.7\\)\n\\(1.894\\)\n\\(0.01\\)\n\n\n\nUse scipy para ajustar los siguientes modelos:\n\n\\(a_1 x\\)\n\\(a_1 x + a_2 x^2\\)\n\\(a_o + a_1 x + a_2 x^2\\)\n\n¿Cuál modelo describe mejor los datos? ¿Por qué?\nAhora repita lo mismo con los siguientes datos:\n\n\n\n\\(x\\)\n\\(f(x)\\)\n\\(\\sigma\\)\n\n\n\n\n\\(0.1\\)\n\\(-1.36\\)\n\\(2.0\\)\n\n\n\\(0.2\\)\n\\(0.20\\)\n\\(1.4\\)\n\n\n\\(0.3\\)\n\\(3.01\\)\n\\(1.0\\)\n\n\n\\(0.4\\)\n\\(0.30\\)\n\\(2.0\\)\n\n\n\\(0.5\\)\n\\(1.11\\)\n\\(0.6\\)\n\n\n\\(0.6\\)\n\\(1.52\\)\n\\(0.2\\)\n\n\n\\(0.7\\)\n\\(2.09\\)\n\\(0.2\\)\n\n\n\nAmbos datos fueron generados a partir de la misma función \\(f\\). Explique por qué cambian los resultados.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Ajustes de mínimos cuadrados"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html",
    "href": "06_definicion_probabilidad.html",
    "title": "Definiciones básicas de probabilidad",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#definición",
    "href": "06_definicion_probabilidad.html#definición",
    "title": "Definiciones básicas de probabilidad",
    "section": "Definición",
    "text": "Definición\nMatemáticamente la probabilidad es la asignación de una medida a un conjunto \\(\\mathcal{S}\\). Es decir, a cada subconjunto \\(E\\) del conjunto le asignamos un número \\(p(E)\\) tal que\n\n\\(p(E) \\geq 0\\) para todo \\(E\\).\n\\(p(A \\cup B) = p(A) + p(B)\\)\n\\(p(\\mathcal{S}) = 1\\)\n\nCuando el conjunto \\(\\mathcal{S}\\) es discreto, le asignamos a cada elemento un número entre \\(0\\) y \\(1\\) tal que la suma de todos los elementos sea \\(1\\).\nCuando el conjunto \\(\\mathcal{S}\\) es un subconjunto continuo de los reales, le asignamos una densidad de probabilidad tal que la probabilidad del intervalo \\((a,b) \\subset \\mathcal{S}\\) es \\[\np((a,b)) = \\int_a^b dx\\,\\rho(x)\\,.\n\\] La función de distribución de probabilidad a veces se llama la PDF por su sigla en inglés.\nMás allá de la definición matemática, uno puede preguntarse por el significado de la probabilidad. Esta pregunta también es práctica, porque nos gustaría saber cómo asignarle una probabilidad a cada evento. Hay dos interpretaciones\n\nObjetiva: La probabilidad es obtenida experimentalmente. Si realizamos un experimento un número \\(N\\) de veces y obtenemos el resultado \\(A\\) un número \\(N_A\\) veces, decimos que la probabilidad de obtener \\(A\\) es \\[\nP(A) = \\lim_{N\\rightarrow \\infty} \\frac{N_A}{N}\\,.\n\\] Esta definición es idealizada ya que nunca podemos realizar un experimento infinitas veces.\nSubjetiva: Las probabilidades nos dan una estima basada en la incertidumbre debida a la ignorancia sobre los procesos.\n\nNormalmente asumimos, a falta de más información, que todos los resultados son igualmente probables. Si hacemos esto la probabilidad es la fracción de eventos favorables.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#propiedades-básicas",
    "href": "06_definicion_probabilidad.html#propiedades-básicas",
    "title": "Definiciones básicas de probabilidad",
    "section": "Propiedades básicas",
    "text": "Propiedades básicas\nDefinimos primero la probabilidad condicional de que ocurra \\(A\\) dado que ocurre \\(B\\): \\(P(A|B)\\)\nEjemplo: La probabilidad de que al lanzar un dado dos veces el segundo resultado sea par dado que la suma de ambos es 6.\nLanzar dos dados tiene 36 posibles resultados. La probabilidad la tomamos como la fracción que cumple lo pedido.\nEntre los 36 resultados, tomemos aquellos que cumplen B (la suma de ambos resultados es 6):\n\\[\n1, 5\\,;\\quad 2, 4\\,;\\quad 3, 3\\,;\\quad 4, 2\\,;\\quad 5, 1\\,.\n\\]\nLa probabilidad condicional es la fracción de estos 5 que cumple la condición A (el segundo es par). Estos son 2. Por lo tanto la probabilidad es \\(2/5\\).\nLa probabilidad conjunta es la probabilidad de que ocurran dos eventos.\nEn el ejemplo anterior, la probabilidad de que el segundo resultado sea par y la suma de ambos sea 6 es la fracción del total que cumple estas dos condiciones. Es decir \\(2/36\\).\nEn general tenemos que\n\\[\nP(AB) = P(A|B)P(B)\n\\]\nPodemos verificar que se cumple para el ejemplo anterior.\nEsto tiene sentido ya que \\(P(B)\\) es la fracción que cumple B, y \\(P(A|B)\\) es la fracción entre todos los que cumplen B de aquellos que cumplen A.\nOtro problema, ¿cuál es la probabilidad de que la suma sea 6 o que el segundo resultado sea par?\nSi lo pensamos un segundo\n\\[\nP(A\\cup B) = P(A) + P(B) - P(AB)\n\\]\nEsto es porque al sumar los que cumplen A y los que cumplen B, estamos contando dos veces los que cumplen ambos.\nDecimos que dos eventos son independientes cuando \\(P(A|B) = P(A)\\). En ese caso \\(P(AB) = P(A)P(B)\\).\nDecimos que dos eventos son mutuamente excluyentes cuando \\(P(AB) = 0\\). En ese caso \\(P(A\\cup B) = P(A) + P(B)\\).",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#teorema-de-bayes",
    "href": "06_definicion_probabilidad.html#teorema-de-bayes",
    "title": "Definiciones básicas de probabilidad",
    "section": "Teorema de Bayes",
    "text": "Teorema de Bayes\nEste teorema es tal vez el teorema famoso más sencillo de demostrar:\n\\[\nP(A|B) = \\frac{P(B|A) P(A)}{P(B)}\n\\]\nDemostración:\n\\[\nP(AB) = P(BA)\n\\]\nentonces\n\\[\nP(A|B)P(B) = P(B|A)P(A)\n\\]\nPara ver un ejemplo de su poder, supongamos que sabemos que los estudiantes de física son \\(70\\) hombres y \\(30\\) mujeres mientras que los estudiantes de química son \\(141\\) hombres y \\(153\\) mujeres. En el pasillo conocemos a un estudiante que está hablando de átomos (tal que es de física o química). Si este estudiante es mujer, ¿cuál es la probabilidad de que sea de física?\nQueremos calcular \\(P(física|mujer)\\), pero conocemos el objeto al revés \\(P(mujer|física)\\). ¿Cómo lo hacemos?\n\nnumero_estudiantes = 141 + 153 + 70 + 30\nprob_mujer = (153 + 30)/numero_estudiantes\nprob_fisica = 100/numero_estudiantes\nprob_mujer_dado_fisica = 30/100\n\nprob_mujer_dado_fisica*prob_fisica/prob_mujer\n\n0.16393442622950818",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#una-variable-aleatoria",
    "href": "06_definicion_probabilidad.html#una-variable-aleatoria",
    "title": "Definiciones básicas de probabilidad",
    "section": "Una variable aleatoria",
    "text": "Una variable aleatoria\nUn número \\(x\\) que puede tomar valores dentro del conjunto \\(\\mathcal{S}\\) se llama una variable aleatoria. En física es más común usar variables aleatorias continuas, es decir \\(\\mathcal{S} = \\mathbb{R}\\). Podemos caracterizar esta variable con varias propiedades:\n\nLa función cumulativa de probabilidad es \\(P(x) = p((-\\infty, x))\\). Claramente \\(P(-\\infty) = 0\\) y \\(P(\\infty) = 1\\). Note que \\(\\frac{d P}{dx}(x) = \\rho(x)\\).\nEl valor esperado de alguna cantidad \\(F(x)\\) es \\[\n\\langle F \\rangle = \\int_{-\\infty}^{\\infty}dx\\,\\rho(x)F(x)\\,.\n\\]\nPodemos cambiar de variable definiendo \\(y(x)\\). La distribución de probabilidad de esta variable es \\[\n\\rho(y) = \\left|\\frac{\\partial x}{\\partial y}\\right|\\rho(x)\\,.\n\\]\n\nEjemplo: Sea \\(\\rho(x) = \\lambda \\exp(-\\lambda|x|)/2\\). Note que \\(\\int_{-\\infty}^\\infty dx\\,\\rho(x) = 1\\). Tomemos \\(y = x^2\\), entonces también \\(\\left|\\frac{\\partial x}{\\partial y}\\right| = \\frac{1}{2\\sqrt{y}}\\).\nComo hay dos valores de \\(x\\) que corresponden al mismo valor de \\(y\\), la probabilidad de \\(y\\) será la suma de esas dos posibilidades: \\[\n\\rho(y) = 2\\frac{\\lambda}{2}\\exp(-\\lambda\\sqrt{y})\\frac{1}{2\\sqrt{y}} = \\frac{\\lambda \\exp(-\\lambda \\sqrt{y})}{2\\sqrt{y}}\\,.\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#momentos-y-cumulantes",
    "href": "06_definicion_probabilidad.html#momentos-y-cumulantes",
    "title": "Definiciones básicas de probabilidad",
    "section": "Momentos y cumulantes",
    "text": "Momentos y cumulantes\nUna propiedad importante de una distribución de probabilidad son sus momentos \\[\nm_n = \\langle x^n \\rangle = \\int dx\\,\\rho(x)x^n\\,.\n\\]\nLa función característica es la transformada de Fourier de la densidad de probabilidad \\[\n\\tilde{\\rho}(k) = \\langle e^{-ikx} \\rangle = \\int dx\\,\\rho(x) e^{-ikx}\\,.\n\\] La PDF se puede recuperar a partir de la función característica tomando la transformada inversa \\[\n\\rho(x) = \\frac{1}{2\\pi}\\int_{-\\infty}^\\infty dk\\,\\rho(k) e^{ikx}\\,.\n\\] Los momentos de la distribución se pueden obtener expandiendo en potencias de \\(k\\) \\[\n\\tilde{\\rho}(k) = \\left\\langle \\sum_{n=0}^\\infty \\frac{(-ik)^n}{n!}x^n\\right\\rangle = \\sum_{n=0}^\\infty \\frac{(-ik)^n}{n!}\\langle x^n\\rangle\\,.\n\\]\nLos cumulantes son valores esperados conexos. Es decir, le restamos a los momentos la información contenida en momentos de orden inferior: \\[\\begin{align*}\n\\langle x \\rangle_c &= \\langle x\\rangle\\,,\\\\\n\\langle x^2 \\rangle_c &= \\langle x^2 \\rangle - \\langle x \\rangle^2\\,,\\\\\n\\langle x^3 \\rangle_c &= \\langle x^3 \\rangle - 3 \\langle x^2\\rangle_c \\langle x \\rangle - \\langle x\\rangle^3\\,,\\\\\n\\langle x^4 \\rangle_c &= \\langle x^4 \\rangle - 4 \\langle x^4\\rangle_c \\langle x \\rangle - 6\\langle x^2\\rangle_c^2 - 6 \\langle x^2\\rangle_c \\langle x \\rangle^2 - \\langle x\\rangle^4\\,.\n\\end{align*}\\] En general, estos cumulantes se definen como proveniendo del logaritmo de la función característica \\[\n\\ln \\tilde{\\rho}(k) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!}\\langle x^n\\rangle_c\\,.\n\\]\nEl segundo cumulante \\(\\sigma^2 = \\langle x^2 \\rangle_c\\) se llama la varianza de la distribución y representa cuánto está esparcida. Si llamamos \\(x_o = \\langle x \\rangle\\) tenemos \\[\n\\langle (x - x_o)^2 \\rangle = \\langle x^2 \\rangle - 2 \\langle x x_o \\rangle + \\langle x_o^2 \\rangle = \\langle x^2 \\rangle - x_o^2 = \\langle x^2 \\rangle_c\\,.\n\\] La varianza es el valor esperado de la desviación al cuadrado. Es decir, nos dice en promedio cual es la desviación al cuadrado de un punto respecto a \\(x_o\\).\nDemostración (opcional):\n\\[\n\\sum_{n=0}^\\infty \\frac{(-ik)^n}{n!}\\langle x^n\\rangle = \\exp\\left[\\sum_{n=1}^\\infty\\frac{(-ik)^n}{n!}\\langle x^n\\rangle_c\\right] = \\prod_n \\sum_{p_n}\\left[\\frac{(-ik)^{np_n}}{p_n!}\\left(\\frac{\\langle x^n \\rangle_c}{n!}\\right)^{p_n}\\right]\\,.\n\\]\nIgualando las potencias de \\(k\\) del lado izquierdo y derecho obtenemos\n\\[\n\\langle x^n \\rangle = \\sum'_{p_n} m! \\prod_n \\frac{1}{p_n!(n!)^{p_n}}\\langle x^n \\rangle_c^{p_n}\\,.\n\\]\nLa suma primada se refiere al hecho que sumamos sobre todos los valores de \\(p_n\\) tales que \\(\\sum n p_n = m\\).",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#generadores-de-números-aleatorios",
    "href": "06_definicion_probabilidad.html#generadores-de-números-aleatorios",
    "title": "Definiciones básicas de probabilidad",
    "section": "Generadores de números aleatorios",
    "text": "Generadores de números aleatorios\nTomado completamente de:\n\nhttp://users.dimi.uniud.it/~alberto.policriti/home/sites/default/files/ASD/prng-slides.pdf\nhttps://www.eg.bucknell.edu/~xmeng/Course/CS6337/Note/master/node40.html\nhttps://realpython.com/python-random/\n\nEste es un tema sumamente interesante. Se le dedican libros enteros y es crucial para las simulaciones en física y estadística. Así mismo es una parte central de la criptografía moderna. Sin embargo, yo no soy un experto y este no es el tema central del curso, así que seremos un poco superficiales.\nDe las siguientes dos secuencias, la segunda parece más aleatoria:\n\n0101010101010101010101010101010101010101\n0010010000111111011010101000100010000101\n\nEsto es porque parece tener menos patrones y repeticiones. En realidad es una representación del número \\(\\pi\\).\nSe pueden obtener números verdaderamente aleatorios a partir de fenómenos físicos como rayos cósmicos, decaimiento de átomos, o incluso los estados electrónicos de algunos componentes del computador. También se pueden obtener números esencialmente aleatorios contando cuántas teclas ha presionado el usuario junto con el estado de la memoria RAM y el número del proceso en el sistema operativo (todo esto es determinista pero imposible de predecir en la práctica). En Python podemos acceder a tales números “verdaderamente” aleatorios:\n\nimport secrets\n\nsecrets.randbelow(10)\n\n3\n\n\n\nsecrets.randbits(64)\n\n13485414310510998814\n\n\n\nlista = [1,2,3,4,5,6]\nsecrets.choice(lista)\n\n5\n\n\nSin embargo estos números aleatorios son lentos de producir. En física, nos basta con que los números “parezcan” aleatorios. Es decir, que tenga buenas propiedades estadísticas y que no sea predecible.\nPor ejemplo, pedimos que la variable aleatoria \\(x_i \\in [0,N]\\) esté distribuida de manera uniforme. Es decir, si tomo \\(n\\) muestras, y divido el intervalo \\([0,N]\\) en \\(m\\) subintervalos, en promedio cada subintervalo contiene \\(n/m\\) muestras.\nA los números que no son aleatorios pero parecen aleatorios se los llama números pseudo-aleatorios. Para generarlos se usan funciones que no tengan patrones fáciles de discernir y que sean caóticas (para condiciones iniciales cercanas producen secuencias muy diferentes).\nEl punto en la secuencia se llama el “estado”. Como el número de bits es finito, el “estado” tarde o temprano se repite. Las secuencias de números aleatorios tienen un período. Queremos que ese período sea lo más largo posible.\nEjemplo sencillo: Generadores de congruencia lineal.\n\\[\nx_{n+1} = (a x_n + c)\\mod(m)\n\\]\n\n# función (muy mala) que implementa el generador de congruencia lineal\ndef lcg():\n    \n    # Variables que definen el generador\n    a = 7 # intentar todos los números de 2 a 9\n    c = 0\n    m = 11 # intentar 10 y 11, ojalá grande para dar un período grande\n    \n    # Esto intenta ejecutar un pedazo de código, y si encuentra un error\n    # ejecuta lo que hay luego de \"except\"\n    try:\n        # queremos que el estado no se borre cuando la función termine,\n        # de esa manera logramos que la función nos de el siguiente valor\n        # en la secuencia.\n        lcg.xn = (a*lcg.xn + c)%m\n    except(AttributeError):\n        # Habrá un error cuando lcg.xn no tenga un valor\n        print('Error: No se ha fijado la semilla.')\n        return\n        \n    return lcg.xn\n\n\nlcg.xn = 1\n\nlcg()\n\n7\n\n\n\nlcg.xn = 4\nnum = 100\naleatorios = [lcg() for i in range(num)]\nplt.scatter(range(num), aleatorios)\n\n\n\n\n\n\n\n\n\n# función (mala) que implementa el generador de congruencia lineal\ndef lcg():\n    \n    # Variables que definen el generador\n    a = 7**5\n    c = 0\n    m = 2**31 - 1   # si es primo es más fácil obtener períodos grandes\n    \n    # Esto intenta ejecutar un pedazo de código, y si encuentra un error\n    # ejecuta lo que hay luego de \"except\"\n    try:\n        # queremos que el estado no se borre cuando la función termine,\n        # de esa manera logramos que la función nos de el siguiente valor\n        # en la secuencia.\n        lcg.xn = (a*lcg.xn + c)%m\n    except(AttributeError):\n        # Habrá un error cuando lcg.xn no tenga un valor\n        print('Error: No se ha fijado la semilla.')\n        return\n        \n    return lcg.xn%10 + 1\n\n\nlcg.xn = 321\nnum = 100\naleatorios = [lcg() for i in range(num)]\nplt.scatter(range(num), aleatorios)\n\n\n\n\n\n\n\n\nAdemás, cuando se grafican las tuplas \\((x_n, x_{n+1},\\dots, x_{n + k})\\), todos los puntos yacen en \\(k - 1\\) planos. Esto hace predecible la secuencia y no muy aleatoria.\nMoraleja: No programar su propio generador aleatorio, si hay que hacerlo leer antes un libro dedicado a ello.\nPython usa un algoritmo más sofisticado llamado “Marsenne twister”. En cambio la librería estándar de C implementa un LCG.\n\nimport random\n\n\nrandom.randint(1,100)\n\n15\n\n\n\nlista = ['a', 'b', 'c', 'd']\nrandom.shuffle(lista)\nlista\n\n['d', 'a', 'b', 'c']\n\n\n\nnum = 10000\nplt.scatter(range(num), np.random.random(num))\n\n\n\n\n\n\n\n\n\nnum = 10000\nplt.scatter(range(num), np.random.randint(10, size=num) + 1)",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#simulaciones-estilo-monte-carlo-de-probabilidades",
    "href": "06_definicion_probabilidad.html#simulaciones-estilo-monte-carlo-de-probabilidades",
    "title": "Definiciones básicas de probabilidad",
    "section": "Simulaciones estilo Monte Carlo de probabilidades",
    "text": "Simulaciones estilo Monte Carlo de probabilidades\nDescribamos la probabilidad con un ejemplo:\nSupongamos que lanzamoos un dado y nos preguntamos cuál es la probabilidad de que caiga un número par.\n\ndado = {1, 2, 3, 4, 5, 6}\npar = {2, 4, 6}\n\n\ndef prob(evento, espacio):\n    ''' \n    Regresa la probabilidad de que ocurra 'evento'.\n    Los argumentos deben ser conjuntos.    \n    '''\n    return (len(evento & espacio)/len(espacio))\n\n\nprob(par, dado)\n\n0.5\n\n\nPara un ejemplo menos trivial, consideremos una urna con 23 bolas: 8 blancas, 6 azules, 9 rojas.\n\ndef unir(color, numeros):\n    return {color + numero for numero in numeros}\n\nurna = unir('B', '12345678') | unir('A', '123456') | unir('R', '123456789')\n\nSe extraen 6 bolas de la urna sin reemplazo.\n\nimport itertools\n\nespacio = set(itertools.permutations(urna, 6))\n\nNos preguntamos cuál es la probabilidad de obtener 6 bolas rojas\n\ndef todos_rojos(evento):\n    s = [i[0] for i in evento]\n    return s.count('R') == 6\n\nrojos = {e for e in espacio if todos_rojos(e)}\n\n\nprob(rojos, espacio)\n\n0.0008321198252548367\n\n\nEsto fue un cálculo a fuerza bruta. El problema es que si la urna tiene muchas bolas, el computador no va a ser capaz de calcular todos los elementos del espacio, se hace todo muy lento.\nConsideremos una urna con 2300 bolas: 800 blancas, 600 azules y 900 rojas.\n\ndef unir(color, numero):\n    return {color + str(n + 1) for n in range(numero)}\n\nurna = list(unir('B', 800) | unir('A', 600) | unir('R', 900))\n\nExtraemos 6 bolas\n# Cuidado, correr esto colapsa el computador\n\nespacio = set(itertools.permutations(urna,6))\nEl problema es que hay demasiadas combinaciones posibles. En estos casos lo que se hace es tomar un número de muestras al azar.\n\nimport random\n\n\nmuestra = {tuple(random.choices(urna, k = 6)) for i in range(100000)}\n\n\nrojos = {e for e in muestra if todos_rojos(e)}\n\n\nprob(rojos, muestra)\n\n0.00374\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nsims = 10\npuntos = 200000\nprobs = np.zeros(sims)\n\nfor i in range(sims):\n    muestra = {tuple(random.choices(urna, k = 6)) for i in range(puntos)}\n    rojos = {e for e in muestra if todos_rojos(e)}\n    probs[i] = prob(rojos, muestra)\n\nplt.plot(np.arange(sims), probs)\n\n\n\n\n\n\n\n\n\nprobs.mean()\n\nnp.float64(0.0035809999999999995)\n\n\n\nprobs.std()/probs.mean()\n\nnp.float64(0.03458551147461027)",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#tarea-3.1",
    "href": "06_definicion_probabilidad.html#tarea-3.1",
    "title": "Definiciones básicas de probabilidad",
    "section": "Tarea 3.1",
    "text": "Tarea 3.1\nEn el problema de la urna con23 bolas, al extraer 6 de ellas sin reemplazo.\n\n¿Cuál es la probabilidad de que entre las tres primeras no haya ninguna roja?\n¿Cuál es la probabilidad de sacar dos bolas de cada color?",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#tarea-3.2",
    "href": "06_definicion_probabilidad.html#tarea-3.2",
    "title": "Definiciones básicas de probabilidad",
    "section": "Tarea 3.2",
    "text": "Tarea 3.2\nRepita el problema de la urna pero con reemplazo. Es decir, luego de sacar cada bola esta se vuelve a poner en la urna. Si se extraen cuatro bolas de la urna, ¿cuál es la probabilidad de que todas sean rojas? Responda este problema escribiendo un código, modificando las funciones escritas en la clase para tomar en cuenta el reemplazo.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#tarea-3.3",
    "href": "06_definicion_probabilidad.html#tarea-3.3",
    "title": "Definiciones básicas de probabilidad",
    "section": "Tarea 3.3",
    "text": "Tarea 3.3\nEjercicio sacado de “Basic Probability Theory”, R. B. Ash, Dover, 1970.\nSe lanza un dado cargado, con probabilidades de \\(\\{0.1, 0.2, 0.2, 0.3, 0.1, 0.1\\}\\) de obtener \\(\\{1, 2, 3, 4, 5, 6\\}\\) respectivamente. Sea \\(N\\) el resultado obtenido al lanzar el dado, luego de lo cual se lanza una moneda \\(N\\) veces. Encuentre la probabilidad condicional de que \\(N\\) sea impar dado que se obtuvo al menos una cara.\nPista: Si no quiere hacerlo analíticamente, construya primero la distribución de probabilidad con todos los resultados posibles junto con sus probabilidades, y luego use las siguientes funciones que definimos en clase.\n\ndef prob(evento, dist):\n    '''\n    Calcula la probabilidad de un evento a partir de una distribución. El evento debe ser una función que\n    regresa verdadero o falso y la distribución debe ser un diccionario (evento: frecuencia)\n    '''\n    \n    conjunto = {e for e in dist.keys() if evento(e)}\n    total = sum(d for d in dist.values())\n    frec = sum(dist[e] for e in conjunto)\n    return frec/total\n\n\ndef prob_cond(A, B, dist):\n    \n    conjuntoB = {e for e in dist.keys() if B(e)}\n    conjuntoA = {e for e in conjuntoB if A(e)}\n    frec_B = sum(dist[e] for e in conjuntoB)\n    frec = sum(dist[e] for e in conjuntoA)\n    return frec/frec_B",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#tarea-3.4",
    "href": "06_definicion_probabilidad.html#tarea-3.4",
    "title": "Definiciones básicas de probabilidad",
    "section": "Tarea 3.4",
    "text": "Tarea 3.4\nEjercicio sacado de “Basic Probability Theory”, R. B. Ash, Dover, 1970.\nEn una cierta población, el \\(20\\%\\) de las personas tiene una enfermedad. Se hace un examen a los miembros de la población que tiene la característica de dar positivo el \\(90\\%\\) de las veces si la persona tiene la enfermedad y el \\(30\\%\\) de las veces si la persona no tiene la enfermedad (falso positivo). A los que dan positivo se les suministra una droga que puede causar manchas rojas en la piel en un \\(20\\%\\) de los pacientes.\nSi una persona tiene esas manchas rojas. ¿Cuál es la probabilidad de que haya tenido la enfermedad?",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "06_definicion_probabilidad.html#tarea-3.5",
    "href": "06_definicion_probabilidad.html#tarea-3.5",
    "title": "Definiciones básicas de probabilidad",
    "section": "Tarea 3.5",
    "text": "Tarea 3.5\nEjercicio sacado de “Basic Probability Theory”, R. B. Ash, Dover, 1970.\nDe las \\(100\\) personas de una aldea, \\(50\\) siempre dicen la verdad, \\(30\\) siempre mienten y \\(20\\) siempre se niegan a responder. Se toma una muestra de \\(30\\) personas sin reemplazo. Encuentre la probabilidad de que esta muestra contenga \\(10\\) personas de cada categoría.\nPara resolver este ejercicio es necesario hacer una simulación estilo Monte Carlo ya que el número de elementos en el espacio de resultados es demasiadoo grande. Estime el error cometido al hacer el cálculo de esta manera y obtenga un error razonable.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Propiedades de la probabilidad"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html",
    "href": "01_funcionamiento_cpu.html",
    "title": "¿Cómo funciona un computador?",
    "section": "",
    "text": "Lo que hace un computador es mover un montón de electrones. Para entender el computador, debemos entender cómo se mueven estas partículas en diferentes materiales. No entraremos en muchos detalles, pero necesitamos un par de hechos\n\nLos portadores de carga son los electrones: Los protones también tienen carga, pero son mucho más pesados y difíciles de mover. Las corrientes eléctricas consisten en electrones débilmente ligados que se mueven de un lugar a otro.\nEl principio de exclusión de Pauli: Dos electrones no pueden tener el mismo estado. Si tenemos un átomo completamente ionizado (sin electrones) y le agregamos un electrón, éste tenderá a ocupar el estado de mínima energía. Al llegar un segundo electrón, no puede estar en el mismo estado, así que ocupa otro. A medida que llenamos el átomo de electrones, estos ocuparán estados de energías más altas (menos ligados al átomo).\nAl poner muchos átomos juntos en un material, los niveles de energía se mezclan formando bandas de energía. Estas bandas pueden acomodar muchos electrones. La energía máxima ocupada por un electrón cuando llenamos el material ignorando los efectos de la temperatura se llama energía de Fermi. Las bandas de energía por encima de las de Fermi están vacías a bajas temperaturas.\nSi la energía de Fermi cae en el medio de una banda de energía, el material es un conductor. Los electrones pueden adquirir un poco de energía cinética sin salirse de la banda y así moverse por el material.\nSi la energía de Fermi cae en la separación de dos bandas, el material es un aislante. Si un electrón quiere moverse, debe adquirir un poco de energía cinética, pero no puede ya que su banda está llena. A ese electrón le queda difícil adquirir suficiente energía cinética para pasar de la última banda llena a la primera banda vacía.\n\n\n\nUn semiconductor es un aislante pero tal que la última banda llena está muy cerca de la primera banda vacía.\nNormalmente los semiconductores se dopan. Es decir, se les agrega una pequeña cantidad de átomos diferentes a los del material, pero que se encuentran cercanos en la tabla periódica.\nEsto quiere decir que esos átomos de dopaje les sobra o les falta un electrón respecto a los del material. Cuando les falta un electrón, se dice que son de tipo p, cuando les sobra uno son de tipo n.\nA continuación vemos el estado de las bandas de conducción para diferentes tipos de materiales. Cuando una banda tiene una región semillena (gris), esta puede conducir electricidad fácilmente. (Fuente: Wikipedia)\n\n\n¿Para qué sirve eso? Una aplicación sencilla son los diodos. Estos consisten en una juntura de un semiconductor tipo p con uno de tipo n. Los electrones sobrantes en el tipo n pueden viajar hacia el tipo p para llenar los huecos presentes en este. Pero si se aplica un voltaje en la dirección opuesta, no puede pasar corriente. El diodo deja pasar corriente en una sola dirección.\nTambién sirven para hacer transistores, que son las componentes fundamentales del computador.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#semiconductores",
    "href": "01_funcionamiento_cpu.html#semiconductores",
    "title": "¿Cómo funciona un computador?",
    "section": "",
    "text": "Un semiconductor es un aislante pero tal que la última banda llena está muy cerca de la primera banda vacía.\nNormalmente los semiconductores se dopan. Es decir, se les agrega una pequeña cantidad de átomos diferentes a los del material, pero que se encuentran cercanos en la tabla periódica.\nEsto quiere decir que esos átomos de dopaje les sobra o les falta un electrón respecto a los del material. Cuando les falta un electrón, se dice que son de tipo p, cuando les sobra uno son de tipo n.\nA continuación vemos el estado de las bandas de conducción para diferentes tipos de materiales. Cuando una banda tiene una región semillena (gris), esta puede conducir electricidad fácilmente. (Fuente: Wikipedia)\n\n\n¿Para qué sirve eso? Una aplicación sencilla son los diodos. Estos consisten en una juntura de un semiconductor tipo p con uno de tipo n. Los electrones sobrantes en el tipo n pueden viajar hacia el tipo p para llenar los huecos presentes en este. Pero si se aplica un voltaje en la dirección opuesta, no puede pasar corriente. El diodo deja pasar corriente en una sola dirección.\nTambién sirven para hacer transistores, que son las componentes fundamentales del computador.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#qué-es-un-transistor",
    "href": "01_funcionamiento_cpu.html#qué-es-un-transistor",
    "title": "¿Cómo funciona un computador?",
    "section": "¿Qué es un transistor?",
    "text": "¿Qué es un transistor?\nUn transistor es un componente electrónico que tiene tres “cables”. Para nuestros propósitos aquí podemos pensar en él como un switch: Cuando el voltaje en un cable supera un cierto valor (Típicamente \\(5\\,\\text{V}\\)), puede pasar corriente entre los otros dos cables.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#cómo-funciona-físicamente",
    "href": "01_funcionamiento_cpu.html#cómo-funciona-físicamente",
    "title": "¿Cómo funciona un computador?",
    "section": "¿Cómo funciona físicamente?",
    "text": "¿Cómo funciona físicamente?\nEl transistor más usado es el de efecto campo. Consiste en semiconductores de tipo n y p en la siguiente configuración:\nHay una diferencia de potencial entre el lado izquierdo y el derecho, pero la corriente no puede pasar debido al mismo efecto que en el díodo.\nPero si en el cable del medio se aplica un potencial positivo que atrae electrones, eso elimina los huecos del semiconductor tipo p y crea un canal por el cual puede fluir la corriente.\nEste es un diagrama del transistor de efecto de campo (Fuente: Wikipedia):\n\n\nEl símbolo del transistor es el siguiente (Fuente: Wikipedia)\n\n\nCuando hay voltaje en la compuerta, la corriente puede fluir entre la fuente y el drenaje.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#compuerta-and",
    "href": "01_funcionamiento_cpu.html#compuerta-and",
    "title": "¿Cómo funciona un computador?",
    "section": "Compuerta AND",
    "text": "Compuerta AND\nEste es el diagrama de la compuerta que implementa la operación booleana y (Fuente: Wikipedia)\n\n\nRepresenta la operación \\(A\\wedge B = Q\\).\nSe puede realizar mediante transistores de la siguiente manera\n\n\nFuente: http://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/trangate.html",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#compuerta-or",
    "href": "01_funcionamiento_cpu.html#compuerta-or",
    "title": "¿Cómo funciona un computador?",
    "section": "Compuerta OR",
    "text": "Compuerta OR\nEste es el diagrama de la compuerta que implementa la operación booleana o (Fuente: Wikipedia)\n\n\nRepresenta la operación \\(A\\vee B = Q\\).\nSe puede realizar mediante transistores de la siguiente manera\n\n\nFuente: http://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/trangate.html",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#compuerta-nand",
    "href": "01_funcionamiento_cpu.html#compuerta-nand",
    "title": "¿Cómo funciona un computador?",
    "section": "Compuerta NAND",
    "text": "Compuerta NAND\nEste es el diagrama de la compuerta que implementa la operación booleana no y (Fuente: Wikipedia)\n\n\nRepresenta la operación \\(\\neg(A\\wedge B) = Q\\).\nSe puede realizar mediante transistores de la siguiente manera\n\n\nFuente: http://hyperphysics.phy-astr.gsu.edu/hbase/Electronic/trangate.html\nEsta compuerta es muy importante ya que es una compuerta universal: Cualquier otra compuerta se puede construir combinando NANDs. Por ejemplo implementa la compuerta NOT mediante \\(\\neg A = \\neg(A \\wedge A)\\).",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#compuerta-xor",
    "href": "01_funcionamiento_cpu.html#compuerta-xor",
    "title": "¿Cómo funciona un computador?",
    "section": "Compuerta XOR",
    "text": "Compuerta XOR\nEste es el diagrama de la compuerta que implementa la operación booleana no exclusivo (Fuente: Wikipedia)\n\n\nRepresenta la operación \\(A \\oplus B = Q\\), que tiene la siguiente tabla de verdad\n\n\n\nA\nB\nQ\n\n\n\n\n0\n0\n0\n\n\n0\n1\n1\n\n\n1\n0\n1\n\n\n1\n1\n0\n\n\n\nComo realizarla con transistores se deja como un ejercicio opcional para el estudiante.\nEsta compuerta corresponde al uso corriente de la palabra “o” en español. Es decir, es verdad cuando uno u otro es verdad, pero no cuando ambos lo son.\nSerá importante en la siguiente sección.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#binarios",
    "href": "01_funcionamiento_cpu.html#binarios",
    "title": "¿Cómo funciona un computador?",
    "section": "Binarios",
    "text": "Binarios\nEl computador combina \\(1\\) y \\(0\\) para formar números. Es decir que usa una base binaria.\nEstamos acostumbrados a la base decimal en la cual los dígitos van de \\(0\\) a \\(9\\). Cuando llegamos a un número mayor que \\(9\\), necesitamos un nuevo dígito que representa las decenas y así sucesivamente.\nEn la base binaria, tenemos sólo los dígitos \\(0\\) y \\(1\\) que se pueden trabajar como voltajes en los circuitos que vimos arriba. Esto quiere decir que el número \\(10\\) en binario representa el número \\(2\\) en decimal. Por el contrario, el número \\(10\\) en decimal se escribe \\(1010\\) en binario.\nSe recomienda que la estudiante intente escribir por su cuenta algunos números más en base binaria.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#la-media-suma",
    "href": "01_funcionamiento_cpu.html#la-media-suma",
    "title": "¿Cómo funciona un computador?",
    "section": "La media suma",
    "text": "La media suma\nEmpezamos por el elemento más sencillo: Sumar dos números enteros positivos binarios de un solo dígito.\nPara sumar los números \\(A\\) y \\(B\\) guardamos el resultado en \\(S\\) que también tiene un solo dígito. Si el resultado tiene más de un dígito, el dígito adicional “se lleva” guardándolo en \\(C\\). De esta manera\n\n\n\nA\nB\nS\nC\n\n\n\n\n0\n0\n0\n0\n\n\n0\n1\n1\n0\n\n\n1\n0\n1\n0\n\n\n1\n1\n0\n1\n\n\n\nNote que \\(S = A\\oplus B\\) y que \\(C = A \\wedge B\\), tal que esto se puede lograr con el siguiente circuito (Fuente: Wikipedia)\n\n\nA un chip que realiza esto lo representamos mediante",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#sumador-completo",
    "href": "01_funcionamiento_cpu.html#sumador-completo",
    "title": "¿Cómo funciona un computador?",
    "section": "Sumador completo",
    "text": "Sumador completo\nAhora nos preguntamos qué pasa si estamos sumando dos dígitos binarios, pero además queremos sumar un tercero que se “lleva” de la suma de dígitos anteriores. Ahora tenemos tres binarios \\(A\\), \\(B\\), \\(C_{in}\\) con la siguiente tabla de verdad\n\n\n\n\\(A\\)\n\\(B\\)\n\\(C_{in}\\)\n\\(S\\)\n\\(C_{out}\\)\n\n\n\n\n0\n0\n0\n0\n0\n\n\n0\n0\n1\n1\n0\n\n\n0\n1\n0\n1\n0\n\n\n0\n1\n1\n0\n1\n\n\n1\n0\n0\n1\n0\n\n\n1\n0\n1\n0\n1\n\n\n1\n1\n0\n0\n1\n\n\n1\n1\n1\n1\n1\n\n\n\nUn posible circuito que lo logra es (fuente: Wikipedia)\n\n\nUn chip que realiza esto lo podemos denotar",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "01_funcionamiento_cpu.html#suma-de-varios-dígitos",
    "href": "01_funcionamiento_cpu.html#suma-de-varios-dígitos",
    "title": "¿Cómo funciona un computador?",
    "section": "Suma de varios dígitos",
    "text": "Suma de varios dígitos\nAhora podemos encadenar varios chips de estos para sumar un número de cuatro bits (cuatro dígitos binarios)\n\n\nEste es sólo un ejemplo de cómo a partir de semiconductores podemos realizar operaciones aritméticas.\nLos procesadores modernos trabajan con números de 64 bits, realizando operaciones como esta miles de millones de veces por segundo. Obviamente no usan solamente números enteros positivos, también usan números decimales (llamados de punto flotante) que estudiaremos en un par de clases.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Funcionamiento de la CPU"
    ]
  },
  {
    "objectID": "20_edo_alto_orden_estabilidad.html",
    "href": "20_edo_alto_orden_estabilidad.html",
    "title": "EDOs - EDOs de alto orden, estabilidad",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Ecuaciones de alto orden y estabilidad"
    ]
  },
  {
    "objectID": "20_edo_alto_orden_estabilidad.html#tarea-10.1",
    "href": "20_edo_alto_orden_estabilidad.html#tarea-10.1",
    "title": "EDOs - EDOs de alto orden, estabilidad",
    "section": "Tarea 10.1",
    "text": "Tarea 10.1\nEstudiemos el péndulo rígido. Sabemos que la aceleración actúa en la componente vertical de la velocidad y que además debe satisfacer la ecuación de ligadura que el radio del movimiento sea constante. Esto lleva a la siguiente ecuación diferencial\n\\[\n\\frac{d^2\\theta}{dt^2} = -\\frac{g}{L}\\sin\\theta\n\\]\ndonde \\(g = 9.81\\,\\text{m}/\\text{s}^2\\) es la aceleración de la gravedad y \\(L = 1\\,\\text{m}\\) es la longitud del péndulo.\nGrafique la solución a esta ecuación tomando \\(\\theta'(0) = 0\\) para \\(\\theta(0) = 0.1\\), \\(\\theta(0) = 1\\), \\(\\theta(0) = 3\\) entre \\(0\\,\\text{s} \\leq t \\leq 6\\,\\text{s}\\). Compare con el caso de pequeñas oscilaciones (\\(\\sin\\theta \\approx \\theta\\)).",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Ecuaciones de alto orden y estabilidad"
    ]
  },
  {
    "objectID": "20_edo_alto_orden_estabilidad.html#tarea-10.2",
    "href": "20_edo_alto_orden_estabilidad.html#tarea-10.2",
    "title": "EDOs - EDOs de alto orden, estabilidad",
    "section": "Tarea 10.2",
    "text": "Tarea 10.2\nImplemente un código para resolver una ecuación de orden \\(n\\) usando el método de Runge-Kutta de orden 4.\n\\[\ny^{(n)}(t) = f(t, y, y',...,y^{(n-1)})\\,,\n\\]\nEste código debería recibir una función \\(f(t, y, y', ..., y^{(n-1)})\\), los valores inical \\(a\\) y final \\(b\\) del parámetro \\(t\\), junto con un arreglo de condiciones iniciales \\((y(a),...,y^{(n-1)}(a))\\) y el número de pasos. El código debe dar la solución \\(y(t_i)\\).\nPara probar que funciona, resuelva la siguiente ecuación diferencial\n\\[\ny'' - 2y' + y = te^t - t\\,,\\quad 0\\leq t\\leq 1\\,,\\quad y(0) = y'(0) = 0\\,.\n\\]\nEsta tiene solución analítica \\(y(t) = (1/6)t^3e^t - te^t + 2e^t - t - 2\\).",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Ecuaciones de alto orden y estabilidad"
    ]
  },
  {
    "objectID": "20_edo_alto_orden_estabilidad.html#tarea-10.3",
    "href": "20_edo_alto_orden_estabilidad.html#tarea-10.3",
    "title": "EDOs - EDOs de alto orden, estabilidad",
    "section": "Tarea 10.3",
    "text": "Tarea 10.3\nAsí como implementamos el método de Runge Kutta de orden 4 para resolver sistemas de ecuaciones diferenciales, implemente el método de Runge Kutta Fehlberg para esos sistemas de ecuaciones.\nNote que para modificar el tamaño del paso es necesario exigir que todas las soluciones alcancen la tolerancia pedida.\nPara probar su código, resuelva el siguiente problema de valor inicial:\n\\[\\begin{align}\ny_1'(t) &= -4y_1 - 2y_2 + \\cos t + 4 \\sin t\\,,\\\\\ny_2'(t) &= 3y_1 + y_2 - 3\\sin t\\,,\n\\end{align}\\]\npara \\(0 \\leq t \\leq 2\\) con condiciones iniciales\n\\[\ny_1(0) = 0\\,,\\quad y_2(t) = -1\\,.\n\\]\nEste sistema tiene soluciones analíticas\n\\[\\begin{align}\nu_1(t) &= 2e^{-t} - 2e^{-2t} + \\sin t\\,,\\\\\nu_2(t) &= -3e^{-t} + 2e^{-2t}\\,.\n\\end{align}\\]",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Ecuaciones de alto orden y estabilidad"
    ]
  },
  {
    "objectID": "20_edo_alto_orden_estabilidad.html#tarea-10.4",
    "href": "20_edo_alto_orden_estabilidad.html#tarea-10.4",
    "title": "EDOs - EDOs de alto orden, estabilidad",
    "section": "Tarea 10.4",
    "text": "Tarea 10.4\nEscriba un código que implemente el algoritmo de diferencias hacia atrás\n\\[\ny_{i+1} - \\frac{18}{11}y_{i} + \\frac{9}{11}y_{i-1} - \\frac{2}{11}y_{i-2} = \\frac{6}{11}hf(t_{i+1}, y_{i+1})\n\\]\ncomo este es un método implícito, es necesario implementar un método de Newton similar a lo hecho para la regla del trapecio.\nAplique este algoritmo a la solución del problema visto en clase:\n\ndef f(t, y):\n    return 5*np.exp(5*t)*(y - t)**2 - 1\n\ndef df(t, y):\n    return 10*np.exp(5*t)*(y - t)\n\na = 0\nb = 1\nyo = -1\n\ndef exacta(t):\n    return t - np.exp(-5*t)",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Ecuaciones de alto orden y estabilidad"
    ]
  },
  {
    "objectID": "20_edo_alto_orden_estabilidad.html#tarea-10.5",
    "href": "20_edo_alto_orden_estabilidad.html#tarea-10.5",
    "title": "EDOs - EDOs de alto orden, estabilidad",
    "section": "Tarea 10.5",
    "text": "Tarea 10.5\nGrafique la solución numérica a la siguiente ecuación diferencial, usando menos de 100 pasos\n\\[\ny' = -30(y + y^2) + \\sin(t/2)\\,,\\quad 0\\leq t \\leq 20\\,,\\quad y(0) = 0\\,.\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Ecuaciones de alto orden y estabilidad"
    ]
  },
  {
    "objectID": "17_metodos_de_taylor.html",
    "href": "17_metodos_de_taylor.html",
    "title": "Ecuaciones diferenciales, método de Taylor",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nUna de las principales aplicaciones de los métodos numéricos a la física es la solución de ecuaciones diferenciales. Por ahora nos reduciremos al caso de ecuaciones diferenciales del primer orden. El caso de ecuaciones de orden más alto se reduce al de un sistema de ecuaciones de primer orden y lo veremos más adelante.\nEn la práctica incluso las ecuaciones diferenciales que queremos resolver son una aproximación al problema físico que tratamos, por este motivo requerimos que pequeños cambios en la formulación de la ecuación no cambien mucho la solución, es decir:\nUn problema de valor inicial \\(y'(t) = f(t, y)\\) con \\(a \\leq t \\leq b\\) y \\(y(a) = y_o\\) está bien puesto si\nNos interesarán ecuaciones diferenciales definidas en el conjunto \\(a \\leq t \\leq b\\) y \\(-\\infty &lt; y &lt; \\infty\\). En estos casos el problema está bien puestot si \\(f\\) es continua y en este conjunto\n\\[\n|f(t, y_1) - f(t, y_2)| \\leq L|y_1 - y_2|\n\\]\npara alguna constante \\(L\\) (esta se llama condición de Lipfschitz). Se puede demosttrar que esta condición se cumple si se tiene\n\\[\n\\left|\\frac{\\partial f}{\\partial y}(t, y)\\right| \\leq L\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Taylor"
    ]
  },
  {
    "objectID": "17_metodos_de_taylor.html#tarea-8.6",
    "href": "17_metodos_de_taylor.html#tarea-8.6",
    "title": "Ecuaciones diferenciales, método de Taylor",
    "section": "Tarea 8.6",
    "text": "Tarea 8.6\nModifique el código del método de Taylor de segundo orden de solución de ecuaciones diferenciales para que la función que resuelve la ecuación diferencial regrese una función interpolante de Hermite (en vez de regresar una lista de puntos).\nEs decir, la función taylor2 debe dar como resultado otra función que al evaluarla en un tiempo \\(t\\) nos da el polinomio interpolante evaluado a ese tiempo.\nPruebe su código con algún ejemplo.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Taylor"
    ]
  },
  {
    "objectID": "17_metodos_de_taylor.html#tarea-8.7",
    "href": "17_metodos_de_taylor.html#tarea-8.7",
    "title": "Ecuaciones diferenciales, método de Taylor",
    "section": "Tarea 8.7",
    "text": "Tarea 8.7\nConsidere la ecuación diferencial que se ha resuelto en los ejemplos de clase:\n\\[\ny'(t) = y(t) - t^2 + 1\\,,\\quad 0 \\leq t \\leq 2\\,,\n\\]\npero ahora con una condición inicial\n\\[\ny(0) = 0.5 + \\delta_o\n\\]\ndonde \\(\\delta_o\\) es un error cometido al fijar la condición.\n\nResuelva esta ecuación usando el método de Euler con una precisión de \\(10^{-4}\\). Considere varios valores de \\(\\delta_o\\) entre \\(-0.1\\) y \\(0.1\\) y grafique \\(y(2)\\) en función de \\(\\delta_o\\).\nCompare su resultado con el valor de \\(y(2)\\) obtenido de la solución analítica \\(y(t) = (t + 1)^2 - 0.5e^t\\). Comente.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Taylor"
    ]
  },
  {
    "objectID": "17_metodos_de_taylor.html#tarea-8.8",
    "href": "17_metodos_de_taylor.html#tarea-8.8",
    "title": "Ecuaciones diferenciales, método de Taylor",
    "section": "Tarea 8.8",
    "text": "Tarea 8.8\nResuelva el siguiente problema de valor inicial usando el método de Euler y los métodos de Taylor de orden 2 y 3\n\\[\ny'(t) = \\frac{\\cos(t)}{\\sin(y(t))}\\,,\\quad y(0) = 1\\,,\\quad 0 \\leq t \\leq 1\n\\]\nResuelva la ecuación analíticamente y grafique en función de \\(h\\) el error cometido con los tres métodos para \\(t = 1\\). ¿Es compatible con lo esperado? ¿Por qué?",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Taylor"
    ]
  },
  {
    "objectID": "17_metodos_de_taylor.html#tarea-8.9",
    "href": "17_metodos_de_taylor.html#tarea-8.9",
    "title": "Ecuaciones diferenciales, método de Taylor",
    "section": "Tarea 8.9",
    "text": "Tarea 8.9\nEjercicio 5.3.12 libro de Burden\nUn proyectil con masa \\(m = 0.11\\) kg se dispara verticalmente hacia arriba con una velocidad inicial \\(v(0) = 8\\) m/s y sufre una desaceleración debida a la fuerza de la gravedad \\(F = -mg\\) y a la resistencia del aire \\(F = -kv|v|\\), donde \\(g = 9.8\\) m/s^2 y \\(k = 0.002\\) kg/m.\n\nEncuentre la velocidad a \\(t = 0.1, 0.2, ..., 1.0\\) segundos.\nEncuentre a la primera cifra decimal el tiempo al cual el proyectil alcanza su máxima altura y vuelve a empezar a caer.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Taylor"
    ]
  },
  {
    "objectID": "17_metodos_de_taylor.html#tarea-8.10",
    "href": "17_metodos_de_taylor.html#tarea-8.10",
    "title": "Ecuaciones diferenciales, método de Taylor",
    "section": "Tarea 8.10",
    "text": "Tarea 8.10\nEjercicio 5.2.12 libro de Burden\nConsidere el problema de valor inicial\n\\[\ny'(t) = -10y\\,,\\quad 0\\leq t\\leq 2\\,,\\quad y(0) = 1\n\\]\nque tiene solución \\(y(t) = e^{-10t}\\).¿Qué ocurre cuando el método de Euler se aplica a este problema con \\(h = 0.1\\)? ¿Viola la fórmula del error del método?",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Taylor"
    ]
  },
  {
    "objectID": "02_python.html",
    "href": "02_python.html",
    "title": "Repaso de Python",
    "section": "",
    "text": "print(\"Normalmente uno escribe: Hola, Mundo!\")\n\nNormalmente uno escribe: Hola, Mundo!\n\n\n\n2 + 3\n\n5\n\n\n\n2 * 3\n\n6\n\n\n\n2/3\n\n0.6666666666666666\n\n\n\n2-3\n\n-1\n\n\n\n2//3\n\n0\n\n\n\n2%3\n\n2\n\n\n\n2**3\n\n8\n\n\n\n\n\n\ntype(\"Normalmente uno escribe: Hola, Mundo!\")\n\nstr\n\n\n\ntype(2)\n\nint\n\n\n\ntype(3.1)\n\nfloat\n\n\n\n\n\n\nmensaje = 'Normalmente uno escribe: Hola, Mundo!'\n\n\nmensaje\n\n'Normalmente uno escribe: Hola, Mundo!'\n\n\n\nn = 17\n\n\nn\n\n17\n\n\n\ncasi_pi = 3.1416\n\n\n\n\n\ncasi_pi + n\n\n20.1416\n\n\n\nprint(n)\n\n17\n\n\n\n\n\nEn Python los operadores tienen jerarquía: - Exponenciación - Multiplicación y división - Suma y resta Primero se evalúan los de mayor jerarquía. Cuando hay dos iguales se evalúa de izquierda a derecha.\nCuando haya dudas, usar paréntesis, por ejemplo \\(2(3 - 1) = 4\\)\n\n2*(3 - 1)\n\n4\n\n\nLo siguiente es \\(1 + 2^3 = 9\\), muy distinto de \\((1 + 2)^3 = 27\\)\n\n1 + 2**3\n\n9\n\n\nEsto es \\(2\\times 3^2 = 18\\) muy distinto de \\((2\\times 3)^2 = 36\\)\n\n2*3**2\n\n18\n\n\n\n2*3 - 1\n\n5\n\n\n\n6 + 4/2\n\n8.0\n\n\n¡Cuidado! Si quiero escribir \\(4/(2\\times 2) = 1\\) no lo puedo hacer de esta manera.\n\n4/2*2\n\n4.0\n\n\n\n4/2/2\n\n1.0\n\n\n\n4/(2*2)\n\n1.0\n\n\n\n\n\n\n# Este código no hace nada, es puro comentario\n\n\n# Este código hace algo muy básico. Convierto mi pc en una calculadora cara\n2 + 3\n\n5\n\n\n\n\n\nError de sintaxis\n\n2 +\n\n\n  Cell In[29], line 1\n    2 +\n       ^\nSyntaxError: invalid syntax\n\n\n\n\nOtros tipos de errores\n\nprint(2/0)\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[30], line 1\n----&gt; 1 print(2/0)\n\nZeroDivisionError: division by zero\n\n\n\n\nfor i in j:\n    print(i)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[31], line 1\n----&gt; 1 for i in j:\n      2     print(i)\n\nNameError: name 'j' is not defined\n\n\n\n\ndef mistake(n):\n    for i in range(n):\n        print(10/i)\n\n\nmistake(10)\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[33], line 1\n----&gt; 1 mistake(10)\n\nCell In[32], line 3, in mistake(n)\n      1 def mistake(n):\n      2     for i in range(n):\n----&gt; 3         print(10/i)\n\nZeroDivisionError: division by zero",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#mi-primer-código",
    "href": "02_python.html#mi-primer-código",
    "title": "Repaso de Python",
    "section": "",
    "text": "print(\"Normalmente uno escribe: Hola, Mundo!\")\n\nNormalmente uno escribe: Hola, Mundo!\n\n\n\n2 + 3\n\n5\n\n\n\n2 * 3\n\n6\n\n\n\n2/3\n\n0.6666666666666666\n\n\n\n2-3\n\n-1\n\n\n\n2//3\n\n0\n\n\n\n2%3\n\n2\n\n\n\n2**3\n\n8",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#tipos-de-valores",
    "href": "02_python.html#tipos-de-valores",
    "title": "Repaso de Python",
    "section": "",
    "text": "type(\"Normalmente uno escribe: Hola, Mundo!\")\n\nstr\n\n\n\ntype(2)\n\nint\n\n\n\ntype(3.1)\n\nfloat",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#variables-y-asignación",
    "href": "02_python.html#variables-y-asignación",
    "title": "Repaso de Python",
    "section": "",
    "text": "mensaje = 'Normalmente uno escribe: Hola, Mundo!'\n\n\nmensaje\n\n'Normalmente uno escribe: Hola, Mundo!'\n\n\n\nn = 17\n\n\nn\n\n17\n\n\n\ncasi_pi = 3.1416",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#expresiones",
    "href": "02_python.html#expresiones",
    "title": "Repaso de Python",
    "section": "",
    "text": "casi_pi + n\n\n20.1416\n\n\n\nprint(n)\n\n17",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#orden-de-operaciones",
    "href": "02_python.html#orden-de-operaciones",
    "title": "Repaso de Python",
    "section": "",
    "text": "En Python los operadores tienen jerarquía: - Exponenciación - Multiplicación y división - Suma y resta Primero se evalúan los de mayor jerarquía. Cuando hay dos iguales se evalúa de izquierda a derecha.\nCuando haya dudas, usar paréntesis, por ejemplo \\(2(3 - 1) = 4\\)\n\n2*(3 - 1)\n\n4\n\n\nLo siguiente es \\(1 + 2^3 = 9\\), muy distinto de \\((1 + 2)^3 = 27\\)\n\n1 + 2**3\n\n9\n\n\nEsto es \\(2\\times 3^2 = 18\\) muy distinto de \\((2\\times 3)^2 = 36\\)\n\n2*3**2\n\n18\n\n\n\n2*3 - 1\n\n5\n\n\n\n6 + 4/2\n\n8.0\n\n\n¡Cuidado! Si quiero escribir \\(4/(2\\times 2) = 1\\) no lo puedo hacer de esta manera.\n\n4/2*2\n\n4.0\n\n\n\n4/2/2\n\n1.0\n\n\n\n4/(2*2)\n\n1.0",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#comentarios",
    "href": "02_python.html#comentarios",
    "title": "Repaso de Python",
    "section": "",
    "text": "# Este código no hace nada, es puro comentario\n\n\n# Este código hace algo muy básico. Convierto mi pc en una calculadora cara\n2 + 3\n\n5",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#errores-y-excepciones",
    "href": "02_python.html#errores-y-excepciones",
    "title": "Repaso de Python",
    "section": "",
    "text": "Error de sintaxis\n\n2 +\n\n\n  Cell In[29], line 1\n    2 +\n       ^\nSyntaxError: invalid syntax\n\n\n\n\nOtros tipos de errores\n\nprint(2/0)\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[30], line 1\n----&gt; 1 print(2/0)\n\nZeroDivisionError: division by zero\n\n\n\n\nfor i in j:\n    print(i)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[31], line 1\n----&gt; 1 for i in j:\n      2     print(i)\n\nNameError: name 'j' is not defined\n\n\n\n\ndef mistake(n):\n    for i in range(n):\n        print(10/i)\n\n\nmistake(10)\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[33], line 1\n----&gt; 1 mistake(10)\n\nCell In[32], line 3, in mistake(n)\n      1 def mistake(n):\n      2     for i in range(n):\n----&gt; 3         print(10/i)\n\nZeroDivisionError: division by zero",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#obtener-y-modificar-elementos",
    "href": "02_python.html#obtener-y-modificar-elementos",
    "title": "Repaso de Python",
    "section": "Obtener y modificar elementos",
    "text": "Obtener y modificar elementos\n\nejemplo[0]\n\n'Pedro'\n\n\n\nejemplo[-1]\n\n['hola', 1.12]\n\n\nCuidado, lo siguiente muestra el tercer elemento, no el segundo\n\nejemplo[2]\n\n['hola', 1.12]\n\n\n\nejemplo[1] = 'adiós'\n\n\nejemplo\n\n['Pedro', 'adiós', ['hola', 1.12]]\n\n\n\nejemplo[3]\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[72], line 1\n----&gt; 1 ejemplo[3]\n\nIndexError: list index out of range",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#atravesar-la-lista",
    "href": "02_python.html#atravesar-la-lista",
    "title": "Repaso de Python",
    "section": "Atravesar la lista",
    "text": "Atravesar la lista\n\nfor element in ejemplo:\n    print(element)\n\nPedro\nadiós\n['hola', 1.12]\n\n\n\nnumeros = [12,13,15,22,23]\n\n\nfor i in range(len(numeros)):\n    numeros[i] = numeros[i] + 1\n\n\nnumeros\n\n[13, 14, 16, 23, 24]",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#operaciones",
    "href": "02_python.html#operaciones",
    "title": "Repaso de Python",
    "section": "Operaciones",
    "text": "Operaciones\n\nnumeros2 = [1,2,3,4,5]\n\n\nnumeros3 = numeros + numeros2\n\n\nnumeros3\n\n[13, 14, 16, 23, 24, 1, 2, 3, 4, 5]\n\n\n\n[0,1]*4\n\n[0, 1, 0, 1, 0, 1, 0, 1]\n\n\n\nnumeros2.append(1)\n\n\nnumeros2\n\n[1, 2, 3, 4, 5, 1]\n\n\n\nnumeros2.extend([1,2])\n\n\nnumeros2\n\n[1, 2, 3, 4, 5, 1, 1, 2]\n\n\n\nsum(numeros2)\n\n19\n\n\n\ndel numeros2[1]\n\n\nnumeros2\n\n[1, 3, 4, 5, 1, 1, 2]",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#tajadas",
    "href": "02_python.html#tajadas",
    "title": "Repaso de Python",
    "section": "Tajadas",
    "text": "Tajadas\n\nnumeros3[1:2]\n\n[14]\n\n\n\nnumeros3[1:4]\n\n[14, 16, 23]\n\n\n\nnumeros3[1:]\n\n[14, 16, 23, 24, 1, 2, 3, 4, 5]\n\n\n\nnumeros3[:-2]\n\n[13, 14, 16, 23, 24, 1, 2, 3]\n\n\n\nnumeros3[:]\n\n[13, 14, 16, 23, 24, 1, 2, 3, 4, 5]",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#tarea-1.1",
    "href": "02_python.html#tarea-1.1",
    "title": "Repaso de Python",
    "section": "Tarea 1.1",
    "text": "Tarea 1.1\nUse Python como una calculadora para calcular cuál es la velocidad inicial de una bola que cae una distancia de \\(2\\) metros en \\(0.3\\) segundos.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#tarea-1.2",
    "href": "02_python.html#tarea-1.2",
    "title": "Repaso de Python",
    "section": "Tarea 1.2",
    "text": "Tarea 1.2\nEscriba un código que produzca el siguiente texto:\n1\n11  \n111  \n1111  \n11111  \n111111  \n1111111  \n11111111  \n111111111  \n1111111111  \n(El código no puede tener más de 4 líneas y un enunciado “print”). Puede usar el siguiente truco:\n\nprint(4*\"1\")\n\n1111",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#tarea-1.3",
    "href": "02_python.html#tarea-1.3",
    "title": "Repaso de Python",
    "section": "Tarea 1.3",
    "text": "Tarea 1.3\nEscriba un código que sea un loop infinito. En cada paso el código le pide al usuario que escriba algo y cuando el usuario escribe “salir” el código termina. Si el usuario escribe otra cosa el código no hace nada y sencillamente vuelve a pedirde al usuario que escriba algo. Para obtener la entrada del usuario use input('Escriba \"salir\" para salir: '). Para terminar el loop use break.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#tarea-1.4",
    "href": "02_python.html#tarea-1.4",
    "title": "Repaso de Python",
    "section": "Tarea 1.4",
    "text": "Tarea 1.4\nEscriba un código que haga la siguiente sumatoria:\n\\[\n\\sum_{n=0}^{100} \\sum_{m=0}^{n} \\left(0.3^n\\right)^m\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "02_python.html#tarea-1.5",
    "href": "02_python.html#tarea-1.5",
    "title": "Repaso de Python",
    "section": "Tarea 1.5",
    "text": "Tarea 1.5\nEscriba un código que calcule el número de Euler con un error menor que 0.01 usando la expresión\n\\[\ne = \\sum_{n = 0}^\\infty \\frac{1}{n!}\\,.\n\\]\nPara calcular el error, puede comparar con la función math.exp(1). Para calcular el factorial de n, puede usar la función math.factorial(n). Para calcular el valor absoluto (puede ser necesario al calcular el error) use abs(x). Estas funciones estarán disponibles luego de ejecutar la siguiente línea.\n\nimport math",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de Python"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html",
    "href": "03_numpy_arrays.html",
    "title": "Repaso de numpy y otros",
    "section": "",
    "text": "Los arreglos son mucho más rápidos para cálculos numéricos ya que son un bloque continuo en memoria. Son similares a los arreglos en lenguajes como C.\n\nimport numpy as np\n\n\nmi_arreglo = np.array([1,2,3])\n\n\nmi_arreglo[1] = 5\n\n\nmi_arreglo\n\narray([1, 5, 3])\n\n\nLos arreglos sólo pueden contener datos de un tipo de datos. Cuando se mezclan tipos, Python hará lo mejor que pueda para convertirlos a un úunico tipo.\n\nnp.array([1,'hola'])\n\narray(['1', 'hola'], dtype='&lt;U21')\n\n\nPodemos hacer arreglos bidimensionales (matrices), tridimensionales, etc\n\nnp.array([[1,1],[1,1]])\n\narray([[1, 1],\n       [1, 1]])\n\n\nLos arreglos no pueden contener elementos de dimensiones diferentes\n\nnp.array([1,'hola',[2,'adios']])\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 np.array([1,'hola',[2,'adios']])\n\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n\n\n\n\n\n\nnp.ones([3,4])\n\narray([[1., 1., 1., 1.],\n       [1., 1., 1., 1.],\n       [1., 1., 1., 1.]])\n\n\n\nnp.zeros((2,3,4))\n\narray([[[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]]])\n\n\n\nnp.full((3,2),3, dtype=np.float128)\n\narray([[3., 3.],\n       [3., 3.],\n       [3., 3.]], dtype=float128)\n\n\n\nnp.arange(10,25,5)\n\narray([10, 15, 20])\n\n\n\nmi_arreglo2 = np.linspace(0,2,9)\n\n\nmi_arreglo2\n\narray([0.  , 0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  ])\n\n\n\n\n\n\nmi_arreglo2.ndim\n\n1\n\n\n\nnp.full((3,2),3, dtype=np.float128).size\n\n6\n\n\n\nmi_arreglo2.data\n\n&lt;memory at 0x73538801a8c0&gt;\n\n\n\nmi_arreglo2.shape\n\n(9,)\n\n\n\nmi_arreglo2.dtype\n\ndtype('float64')\n\n\n\nmi_arreglo2.nbytes\n\n72\n\n\n\nmi_arreglo2.astype(np.float16)\n\narray([0.  , 0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  ],\n      dtype=float16)\n\n\n\nmi_arreglo2.astype(np.float16).nbytes\n\n18\n\n\n\n\n\n\nmi_arreglo\n\narray([1, 5, 3])\n\n\n\nmi_arreglo3 =  mi_arreglo + 1\n\n\nmi_arreglo3\n\narray([2, 6, 4])\n\n\n\nmi_arreglo + mi_arreglo3\n\narray([ 3, 11,  7])\n\n\n\nmi_arreglo3/mi_arreglo\n\narray([2.        , 1.2       , 1.33333333])\n\n\n\nmi_arreglo3 == mi_arreglo\n\narray([False, False, False])\n\n\nSe pueden usar los operadores +, -, *, /, %, **, ==, !=, &gt;, &lt;, &gt;=, &lt;=\n\nmi_arreglo3.max()\n\nnp.int64(6)\n\n\n\nmi_arreglo3.min()\n\nnp.int64(2)\n\n\n\n\n\n\nmi_arreglo_2d = np.array([[1,2,3],[4,5,6],[7,8,9]])\n\n\nmi_arreglo_2d\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\n\nmi_arreglo_2d[1:2]\n\narray([[4, 5, 6]])\n\n\n\nmi_arreglo_2d[1:]\n\narray([[4, 5, 6],\n       [7, 8, 9]])\n\n\n\nmi_arreglo_2d[1,1]\n\nnp.int64(5)\n\n\n¿Cuál es la diferencia? El siguiente código primero toma todas las filas desde la segunda (índice 1), luego toma la segunda de esas listas.\n\nmi_arreglo_2d[1:][1]\n\narray([7, 8, 9])\n\n\nPor otra parte, el siguiente código toma el primer elemento de cada una de esas listas.\n\nmi_arreglo_2d[1:,1]\n\narray([5, 8])\n\n\n\nmi_arreglo_2d[1:,:-1]\n\narray([[4, 5],\n       [7, 8]])\n\n\n\nmi_arreglo\n\narray([1, 5, 3])\n\n\n\nmi_arreglo[mi_arreglo&lt;=3]\n\narray([1, 3])\n\n\n\nmenor_que_3 = mi_arreglo &lt; 3\n\n\nmenor_que_3\n\narray([ True, False, False])\n\n\n\nmi_arreglo[menor_que_3]\n\narray([1])",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#llenar-arreglos-automáticamente",
    "href": "03_numpy_arrays.html#llenar-arreglos-automáticamente",
    "title": "Repaso de numpy y otros",
    "section": "",
    "text": "np.ones([3,4])\n\narray([[1., 1., 1., 1.],\n       [1., 1., 1., 1.],\n       [1., 1., 1., 1.]])\n\n\n\nnp.zeros((2,3,4))\n\narray([[[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]]])\n\n\n\nnp.full((3,2),3, dtype=np.float128)\n\narray([[3., 3.],\n       [3., 3.],\n       [3., 3.]], dtype=float128)\n\n\n\nnp.arange(10,25,5)\n\narray([10, 15, 20])\n\n\n\nmi_arreglo2 = np.linspace(0,2,9)\n\n\nmi_arreglo2\n\narray([0.  , 0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  ])",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#inspeccionar-arreglos",
    "href": "03_numpy_arrays.html#inspeccionar-arreglos",
    "title": "Repaso de numpy y otros",
    "section": "",
    "text": "mi_arreglo2.ndim\n\n1\n\n\n\nnp.full((3,2),3, dtype=np.float128).size\n\n6\n\n\n\nmi_arreglo2.data\n\n&lt;memory at 0x73538801a8c0&gt;\n\n\n\nmi_arreglo2.shape\n\n(9,)\n\n\n\nmi_arreglo2.dtype\n\ndtype('float64')\n\n\n\nmi_arreglo2.nbytes\n\n72\n\n\n\nmi_arreglo2.astype(np.float16)\n\narray([0.  , 0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  ],\n      dtype=float16)\n\n\n\nmi_arreglo2.astype(np.float16).nbytes\n\n18",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#aritmética-de-arreglos",
    "href": "03_numpy_arrays.html#aritmética-de-arreglos",
    "title": "Repaso de numpy y otros",
    "section": "",
    "text": "mi_arreglo\n\narray([1, 5, 3])\n\n\n\nmi_arreglo3 =  mi_arreglo + 1\n\n\nmi_arreglo3\n\narray([2, 6, 4])\n\n\n\nmi_arreglo + mi_arreglo3\n\narray([ 3, 11,  7])\n\n\n\nmi_arreglo3/mi_arreglo\n\narray([2.        , 1.2       , 1.33333333])\n\n\n\nmi_arreglo3 == mi_arreglo\n\narray([False, False, False])\n\n\nSe pueden usar los operadores +, -, *, /, %, **, ==, !=, &gt;, &lt;, &gt;=, &lt;=\n\nmi_arreglo3.max()\n\nnp.int64(6)\n\n\n\nmi_arreglo3.min()\n\nnp.int64(2)",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#tajadas-de-arreglos",
    "href": "03_numpy_arrays.html#tajadas-de-arreglos",
    "title": "Repaso de numpy y otros",
    "section": "",
    "text": "mi_arreglo_2d = np.array([[1,2,3],[4,5,6],[7,8,9]])\n\n\nmi_arreglo_2d\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\n\nmi_arreglo_2d[1:2]\n\narray([[4, 5, 6]])\n\n\n\nmi_arreglo_2d[1:]\n\narray([[4, 5, 6],\n       [7, 8, 9]])\n\n\n\nmi_arreglo_2d[1,1]\n\nnp.int64(5)\n\n\n¿Cuál es la diferencia? El siguiente código primero toma todas las filas desde la segunda (índice 1), luego toma la segunda de esas listas.\n\nmi_arreglo_2d[1:][1]\n\narray([7, 8, 9])\n\n\nPor otra parte, el siguiente código toma el primer elemento de cada una de esas listas.\n\nmi_arreglo_2d[1:,1]\n\narray([5, 8])\n\n\n\nmi_arreglo_2d[1:,:-1]\n\narray([[4, 5],\n       [7, 8]])\n\n\n\nmi_arreglo\n\narray([1, 5, 3])\n\n\n\nmi_arreglo[mi_arreglo&lt;=3]\n\narray([1, 3])\n\n\n\nmenor_que_3 = mi_arreglo &lt; 3\n\n\nmenor_que_3\n\narray([ True, False, False])\n\n\n\nmi_arreglo[menor_que_3]\n\narray([1])",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#preparar-los-datos",
    "href": "03_numpy_arrays.html#preparar-los-datos",
    "title": "Repaso de numpy y otros",
    "section": "Preparar los datos",
    "text": "Preparar los datos\nPara graficar necesitamos una tabla de datos. Estos pueden ser de dos tipos:\n\nResultados de la evaluación de una función (como en el ejemplo anterior).\nDatos de una simulación o una medición experimental.\n\n\n# Preparamos los datos\nx = np.linspace(-1,1,100)\ny1 = np.arccos(x)\ny2 = np.arcsin(x)\n\n\n# Producimos el gráfico \nplt.plot(x, y1, label=r'$\\cos^{-1}(x)$')\nplt.plot(x, y2, label=r'$\\sin^{-1}(x)$')\n\n# Para diferenciar los dos gráficos podemos incluir una leyenda\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\nNormalmente los datos de un experimento o simulación están guardados en un archivo. Hablaremos de cómo manejar archivos más adelante. Por ahora ponemos a mano algunos datos (que son el resultado de una simulación de ciertas propiedades estadísticas de la distribución de materia a gran escala en el universo).\n\ndatos = np.array(\n    [[0.00314159, 3.0318397997408217, 0.4566634429053162], \n    [0.00628318, 2.7707221181056867, 0.17510327334847328], \n    [0.00942477, 2.6792094345075723, 0.14418474960362074], \n    [0.01256636, 2.8629530955402314, 0.0799879332308988], \n    [0.015707950000000002, 2.6228671669898738, 0.04669866360637852], \n    [0.01884954, 2.544881594794191, 0.032079885722964156], \n    [0.02199113, 2.457245781452802, 0.045660793878032256], \n    [0.02513272, 2.418177998205174, 0.041336657066345844], \n    [0.02827431, 2.358376185696977, 0.03448018004161942], \n    [0.031415900000000004, 2.346427014273152, 0.0331860259716874], \n    [0.03455749, 2.339197080901526, 0.02361983589273171], \n    [0.03769908, 2.2761885850394745, 0.026495927143311844], \n    [0.04084067, 2.2553242344026168, 0.021181457699213722], \n    [0.04398226, 2.218805385557498, 0.01764832127890884], \n    [0.04712385, 2.1968751769225405, 0.02084889785594682], \n    [0.05026544, 2.183116404353682, 0.0229514467313476], \n    [0.05340703, 2.149455000853029, 0.012785355627588396], \n    [0.05654862, 2.122002117746843, 0.017161461769528517], \n    [0.05969021, 2.0863880826499894, 0.013943154873837437]])\n\nEsto es el resultado de simular una cierta función \\(f(q)\\) donde \\(q\\) es la primera columna, \\(f\\) es la segunda columna y el error está en la tercera columna. Queremos solamente graficar f como función de q.\n\nq = datos[:,0]\nf = datos[:,1]\n\n\nplt.plot(q,f, label='$f(q)$')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nEstas son las notas (normalizadas entre 0 y 100) de un conjunto de estudiantes de licenciatura en física de una universidad norteamericana. El primer número es la nota en un curso de mecánica clásica, la segunda la nota en un curso de mecánica cuántica y la tercera es la nota de un curso de experimentación avanzada.\n\nnotas = np.array(\n[[100, 100, 93.0],\n [53.0, 60.0, 37.0],\n [42.0, 35.0, 89.0],\n [57.0, 54.0, 37.0],\n [77.0, 66.0, 53.0],\n [23.0, 26.0, 55.0],\n [97.0, 78.0, 68.0],\n [65.0, 45.0, 69.0],\n [74.0, 74.0, 84.0],\n [39.0, 44.0, 78.0],\n [95.0, 94.0, 25.0],\n [95.0, 74.0, 60.0],\n [77.0, 67.0, 17.0],\n [52.0, 47.0, 49.0],\n [66.0, 52.0, 27.0],\n [74.0, 63.0, 47.0],\n [79.0, 59.0, 13.0],\n [60.0, 40.0, 92.0],\n [80.0, 69.0, 36.0],\n [74.0, 44.0, 82.0],\n [100, 77.0, 7.0],\n [30.0, 23.0, 14.0],\n [96.0, 78.0, 57.0],\n [60.0, 81.0, 2.0],\n [57.0, 60.0, 29.0],\n [72.0, 88.0, 25.0],\n [44.0, 48.0, 58.0],\n [57.0, 53.0, 89.0],\n [58.0, 66.0, 31.0],\n [54.0, 48.0, 27.0],\n [58.0, 39.0, 86.0],\n [62.0, 55.0, 67.0],\n [54.0, 54.0, 66.0],\n [74.0, 70.0, 89.0],\n [60.0, 73.0, 39.0],\n [58.0, 74.0, 81.0],\n [50.0, 67.0, 52.0],\n [55.0, 50.0, 60.0],\n [91.0, 89.0, 70.0],\n [50.0, 55.0, 100],\n [47.0, 83.0, 51.0],\n [100, 100, 32.0],\n [53.0, 59.0, 72.0],\n [7.0, 39.0, 95.0],\n [73.0, 68.0, 76.0],\n [92.0, 100.0, 83.0],\n [81.0, 82.0, 66.0],\n [99.0, 88.0, 80.0],\n [79.0, 98.0, 48.0],\n [71.0, 45.0, 53.0]])",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#crear-el-gráfico",
    "href": "03_numpy_arrays.html#crear-el-gráfico",
    "title": "Repaso de numpy y otros",
    "section": "Crear el gráfico",
    "text": "Crear el gráfico\nLos ejemplos de arriba usan una versión simplificada (y mucho más limpia). Vamos a hacer unos ejemplos que usan toda la maquinaria de matplotlib, pero siempre es mejor usar la solución más sencilla.\n\n# Primero creamos una figura, es un objeto abstracto que puede contener varios gráficos\nfig = plt.figure()\n\n# Ahora creamos unos \"ejes\", que son la región donde el gráfico aparecerá\nax1 = fig.add_subplot(2,2,1) # número de filas, número de columnas, posición de este eje\nax2 = fig.add_subplot(2,2,2)\nax3 = fig.add_subplot(2,2,3)",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#graficar",
    "href": "03_numpy_arrays.html#graficar",
    "title": "Repaso de numpy y otros",
    "section": "Graficar",
    "text": "Graficar\n\nfig = plt.figure()\n\naxs1 = fig.add_subplot(2,2,1)\naxs2 = fig.add_subplot(2,2,2)\naxs3 = fig.add_subplot(2,2,3)\n\naxs1.scatter(notas[:,0], notas[:,1])\naxs2.scatter(notas[:,0], notas[:,2])\naxs3.scatter(notas[:,1], notas[:,2])\n\nfig.show()\n\n\n\n\n\n\n\n\n\n# Preparamos los datos\nx = np.linspace(0,2*np.pi,100)\ny = np.sin(x)\n\n# Graficamos los datos\nplt.fill(x, y)\n\n# Mostramos el gráfico\nplt.show()",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#parámetros-del-gráfico",
    "href": "03_numpy_arrays.html#parámetros-del-gráfico",
    "title": "Repaso de numpy y otros",
    "section": "Parámetros del gráfico",
    "text": "Parámetros del gráfico\nPodemos cambiar diferentes parámetros como el color, el tipo de línea o punto, etc.\n\nfig = plt.figure()\n\naxs1 = fig.add_subplot(2,2,1)\naxs2 = fig.add_subplot(2,2,2)\naxs3 = fig.add_subplot(2,2,3)\n\naxs1.scatter(notas[:,0], notas[:,1], color='yellowgreen', marker='^')\naxs2.scatter(notas[:,0], notas[:,2], color='teal', marker='o')\naxs3.scatter(notas[:,1], notas[:,2], color='darkslategray', marker='+')\n\nfig.suptitle('Correlación entre notas')\naxs1.set_title('Cuántica-Clásica')\naxs2.set_title('Cuántica-Experimental')\naxs3.set_title('Clásica-Experimental')\nfig.tight_layout(pad=2.0)\n\nfig.show()\n\n\n\n\n\n\n\n\n\n# Preparamos los datos\nx = np.linspace(-1,1,100)\ny1 = np.arccos(x)\ny2 = np.arcsin(x)\ny3 = np.arctan(x)\n\nplt.plot(x, y1, label=r'$\\cos^{-1}(x)$', linestyle='--', color='turquoise', linewidth=2)\nplt.plot(x, y2, label=r'$\\sin^{-1}(x)$', linestyle='-', color='tan', linewidth=2)\nplt.plot(x, y3, label=r'$\\tan^{-1}(x)$', linestyle=':', color='cornflowerblue', linewidth=2.5)\nplt.xlabel('$x$')\nplt.ylabel('Función')\n\n# Para diferenciar los dos gráficos podemos incluir una leyenda\nplt.legend()\n\nplt.show()",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#guardar-el-gráfico",
    "href": "03_numpy_arrays.html#guardar-el-gráfico",
    "title": "Repaso de numpy y otros",
    "section": "Guardar el gráfico",
    "text": "Guardar el gráfico\n\nq = datos[:,0]\nf = datos[:,1]\ne = datos[:,2]\n\nplt.errorbar(q,f,e, ecolor='black', capsize=3)\nplt.xlabel('$q$')\nplt.ylabel('$f(q)$')\n\n## Importante! Poner antes de plt.show()\n#plt.savefig('datos.pdf')\n\nplt.show()",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#formato-para-archivos-de-texto",
    "href": "03_numpy_arrays.html#formato-para-archivos-de-texto",
    "title": "Repaso de numpy y otros",
    "section": "Formato para archivos de texto",
    "text": "Formato para archivos de texto\nNormalmente queremos guardar números bien formateados.\n\nimport numpy as np\n\n\nx = np.linspace(0,1,20)\ny = x**2\n\n\nwith open('copia.txt', 'w') as file:\n    for i in range(len(x)):\n        texto = f'{x[i]:020.3f}\\t{y[i]:.3e}\\n'\n        file.write(texto)\n\n\nwith open('copia.txt', 'r') as file:\n    x = []\n    y = []\n    for l in file:\n        xin, yin = l.split()\n        x.append(float(xin))\n        y.append(float(yin))\n        print(l, end='')\n\n0000000000000000.000    0.000e+00\n0000000000000000.053    2.770e-03\n0000000000000000.105    1.108e-02\n0000000000000000.158    2.493e-02\n0000000000000000.211    4.432e-02\n0000000000000000.263    6.925e-02\n0000000000000000.316    9.972e-02\n0000000000000000.368    1.357e-01\n0000000000000000.421    1.773e-01\n0000000000000000.474    2.244e-01\n0000000000000000.526    2.770e-01\n0000000000000000.579    3.352e-01\n0000000000000000.632    3.989e-01\n0000000000000000.684    4.681e-01\n0000000000000000.737    5.429e-01\n0000000000000000.789    6.233e-01\n0000000000000000.842    7.091e-01\n0000000000000000.895    8.006e-01\n0000000000000000.947    8.975e-01\n0000000000000001.000    1.000e+00\n\n\n\ny\n\n[0.0,\n 0.00277,\n 0.01108,\n 0.02493,\n 0.04432,\n 0.06925,\n 0.09972,\n 0.1357,\n 0.1773,\n 0.2244,\n 0.277,\n 0.3352,\n 0.3989,\n 0.4681,\n 0.5429,\n 0.6233,\n 0.7091,\n 0.8006,\n 0.8975,\n 1.0]",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#tarea-1.6",
    "href": "03_numpy_arrays.html#tarea-1.6",
    "title": "Repaso de numpy y otros",
    "section": "Tarea 1.6",
    "text": "Tarea 1.6\nUn colega le entrega a usted archivos de texto con los resultados de una simulación (simulacion.txt). Este archivo contiene tres columnas separadas por espacios tal que cada fila es un dato y las tres columnas son tres propiedades simuladas de ese dato.\nEscriba una función que lea ese archivo de texto y lo vuelva a guardar en un archivo simulacion.hd5 con tres datasets correspondientes a las tres propiedades de cada dato.\nComo usted quiere reutilizar esta función para cualquier otro archivo con tres columnas, la función debe tomar el nombre del archivo de texto y el nombre deseado para el nuevo archivo hd5 como argumentos.\nEl archivo simulacion.txt contiene por ejemplo lo siguiente:\n3.141590000000000094e-03 2.557680595776000416e+02 4.501400409434224770e+01 \n6.283180000000000189e-03 3.752818426478838205e+02 2.947770471609068110e+01 \n9.424770000000000716e-03 4.246697882492646841e+02 2.843524433400840579e+01 \n1.256636000000000038e-02 4.676325636948347437e+02 2.576223788106328882e+01 \n1.570795000000000177e-02 4.820912691815412359e+02 1.530261598082400276e+01 \n1.884954000000000143e-02 4.337667969674867550e+02 1.450243036000263963e+01 \n2.199113000000000109e-02 4.299064323187142804e+02 7.689521175184014012e+00 \n2.513272000000000075e-02 3.840742743415148084e+02 5.880658615460115257e+00 \n2.827431000000000041e-02 3.464876766126099596e+02 5.062040746246734280e+00",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#tarea-1.7",
    "href": "03_numpy_arrays.html#tarea-1.7",
    "title": "Repaso de numpy y otros",
    "section": "Tarea 1.7",
    "text": "Tarea 1.7\nSin usar ciclos for ni while, escriba un código que calcule la siguiente sumatoria\n\\[\n\\sum_{n = 1}^{100} e^n(n+1)\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#tarea-1.8",
    "href": "03_numpy_arrays.html#tarea-1.8",
    "title": "Repaso de numpy y otros",
    "section": "Tarea 1.8",
    "text": "Tarea 1.8\nGrafique en una misma figura la siguiente función junto con su serie de Taylor alrededor de \\(x = 0\\) truncada al término número 10. ¿Hasta cuál valor de \\(x\\) parece ser una buena aproximación?\n\\[\nf(x) = x\\sin(x)\n\\]\nUse colores y estilos de línea diferentes para cada línea. Escoja un rango de valores de \\(x\\) que represente lo que quiera concluir sobre esta aproximación. Incluya una leyenda para facilitar la lectura del gráfico.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#tarea-1.9",
    "href": "03_numpy_arrays.html#tarea-1.9",
    "title": "Repaso de numpy y otros",
    "section": "Tarea 1.9",
    "text": "Tarea 1.9\nSuponga que usted es un ayudante de un laboratorio de física. En un experimento se pide medir la posición de una masa que cae en un plano inclinado a intervalos regulares en el tiempo. El equipo disponible puede medir las posiciones con una precisión de \\(4\\,\\text{mm}\\). Uno de los estudiantes usa los siguientes datos (en \\(\\text{cm}\\)):\n\ndatos = [0.9,  2. ,  3.6,  5.6,  8. , 10.9, 14.2, 18.]\n\nGrafique estos datos con sus barras de error. Explique por qué el estudiante merece una nota de 1.0. Compare con los siguientes datos obtenidos por un estudiante que merece 7.0.\n\ndatos_7 = [0.3,  1.7,  4.1,  5.7,  8.5, 10.7, 13.6, 17.2]",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "03_numpy_arrays.html#tarea-1.10",
    "href": "03_numpy_arrays.html#tarea-1.10",
    "title": "Repaso de numpy y otros",
    "section": "Tarea 1.10",
    "text": "Tarea 1.10\nUn colega le pasa a usted un archivo .hd5 que contiene tres “datasets” ‘x’, ‘y’, ‘e’. Todos los datasets tienen la misma longitud y el i-ésimo elemento de cada dataset corresponde a una propiedad diferente del i-ésimo dato.\nEscriba una función que grafique esos resultados donde ‘x’ es el eje horizontal, ‘y’ el eje vertical y ‘e’ son las barras de error de ‘y’.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Repaso de numpy, matplotlib, archivos"
    ]
  },
  {
    "objectID": "11_solucion_sistemas_lineales.html",
    "href": "11_solucion_sistemas_lineales.html",
    "title": "Solución de Sistemas de Ecuaciones Lineales",
    "section": "",
    "text": "import numpy as np\nimport scipy.linalg",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Sistemas de Ecuaciones Lineales"
    ]
  },
  {
    "objectID": "11_solucion_sistemas_lineales.html#sistemas-triangulares",
    "href": "11_solucion_sistemas_lineales.html#sistemas-triangulares",
    "title": "Solución de Sistemas de Ecuaciones Lineales",
    "section": "Sistemas triangulares",
    "text": "Sistemas triangulares\nSupongamos que tenemos el siguiente sistema\n\\[\n\\begin{pmatrix}\n3 & 0 & 0 \\\\\n1 & 2 & 0 \\\\\n4 & 5 & 6\n\\end{pmatrix}\n\\begin{pmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n9 \\\\\n8 \\\\\n7\n\\end{pmatrix}\n\\]\nA esta matriz la llamamos una matriz triangular inferior. Este tipo de problemas es fácil de resolver. La primera ecuación nos da directamente \\(x_1 = 3\\). La segunda nos da \\(2x_2 = 8 - x_1 = 5\\), es decir, \\(x_2 = 2.5\\). Finalmente, la tercera ecuación nos da \\(6x_3 = 7 - 4x_1 - 5x_2 = -10.5\\), es decir, \\(x_3 = -1.75\\). Esto lo podemos traducir a un algoritmo (llamado sustitución hacia adelante)\n\\[\n\\begin{align}\nx_1 &= \\frac{b_1}{a_{11}} \\\\\nx_2 &= \\frac{b_2 - a_{21}x_1}{a_{22}} \\\\\nx_3 &= \\frac{b_3 - a_{31}x_1 - a_{32}x_2}{a_{33}} \\\\\n\\vdots \\\\\nx_n &= \\frac{b_n - a_{n1}x_1 - a_{n2}x_2 - \\cdots - a_{n,n-1}x_{n-1}}{a_{nn}}\\,,\n\\end{align}\n\\]\nque funciona siempre y cuando los elementos de la diagonal \\(a_{ii}\\) sean distintos de cero. En Python:\n\ndef forwardsub(A, b):\n    n = A.shape[0]\n    x = np.zeros(n)\n    x[0] = b[0] / A[0, 0]\n    for i in range(1, n):\n        s = sum(A[i, j] * x[j] for j in range(i))\n        x[i] = (b[i] - s) / A[i,i]\n    return x\n\nVeamos que funciona\n\nA = np.array([[3, 0, 0],\n              [1, 2, 0],\n              [4, 5, 6]])\nb = np.array([9, 8, 7])\nx = forwardsub(A, b)\nprint(x)\n\n[ 3.          2.5        -2.91666667]\n\n\nDe forma análoga, si tenemos una matriz triangular superior\n\ndef backsub(A, b):\n    n = A.shape[0]\n    x = np.zeros(n)\n    x[-1] = b[-1] / A[-1, -1]\n    for i in range(n-2, -1, -1):\n        s = sum(A[i, j] * x[j] for j in range(i+1, n))\n        x[i] = (b[i] - s) / A[i,i]\n    return x",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Sistemas de Ecuaciones Lineales"
    ]
  },
  {
    "objectID": "11_solucion_sistemas_lineales.html#factorización-lu-con-pivoteo",
    "href": "11_solucion_sistemas_lineales.html#factorización-lu-con-pivoteo",
    "title": "Solución de Sistemas de Ecuaciones Lineales",
    "section": "Factorización LU con pivoteo",
    "text": "Factorización LU con pivoteo\nLa solución es primero pivotear la matriz, es decir, intercambiar filas para que los elementos de la diagonal sean los más grandes posibles. Por ejemplo, cambiemos la segunda y tercera fila de \\(A\\) para resolver el problema equivalente\n\nA = np.array([[2, 0, 4], [1, 15, 2], [-2, 1e-16, 2]])\nL, U = lufact(A)\nb = np.array([1, 3, 2])\nz = forwardsub(L, b)\nx = backsub(U, z)\nprint(\"nueva aproximación:\", x)\n\nnueva aproximación: [-0.5         0.16666667  0.5       ]\n\n\nEntonces el truco es primero permutar las filas de \\(A\\) para que los elementos de la diagonal sean los más grandes posibles. Esto se logra con una matriz de permutación \\(P\\). Por ejemplo \\[\nP = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{pmatrix}\\,,\\quad\nA = \\begin{pmatrix}\n2 & 0 & 4 \\\\\n-2 & 1e-16 & 2 \\\\\n1 & 15 & 2\n\\end{pmatrix}\\,,\\quad\nPA = \\begin{pmatrix}\n2 & 0 & 4 \\\\\n1 & 15 & 2 \\\\\n-2 & 1e-16 & 2\n\\end{pmatrix}\\,.\n\\]\nEntonces en realidad queremos factorizar \\(A = PLU\\). Note que \\(PA\\mathbf{x} = P\\mathbf{b}\\) es un sistema equivalente.\nUn algoritmo que lo logra es\n\ndef plufact(A):\n    import numpy as np\n    A = np.asarray(A, dtype=float)\n    n = A.shape[0]\n    L = np.zeros((n, n), dtype=float)\n    U = np.zeros((n, n), dtype=float)\n    p = np.zeros(n, dtype=int)\n    Ak = A.copy()\n\n    for k in range(n - 1):\n        # Find pivot row for column k\n        p[k] = np.argmax(np.abs(Ak[:, k]))\n        # Place pivot row in U\n        U[k, :] = Ak[p[k], :]\n        # Compute multipliers for column k\n        L[:, k] = Ak[:, k] / U[k, k]\n        # Update Ak by outer product\n        Ak -= np.outer(L[:, k], U[k, :])\n\n    # Last pivot\n    p[n - 1] = np.argmax(np.abs(Ak[:, n - 1]))\n    U[n - 1, n - 1] = Ak[p[n - 1], n - 1]\n    L[:, n - 1] = Ak[:, n - 1] / U[n - 1, n - 1]\n\n    # Permute L rows according to p\n    Lp = L[p, :]\n\n    return p, L, U\n\nEsto es lo que hace numpy\n\nP, L, U = scipy.linalg.lu(A, permute_l=False)\nprint(\"L:\\n\", L, \"\\nU:\\n\", U)\n\nL:\n [[ 1.00000000e+00  0.00000000e+00  0.00000000e+00]\n [ 5.00000000e-01  1.00000000e+00  0.00000000e+00]\n [-1.00000000e+00  6.66666667e-18  1.00000000e+00]] \nU:\n [[ 2.  0.  4.]\n [ 0. 15.  0.]\n [ 0.  0.  6.]]\n\n\nSi tenemos que resolver \\(A\\mathbf{x} = \\mathbf{b}\\) para muchos vectores \\(\\mathbf{b}\\), nos conviene hacer la factorización LU una sola vez (que cuesta \\(O(n^3)\\)), y luego para cada \\(\\mathbf{b}\\) resolver los dos sistemas triangulares (que cuestan solo \\(O(n^2)\\) cada uno).",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Sistemas de Ecuaciones Lineales"
    ]
  },
  {
    "objectID": "11_solucion_sistemas_lineales.html#tarea-5.6",
    "href": "11_solucion_sistemas_lineales.html#tarea-5.6",
    "title": "Solución de Sistemas de Ecuaciones Lineales",
    "section": "Tarea 5.6",
    "text": "Tarea 5.6\nLa inversión de una matriz \\(A\\) de \\(n \\times n\\) usando el método de cofactores requiere calcular: \\[A^{-1} = \\frac{1}{\\det(A)} \\text{adj}(A)\\] donde \\(\\text{adj}(A)\\) es la matriz adjunta (transpuesta de la matriz de cofactores).\n\nPara calcular \\(\\det(A)\\) usando expansión por cofactores se requieren aproximadamente \\(n!\\) operaciones. Explique por qué.\nPara calcular la matriz adjunta necesitamos \\(n^2\\) determinantes de matrices \\((n-1) \\times (n-1)\\), cada uno requiriendo \\((n-1)!\\) operaciones. ¿Cuántas operaciones son en total?\n¿Para \\(n\\) grande, cómo se comporta el total de operaciones?",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Sistemas de Ecuaciones Lineales"
    ]
  },
  {
    "objectID": "11_solucion_sistemas_lineales.html#tarea-5.7",
    "href": "11_solucion_sistemas_lineales.html#tarea-5.7",
    "title": "Solución de Sistemas de Ecuaciones Lineales",
    "section": "Tarea 5.7",
    "text": "Tarea 5.7\nDemuestre que el número de condicionamiento de una matriz satisface \\(\\kappa(AB) \\leq \\kappa(A)\\kappa(B)\\). Encuentre además un ejemplo donde no se cumple la igualdad.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Sistemas de Ecuaciones Lineales"
    ]
  },
  {
    "objectID": "11_solucion_sistemas_lineales.html#tarea-5.8",
    "href": "11_solucion_sistemas_lineales.html#tarea-5.8",
    "title": "Solución de Sistemas de Ecuaciones Lineales",
    "section": "Tarea 5.8",
    "text": "Tarea 5.8\nConsidere el sistema de ecuaciones \\(A\\mathbf{x} = \\mathbf{b}\\), donde \\[\nA = \\pmatrix{\n    1 & -1 & 0 & \\alpha - \\beta & \\beta \\\\\n    0 & 1 & -1 & 0 & 0 \\\\\n    0 & 0 & 1 & -1 & 0 \\\\\n    0 & 0 & 0 & 1 & -1 \\\\\n    0 & 0 & 0 & 0 & 1\n}\\,,\\qquad\n\\mathbf{b} = \\pmatrix{\n    \\alpha \\\\\n    0 \\\\\n    0 \\\\\n    0 \\\\\n    1\n}\\,.\n\\]\nConsidere \\(\\alpha = 0.1\\) y los siguientes valores de \\(\\beta = 10, 100, 10^3, ..., 10^{12}\\). Produzca una tabla con las columnas \\(\\beta\\), \\((x_1 - 1)\\) y \\(\\kappa(A)\\), donde \\(\\mathbf{x}\\) se encuentra usando la factorización LU (sin la P). Explique.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Sistemas de Ecuaciones Lineales"
    ]
  },
  {
    "objectID": "11_solucion_sistemas_lineales.html#tarea-5.9",
    "href": "11_solucion_sistemas_lineales.html#tarea-5.9",
    "title": "Solución de Sistemas de Ecuaciones Lineales",
    "section": "Tarea 5.9",
    "text": "Tarea 5.9\nDemuestre que si factorizamos una matriz de la forma \\(A = LU\\) usando el algoritmo visto en clase, su determinante se puede escribir \\(\\det(A) = \\det(U) = \\prod_i U_{ii}\\). Escriba una función que use este hecho para calcular el determinante y verifique para tres matrices distintas.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Sistemas de Ecuaciones Lineales"
    ]
  },
  {
    "objectID": "11_solucion_sistemas_lineales.html#tarea-5.10",
    "href": "11_solucion_sistemas_lineales.html#tarea-5.10",
    "title": "Solución de Sistemas de Ecuaciones Lineales",
    "section": "Tarea 5.10",
    "text": "Tarea 5.10\nConsidere la matriz triangular inferior \\[\nA = \\begin{pmatrix}\n2 & 0 & 0 & 0 & 0 \\\\\n1 & 1.4 & 0 & 0 & 0 \\\\\n1.4 & 2 & 1.1 & 0 & 0 \\\\\n2.3 & 3.3 & 3 & 0.4 & 0 \\\\\n0.3 & 1 & 5 & 2 & 3\n\\end{pmatrix}\n\\]\nUse el algoritmo visto en clase para encontrar la factorización LU de esta matriz. Explique por qué \\(L \\neq A\\) y por qué \\(U\\) no es la matriz identidad.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Sistemas de Ecuaciones Lineales"
    ]
  },
  {
    "objectID": "19_metodos_de_multiples_pasos.html",
    "href": "19_metodos_de_multiples_pasos.html",
    "title": "EDOs - Métodos de múltiples pasos",
    "section": "",
    "text": "Los métodos que hemos estudiado han intentado predecir \\(y(t_i)\\) usando la predicción anterior \\(w_{i-1}\\). Como hemos visto, el error cometido por los métodos estudiados hasta ahora va creciendo a medida que crece \\(t\\). Debido a esto, vale la pena involucrar varias predicciones anteriores en la predicción apra \\(y(t_i)\\).\nimport numpy as np\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Múltiples Pasos"
    ]
  },
  {
    "objectID": "19_metodos_de_multiples_pasos.html#tarea-9.6",
    "href": "19_metodos_de_multiples_pasos.html#tarea-9.6",
    "title": "EDOs - Métodos de múltiples pasos",
    "section": "Tarea 9.6",
    "text": "Tarea 9.6\nModifique los códigos de Runge-Kutta-Fehlberg y Adams con control de error para que impriman el número de pasos requeridos. Luego resuelva el siguiente problema de condición incial con ambos métodos y compare para diferentes tolerancias:\n\\[\ny'(t) = (1/t)(y^2 + y)\\,,\\quad 1 \\leq t \\leq 3\\,,\\quad y(1) = -2\\,.\n\\]\n\nclass MinStep(Exception):\n    pass\n\ndef rkf_m(f, a, b, yo, tol, hmin, hmax):\n    \n    t = a\n    w = yo\n    h = hmax\n    flag = 1\n    \n    ts = [t]\n    sol = [w]\n    hs = []\n    rs = []\n    evals = 0\n    \n    while flag:\n        \n        # Evaluaciones de la función \n        k1 = h*f(t, w)\n        k2 = h*f(t + h/4, w + k1/4)\n        k3 = h*f(t + 3*h/8, w + 3*k1/32 + 9*k2/32)\n        k4 = h*f(t + 12*h/13, w + 1932*k1/2197 - 7200*k2/2197 + 7296*k3/2197)\n        k5 = h*f(t + h, w + 439*k1/216 - 8*k2 + 3680*k3/513 - 845*k4/4104)\n        k6 = h*f(t + h/2, w - 8*k1/27 + 2*k2 - 3544*k3/2565 + 1859*k4/4104 - 11*k5/40)\n        evals += 6\n        \n        # Estima del error dada por la diferencia entre dos RKs\n        R = abs(k1/360 - 128*k3/4275 - 2197*k4/75240 + k5/50 + 2*k6/55)\n        \n        # Si el error es menor que la tolerancia, se acepta el paso\n        if R &lt;= tol:\n            t += h\n            w = w + 25*k1/216 + 1408*k3/2565 + 2197*k4/4104 - k5/5\n            ts.append(t)\n            sol.append(w)\n            hs.append(h)\n            rs.append(R)\n            \n        # el 0.84 es un factor para hacer la estima más conservadora \n        # corresponde a 1/2**(1/4)\n        q = 0.84*(tol/R)**(1/4)\n        \n        # ACTUALIZACIÓN DE h\n        # Se establece un q mínimo para no quedarse atrapado en alguna región.\n        # Esto se puede cambiar.\n        if q &lt;= 0.1:\n            h = 0.1*h\n        # Se establece también un q máximo para no peder detalles de la función\n        elif q &gt;= 4:\n            h = 4*h\n        else:\n            h = q*h\n        if h &gt; hmax:\n            h = hmax\n        \n        # Si nos pasamos de b, terminamos\n        if t &gt;= b:\n            flag = 0\n        # El último paso debe llegar a b\n        elif t + h &gt; b:\n            h = b - t\n        elif h &lt; hmin:\n            raise MinStep('Se excedió el paso mínimo.')\n            \n    return np.array(ts), np.array(sol), np.array(hs), np.array(rs), evals\n\n\ndef rk4_step(f, fi, t, w, h):\n    \n    k1 = h*fi\n    k2 = h*f(t+h/2, w+k1/2)\n    k3 = h*f(t+h/2, w+k2/2)\n    k4 = h*f(t + h, w + k3)\n    return (k1 + 2*k2 + 2*k3 + k4)/6\n\nclass MinStep(Exception):\n    pass\n\ndef apce_m(f, a, b, yo, tol, hmin, hmax):\n    \n    h = hmax\n    flag = 1 # Indica si terminamos\n    last = 0 # Indica si es el último paso\n    \n    ts = [a]\n    ws = [yo]\n    hs = [h]\n    rs = [-1]\n    \n    evals = 0\n    \n    fi = f(ts[0], ws[0])\n    evals += 1\n    fim1 = 0\n    fim2 = 0\n    fim3 = 0\n    \n    # Puntos iniciales obtenidos de Runge-Kutta\n    for i in range(3):\n        ws.append(ws[i] + rk4_step(f, fi, ts[i], ws[i], h))\n        evals += 3\n        ts.append(ts[i] + h)\n        hs.append(h)\n        rs.append(-1)\n        fim3 = fim2\n        fim2 = fim1\n        fim1 = fi\n        fi = f(ts[i+1], ws[i+1])\n        evals += 1\n    nflag = 1 # Indica si los últimos puntos fueron obtenidos con RK\n    i = 4\n    t = ts[3] + h\n    \n    while flag:\n        \n        # Predictor Adams-Bashforth de 4 pasos\n        wp = ws[i-1] + h*(55*fi - 59*fim1 +37*fim2 - 9*fim3)/24\n        # Corrector Adams-Moulton de 3 pasos\n        wc = ws[i-1] + h*(9*f(t, wp) + 19*fi - 5*fim1 + fim2)/24\n        evals += 1\n        \n        # Estima del error dada por la diferencia entre dos Adams\n        sigma = 19*abs(wc - wp)/(270*h)\n        \n        # Si el error es menor que la tolerancia, se acepta el paso\n        if sigma &lt;= tol:\n            ws.append(wc)\n            ts.append(t)\n            hs.append(h)\n            rs.append(sigma)\n            fim3 = fim2\n            fim2 = fim1\n            fim1 = fi\n            fi = f(ts[i], ws[i])\n            evals += 1\n            \n            # Si es el último paso, terminamos\n            if last:\n                flag = 0\n            else:\n                i += 1\n                nflag = 0\n                \n                # Incrementamos h si es más preciso de lo requerido\n                # o lo reducimos para incluir b\n                if sigma &lt;= 0.1*tol or ts[i-1] + h &gt; b:\n                    delta = (tol/(2*sigma))**(1/4)\n                    if delta &gt; 4: # Evitamos que crezca demasiado\n                        h = 4*h \n                    else:\n                        h = delta*h\n                    if h &gt; hmax:\n                        h = hmax\n                    if ts[i-1] + 4*h &gt; b:\n                        h = (b - ts[i-1])/4\n                        last = 1\n                    # Como h cambió, necesitamos volver a calcular los\n                    # puntos iniciales para los Adams\n                    for j in range(3):\n                        ws.append(ws[i+j-1] + rk4_step(f, fi, ts[i+j-1], ws[i+j-1], h))\n                        evals += 3\n                        ts.append(ts[i+j-1] + h)\n                        hs.append(h)\n                        rs.append(-1)\n                        fim3 = fim2\n                        fim2 = fim1\n                        fim1 = fi\n                        fi = f(ts[i+j],ws[i+j])\n                        evals += 1\n                    i += 3\n                    nflag = 1\n        else: # sigma &gt; tol\n            # disminuimos h\n            delta = (tol/(2*sigma))**(1/4)\n            if delta &lt; 0.1: # evitamos que disminuya demasiado\n                h = 0.1*h\n            else:\n                h = delta*h\n                \n            if h &lt; hmin:\n                raise MinStep('Tamaño de paso mínimo excedido', ts, ws, hs, rs)\n            else:\n                if nflag: # los últimos pasos vienen de RK\n                    i -= 3 # se rechazan los pasos anteriores del RK\n                    fi = fim3\n                    for j in range(3):\n                        ws[i+j] = ws[i+j-1] + rk4_step(f, fi, ts[i+j-1], ws[i+j-1], h)\n                        evals += 3\n                        ts[i+j] = ts[i+j-1] + h\n                        hs[i+j] = h\n                        rs[i+j] = -1\n                        fim3 = fim2\n                        fim2 = fim1\n                        fim1 = fi\n                        fi = f(ts[i+j],ws[i+j])\n                        evals += 1\n                    i += 3\n                    nflag = 1\n                else:\n                    for j in range(3):\n                        ws.append(ws[i+j-1] + rk4_step(f, fi, ts[i+j-1], ws[i+j-1], h))\n                        evals += 3\n                        ts.append(ts[i+j-1] + h)\n                        hs.append(h)\n                        rs.append(-1)\n                        fim3 = fim2\n                        fim2 = fim1\n                        fim1 = fi\n                        fi = f(ts[i+j],ws[i+j])\n                        evals += 1\n                    i += 3\n                    nflag = 1\n        \n        t = ts[i-1] + h\n        # fin del while\n            \n    return np.array(ts), np.array(ws), np.array(hs), np.array(rs), evals\n\n\ndef f(t, y):\n    return (1/t)*(y**2 + y)\n\na = 1\nb = 3\nyo = -2\nhmin = 0.001\nhmax = 0.2\n\n\ntols = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9]\nnum_rkf = [rkf_m(f, a, b, yo, t, hmin, hmax)[-1] for t in tols]\nnum_apce = [apce_m(f, a, b, yo, t, hmin, hmax)[-1] for t in tols]\nplt.loglog(tols, num_rkf, label='RKF')\nplt.loglog(tols, num_apce, label='APCE')\nplt.legend()\nplt.xlabel('Tolerancia')\nplt.ylabel('Nro. evaluaciones')\n\nText(0, 0.5, 'Nro. evaluaciones')\n\n\n\n\n\n\n\n\n\nPara este problema, el método de RKF es más económico para pecisiones altas, ya que logra una mejor aproximación con un tamaño de paso grande. Para bajas tolerancias requiere más evaluaciones.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Múltiples Pasos"
    ]
  },
  {
    "objectID": "19_metodos_de_multiples_pasos.html#tarea-9.7",
    "href": "19_metodos_de_multiples_pasos.html#tarea-9.7",
    "title": "EDOs - Métodos de múltiples pasos",
    "section": "Tarea 9.7",
    "text": "Tarea 9.7\nEscriba un código que implemente el método de Adams-Bashforth de dos pasos. Úselo para resolver el siguiente problema\n\\[\ny'(t) = 1 + \\frac{y}{t} + \\left(\\frac{y}{t}\\right)^2\\,,\\quad 1 \\leq t \\leq 1.5\\,,\\quad y(1) = 0\\,.\n\\]\nPara ser consistente con el orden, los primeros pasos deberían ser dados por un Runge-Kutta de orden 2.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Múltiples Pasos"
    ]
  },
  {
    "objectID": "19_metodos_de_multiples_pasos.html#tarea-9.10",
    "href": "19_metodos_de_multiples_pasos.html#tarea-9.10",
    "title": "EDOs - Métodos de múltiples pasos",
    "section": "Tarea 9.10",
    "text": "Tarea 9.10\nEjercicio 5.7.12, libro de Burden\nSea \\(P(t)\\) la cantidad de individuos en una población al tiempo \\(t\\), medido en años. Si el la tasa de nacimientos promedio \\(b\\) es constante y la tasa de muerte promedio \\(d\\) es proporcional al tamaño de la población (debido al hacinamiento), entonces la razón de crecimiento de la población está dada por la ecuación logística\n\\[\n\\frac{d P(t)}{dt} = bP(t) - k[P(t)]^2\n\\]\ndonde \\(d = kP(t)\\). Suponga que \\(P(0) = 50976\\), \\(b = 2.9\\times 10^{-2}\\) y \\(k = 1.4\\times 10^{-7}\\). Encuentre la población luego de \\(5\\) años.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Múltiples Pasos"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html",
    "href": "08_varias_variables_aleatorias.html",
    "title": "Varias variables aleatorias",
    "section": "",
    "text": "\\[\n\\tilde{p}(k;n) = \\sum_{s=0}^n\\frac{n!}{s!(n-s)!}p^s(1-p)^{(n-s)}e^{-iks} = \\left(p e^{-ik} + (1 - p)\\right)^n\\,.\n\\] Entonces, \\[\n\\ln \\tilde{p}(k;n) = n \\ln \\tilde{p}(k;1)\\,.\n\\] Pero por otro lado cuando \\(n=1\\) \\[\n\\langle s^\\ell \\rangle_1 = 1^\\ell p + 0^\\ell (1 - p) = p\\,.\n\\] De aquí podemos deducir \\[\n\\mu = \\langle s \\rangle_c = n \\langle s \\rangle_1 = np\\,,\n\\]\n\\[\n\\sigma^2 = \\langle s^2 \\rangle_c = n \\langle s^2 \\rangle_{1,c} = n \\left(\\langle s^2 \\rangle_1 - \\langle s\\rangle_1^2\\right) = np(1 - p)\\,.\n\\]\n\n\n\nLo más fácil es tomar el límite continuo de la binomial con \\(n = T/dt\\) donde \\(dt\\) es un intervalo infinitesimal, y \\(p = \\lambda dt\\) \\[\n\\tilde{p}(k) = \\lim_{dt\\rightarrow 0} \\left(\\lambda dt e^{-ik} + (1 - \\lambda dt)\\right)^{T/dt} = \\exp\\left[\\lambda (e^{-ik} - 1)\\right]\\,.\n\\] De aquí tenemos que \\[\n\\ln \\tilde{p}(k) = \\lambda (e^{-ik} - 1) = \\lambda\\sum_{n=1}^\\infty \\frac{1}{n!}(-ik)^n\n\\] ¡Eso quiere decir que todos los cumulantes son iguales! \\[\n\\langle s^n \\rangle_c = \\lambda\\,.\n\\] En particular el valor esperado de \\(s\\) y la varianza son \\[\n\\mu = s\\,,\\quad \\sigma^2 = s\\,.\n\\]\n\n\n\n\\[\n\\tilde{\\rho}(k) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty} dx\\,e^{-(x - \\mu)^2/2\\sigma}e^{-ikx} = \\exp\\left(-ik\\mu - \\frac{1}{2}\nk^2\\sigma^2\\right)\n\\] Entonces \\[\n\\ln \\tilde{\\rho}(k) = -ik\\mu -\\frac{1}{2}k^2\\sigma^2\\,.\n\\] Esto quiere decir que todos los cumulantes son cero excepto los primeros dos. La gaussiana es una distribución completamente determinada por su media y su varianza.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html#binomial",
    "href": "08_varias_variables_aleatorias.html#binomial",
    "title": "Varias variables aleatorias",
    "section": "",
    "text": "\\[\n\\tilde{p}(k;n) = \\sum_{s=0}^n\\frac{n!}{s!(n-s)!}p^s(1-p)^{(n-s)}e^{-iks} = \\left(p e^{-ik} + (1 - p)\\right)^n\\,.\n\\] Entonces, \\[\n\\ln \\tilde{p}(k;n) = n \\ln \\tilde{p}(k;1)\\,.\n\\] Pero por otro lado cuando \\(n=1\\) \\[\n\\langle s^\\ell \\rangle_1 = 1^\\ell p + 0^\\ell (1 - p) = p\\,.\n\\] De aquí podemos deducir \\[\n\\mu = \\langle s \\rangle_c = n \\langle s \\rangle_1 = np\\,,\n\\]\n\\[\n\\sigma^2 = \\langle s^2 \\rangle_c = n \\langle s^2 \\rangle_{1,c} = n \\left(\\langle s^2 \\rangle_1 - \\langle s\\rangle_1^2\\right) = np(1 - p)\\,.\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html#poisson",
    "href": "08_varias_variables_aleatorias.html#poisson",
    "title": "Varias variables aleatorias",
    "section": "",
    "text": "Lo más fácil es tomar el límite continuo de la binomial con \\(n = T/dt\\) donde \\(dt\\) es un intervalo infinitesimal, y \\(p = \\lambda dt\\) \\[\n\\tilde{p}(k) = \\lim_{dt\\rightarrow 0} \\left(\\lambda dt e^{-ik} + (1 - \\lambda dt)\\right)^{T/dt} = \\exp\\left[\\lambda (e^{-ik} - 1)\\right]\\,.\n\\] De aquí tenemos que \\[\n\\ln \\tilde{p}(k) = \\lambda (e^{-ik} - 1) = \\lambda\\sum_{n=1}^\\infty \\frac{1}{n!}(-ik)^n\n\\] ¡Eso quiere decir que todos los cumulantes son iguales! \\[\n\\langle s^n \\rangle_c = \\lambda\\,.\n\\] En particular el valor esperado de \\(s\\) y la varianza son \\[\n\\mu = s\\,,\\quad \\sigma^2 = s\\,.\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html#gaussiana",
    "href": "08_varias_variables_aleatorias.html#gaussiana",
    "title": "Varias variables aleatorias",
    "section": "",
    "text": "\\[\n\\tilde{\\rho}(k) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\int_{-\\infty}^{\\infty} dx\\,e^{-(x - \\mu)^2/2\\sigma}e^{-ikx} = \\exp\\left(-ik\\mu - \\frac{1}{2}\nk^2\\sigma^2\\right)\n\\] Entonces \\[\n\\ln \\tilde{\\rho}(k) = -ik\\mu -\\frac{1}{2}k^2\\sigma^2\\,.\n\\] Esto quiere decir que todos los cumulantes son cero excepto los primeros dos. La gaussiana es una distribución completamente determinada por su media y su varianza.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html#la-gaussiana-multidimensional",
    "href": "08_varias_variables_aleatorias.html#la-gaussiana-multidimensional",
    "title": "Varias variables aleatorias",
    "section": "La gaussiana multidimensional",
    "text": "La gaussiana multidimensional\nLa distribución de varias variables más importante es la gaussiana \\[\n\\rho(\\mathbf{x}) = \\frac{1}{(2\\pi)^{n/2}(\\det \\Sigma)^{1/2}\n}\\exp\\left\\{-\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu})^T \\Sigma^{-1} (\\mathbf{x} - \\mathbf{\\mu})\\right\\}\\,,\n\\] donde \\(\\Sigma_{ij}\\) es la matriz de covarianza.\nLa función característica es simplemente la transformada de Fourier, que es análoga al caso de una dimensión \\[\n\\tilde\\rho(\\mathbf{k}) = \\exp\\left(-i\\mathbf{\\mu}\\cdot\\mathbf{k} - \\frac{1}{2}\\mathbf{k}^T\\Sigma \\mathbf{k}\\right)\n\\]\nUsando las fórmulas de arriba es fácil demostrar que \\[\n\\langle x_i x_j \\rangle_c = \\Sigma_{ij}\\,.\n\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parámetros para la distribución normal multidimensional\nmean = np.array([0, 0])\ncov = np.array([[1, 0.8], [0.8, 1]])\n\n# Generamos una muestra a partir de la distribución gaussiana\nnp.random.seed(42)\nsamples = np.random.multivariate_normal(mean, cov, 500)\n\n# Grilla para el gráfico de contornos de equiprobabilidad\nx, y = np.mgrid[-3:3:.01, -3:3:.01]\npos = np.dstack((x, y))\n\n# Distribución gaussiana multidimensional\ndef multivariate_gaussian(pos, mean, cov):\n    n = mean.shape[0]\n    diff = pos - mean\n    return np.exp(-0.5 * np.einsum('...k,kl,...l-&gt;...', diff, np.linalg.inv(cov), diff)) / \\\n           (np.sqrt((2 * np.pi) ** n * np.linalg.det(cov)))\n\n# Calculamos los valores de la gaussiana en la grilla\nz = multivariate_gaussian(pos, mean, cov)\n\n# Graficamos\nplt.figure(figsize=(8, 6))\nplt.scatter(samples[:, 0], samples[:, 1], alpha=0.5, label='Random samples')\nplt.contour(x, y, z, levels=5, colors='blue', alpha=0.7)\nplt.title('Multivariate Gaussian Distribution\\nMean = [0, 0], Covariance = [[1, 0.8], [0.8, 1]]')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html#section",
    "href": "08_varias_variables_aleatorias.html#section",
    "title": "Varias variables aleatorias",
    "section": "4.1",
    "text": "4.1\nDado un vector aleatorio de dos componentes \\(\\mathbf{X}\\) tomado de una distribución gaussiana de dos variables, con media y varianza \\[\n\\mu = \\begin{bmatrix}1 \\\\ 2\\end{bmatrix}\\,,\\quad \\Sigma = \\begin{bmatrix}2 & 1 \\\\ 1 & 2\\end{bmatrix}\\,,\n\\] considere la transformación \\(\\mathbf{y} = A\\mathbf{x} + \\mathbf{b}\\) donde \\[\nA = \\begin{bmatrix}1 & 2 \\\\ 3 & 4\\end{bmatrix}\\,,\\quad \\mathbf{b} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}\\,.\n\\]\n\nDeduzca la media y la covarianza de la nueva variable \\(\\mathbf{y}\\).\nExplique cómo la transformación afecta la geometría de los contornos de equiprobabilidad de la nueva distribución. Use gráficos para ilustrar su respuesta.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html#section-1",
    "href": "08_varias_variables_aleatorias.html#section-1",
    "title": "Varias variables aleatorias",
    "section": "4.2",
    "text": "4.2\nDemuestre que la covarianza siempre cumple \\(\\mathbf{v}^T\\Sigma\\mathbf{v} \\geq 0\\) para cualquier vector \\(\\mathbf{v}\\). Interprete el caso en el cual \\(\\mathbf{w}^T\\Sigma\\mathbf{w} = 0\\) para algún vector \\(\\mathbf{w}\\).",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html#section-2",
    "href": "08_varias_variables_aleatorias.html#section-2",
    "title": "Varias variables aleatorias",
    "section": "4.3",
    "text": "4.3\nConsidere una variable aleatoria \\(x \\in (0,\\infty)\\) distribuida de acuerdo a una distribución exponencial \\(\\rho(x) = \\lambda e^{-\\lambda x}\\).\n\nCalcule la función característica \\(\\tilde{\\rho}(k)\\).\nCalcule los primeros cuatro cumulantes de esta distribución.\nBasado en el punto anterior, compare con la distribución gaussiana.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html#section-3",
    "href": "08_varias_variables_aleatorias.html#section-3",
    "title": "Varias variables aleatorias",
    "section": "4.4",
    "text": "4.4\nUna distribución es simétrica respecto a la transformación \\(\\mathbf{x} \\rightarrow - \\mathbf{x}\\).\n\n¿Qué podemos concluir sobre sus momentos \\(\\langle x^\\ell \\rangle\\) con \\(\\ell = 3, 4\\)?\nAplique sus conclusiones a la distribución de Cauchy\n\n\\[\nf(x) = \\frac{1}{\\pi}\\frac{\\gamma}{x^2 + \\gamma^2}\\,,\n\\]\ndonde \\(\\gamma\\) es una constante positiva.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "08_varias_variables_aleatorias.html#section-4",
    "href": "08_varias_variables_aleatorias.html#section-4",
    "title": "Varias variables aleatorias",
    "section": "4.5",
    "text": "4.5\nSuponga que tenemos dos variables \\(A\\) y \\(B\\) que pueden tomar valores \\(0\\) o \\(1\\).\n\nEncuentre una distribución de probabilidad tal que \\[\nP(A=1) = 0.5\\,, P(B=1)=0.1\\,, P(A=1, B=1) = 0\\,.\n\\]\nInterprete la covarianza entre \\(A\\) y \\(B\\).",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Varias variables aleatorias"
    ]
  },
  {
    "objectID": "16_derivadas.html",
    "href": "16_derivadas.html",
    "title": "Derivadas numéricas",
    "section": "",
    "text": "En muchos casos la derivada de una función es fácil de calcular. Sin embargo con frecuencia la función se conoce sólo en algunos puntos (por ejemplo cuando es el resultado de una medición o de una simulación) y los métodos numéricos para tomar derivadas pueden resultar muy útiles.\nAdemás, las derivadas numéricas forman parte fundamental de la solución numérica a ecuaciones diferenciales parciales (para modelar el clima, la fusión de dos agujeros negros, el colapso estelar, la turbulencia, entre muchos otros fenómenos). También son la base de los métodos de optimización en los cuales se basa el aprendizaje automático.\nimport numpy as np\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#fórmula-de-dos-puntos",
    "href": "16_derivadas.html#fórmula-de-dos-puntos",
    "title": "Derivadas numéricas",
    "section": "Fórmula de dos puntos",
    "text": "Fórmula de dos puntos\nRecordemos la definición de la derivada\n\\[\nf'(x_o) = \\lim_{h\\rightarrow 0}\\frac{f(x_o + h) - f(x_o)}{h}\n\\]\nPodemos entonces tomar un \\(h\\) lo suficientemente pequeño. Para obtener una estimación del error usamos la expansión de Taylor\n\\[\nf(x_o + h) = f(x_o) + h f'(x_o) + \\frac{1}{2}h^2 f''(\\xi)\n\\]\ntal que\n\\[\nf'(x_o) = \\frac{f(x_o + h) - f(x_o)}{h} - \\frac{1}{2}h f''(\\xi)\n\\]\nEl error es entonces\n\\[\n\\left|f'(x_o) - \\frac{f(x_o + h) - f(x_o)}{h}\\right| \\leq \\frac{h}{2}\\,\\text{max}_{x\\in[x_o, x_o+h]}\\,|f''(x)|\n\\]\n\ndef deriv2p(f, x, h):\n    return (f(x + h) - f(x))/h\n\nTambién podríamos haber usado\n\\[\nf'(x_o) = \\frac{f(x_o) - f(x_o - h)}{h} + \\frac{1}{2}h f''(\\xi)\n\\]\n\nx = np.linspace(0,4,100)\nexactas = np.cos(x)\naprox2 = [deriv2p(np.sin, xi, 0.2) for xi in x]\n\nplt.plot(x, exactas, label='Exacta')\nplt.plot(x, aprox2, label='Orden 2')\nplt.legend()",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#fórmulas-de-más-puntos",
    "href": "16_derivadas.html#fórmulas-de-más-puntos",
    "title": "Derivadas numéricas",
    "section": "Fórmulas de más puntos",
    "text": "Fórmulas de más puntos\nPara obtener una mejor precisión, podemos usar expansiones de Taylor a orden más alto. Tomemos\n\\[\nf(x_o + h) = f(x_o) + h f'(x_o) + \\frac{1}{2}h^2 f''(\\xi) + \\frac{h^3}{6}f^{(3)}(\\xi)\n\\]\nDi queremos obtener \\(f'(x_o)\\), tenemos que combinar esta expresión con la evaluación en otros puntos para cancelar los términos proporcionales a \\(f(x_o)\\) y \\(f''(x_o)\\). En este caso es fácil\n\\[\nf(x_o + h) - f(x_o - h) = 2h f'(x_o) + \\mathcal{O}(h^3)\\,,\n\\]\ntal que\n\\[\nf'(x_o) =\\frac{1}{2h}\\left(f(x_o + h) - f(x_o - h)\\right) + \\frac{h^2}{6}f^{(3)}(\\xi)\n\\]\n¡Obtenemos una mayor precisión (error cuadrático) haciendo un número igual de evaluaciones que la fórmula de dos puntos!\n\ndef deriv3p(f, x, h):\n    return (f(x + h) - f(x - h))/(2*h)\n\n\nx = np.linspace(0,4,100)\nexactas = np.cos(x)\naprox2 = [deriv2p(np.sin, xi, 0.2) for xi in x]\naprox3 = [deriv3p(np.sin, xi, 0.2) for xi in x]\n\nplt.plot(x, exactas - aprox2, label='Orden 2')\nplt.plot(x, exactas - aprox3, label='Orden 3')\nplt.legend()\n\n\n\n\n\n\n\n\nPodemos encontrar otras expresiones para la derivada usando otras combinaciones de las expansiones de Taylor. Por ejemplo\n\\[\nf'(x_o) =\\frac{1}{2h}\\left(- 3f(x_o) + 4f(x_o + h) - f(x_o + 2h)\\right) + \\frac{h^2}{3}f^{(3)}(\\xi)\n\\]\nEsta fórmula sirve para estimar la derivada de una función en los bordes, cuando no conocemos \\(f(x)\\) para \\(x &lt; x_o\\). También se puede usar cuando no conocemos la función para \\(x &gt; x_o\\), en cuyo caso reemplazamos \\(h \\rightarrow -h\\). Tiene dos desventajas respecto a la anterior: Necesita tres evaluaciones y el error es aproximadamente el doble.\n\ndef deriv3p_extremo(f, x, h):\n    return (-3*f(x) + 4*f(x + h) - f(x + 2*h))/(2*h)\n\nTambién podemos usar polinomios de más alto orden para obtener fórmulas de más puntos. Por ejemplo la fórmula de tres puntos tiene un error \\((h^4/30)f^{(5)}(\\xi)\\).\n\ndef deriv5p(f, x, h):\n    return (f(x - 2*h) - 8*f(x - h) + 8*f(x + h) - f(x + 2*h))/(12*h)\n\n\ndef deriv5p_extremo(f, x, h):\n    return (-25*f(x) + 48*f(x + h) - 36*f(x + 2*h) + 16*f(x + 3*h) - 3*f(x + 4*h))/(12*h)\n\nDe manera análoga se pueden deducir fórmulas para derivadas de más alto orden (que necesitarán una mayor número de evaluaciones). Si consideramos la expansión de Taylor\n\\[\nf(x_o + h) = f(x_o) + f'(x_o)h + \\frac{1}{2}f''(x_o)h^2 + \\frac{1}{6}f^{(3)}(x_o)h^3 + \\frac{1}{24}f^{(4)}(\\xi)h^4\n\\]\nde donde vemos que\n\\[\nf(x_o + h) + f(x_o - h) = 2f(x_o) + f''(x_o)h^2 + \\frac{1}{12}f^{(4)}(\\xi)h^4\\,.\n\\]\ny entonces\n\\[\nf''(x_o) = \\frac{1}{h^2}\\left(f(x_o + h) - 2f(x_o) + f(x_o - h)\\right) - \\frac{1}{12}f^{(4)}(\\xi)h^2\n\\]\n\ndef segunda_deriv(f, x, h):\n    return (f(x + h) - 2*f(x) + f(x - h))/(h*h)",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#las-diferencias-finitas-son-inestables-y-ruidosas",
    "href": "16_derivadas.html#las-diferencias-finitas-son-inestables-y-ruidosas",
    "title": "Derivadas numéricas",
    "section": "Las diferencias finitas son inestables y ruidosas",
    "text": "Las diferencias finitas son inestables y ruidosas\nLas derivadas numéricas sufren de una inestabilidad respecto a los errores de redondeo. Para verlo consideremos la fórmula a tres puntos y supongamos que el error de redondeo (o un error de la simulación) está acotado por un valor \\(e\\) y \\(f(x) = \\tilde{f}(x) + \\delta(x)\\) donde \\(\\tilde{f}\\) es el verdadero valor, tal que \\(\\delta(x) \\leq \\Delta\\). Entonces\n\\[\n\\left|f'(x_o) - \\frac{1}{2h}\\left(f(x_o + h) - f(x_o - h)\\right)\\right| \\leq \\left|\\frac{1}{2h}(\\delta(x_o + h) - \\delta(x_o - h))\\right| + \\frac{h^2}{6} M \\leq \\frac{\\Delta}{h} + \\frac{h^2}{6} M\n\\]\n¡Al disminuir \\(h\\) aumentamos el primer término de este error!\n\nx = np.arange(0, 4, 0.1)\ndatos_r = np.sin(x) + np.random.normal(0, 0.05, 40)\ndatos_e = np.sin(x)\n\n\nplt.scatter(x, datos_e)\nplt.scatter(x, datos_r)\n\n\n\n\n\n\n\n\n\ndef deriv3_datos(fxo, fx2, h):\n    return (fx2 - fxo)/(2*h)\n\ndef deriv3_borde_datos(fxo, fx1, fx2, h):\n    return (-3*fxo + 4*fx1 - fx2)/(2*h)\n\ndef deriv_datos(fx, h):\n    \n    n = len(fx)\n    deriv = np.zeros(n)\n    for i in range(n):\n        if i == 0:\n            deriv[i] = deriv3_borde_datos(fx[0], fx[1], fx[2], h)\n        elif i == n - 1:\n            deriv[i] = deriv3_borde_datos(fx[n-1], fx[n-2], fx[n-3], -h)\n        else:\n            deriv[i] = deriv3_datos(fx[i-1], fx[i+1], h)\n    return deriv\n    return (fx2 - fxo)/(2*h)\n\n\nnum = 20\nx = np.linspace(0, 4, 20)\nh = 4/num\ndatos_e = np.sin(x)\ndatos_r = np.sin(x) + np.random.normal(0, 0.001, num)\nplt.plot(x, deriv_datos(datos_e, h) - np.cos(x))\nplt.plot(x, deriv_datos(datos_r, h) - np.cos(x))",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#la-idea-detrás-de-la-autodiferenciación",
    "href": "16_derivadas.html#la-idea-detrás-de-la-autodiferenciación",
    "title": "Derivadas numéricas",
    "section": "La idea detrás de la autodiferenciación",
    "text": "La idea detrás de la autodiferenciación\nLa idea es sencilla: Conocemos las derivadas de cualquier función sencilla y para las demás usamos la regla de la cadena.\nPor ejemplo, supongamos que queremos tomar la derivada del coseno. Existen librerías que tuenen tabuladas las derivadas para muchas funciones. Aquí usamos jax.\n\n# derivada_cos_autodiff_vs_finitas.py\n# Comparar derivadas con autodiff (JAX) y con diferencias finitas para cos(x)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport jax\nimport jax.numpy as jnp\nfrom jax import grad, vmap\n\n# --- Función ---\ndef f(x):\n    return jnp.cos(x)\n\n# --- Derivada con autodiff (JAX) ---\ndf_dx_scalar = grad(f)          # derivada escalar\ndf_dx_ad = vmap(df_dx_scalar)   # vectorizar para arreglos\n\n# --- Malla y verdad analítica ---\nx = np.linspace(-2*np.pi, 2*np.pi, 400)\nf_real = np.cos(x)\ndf_real = -np.sin(x)\n\n# --- Diferencias finitas (central, con np.gradient) ---\ndf_fd = np.gradient(f_real, x)\n\n# --- Derivada con autodiff ---\ndf_ad = np.array(df_dx_ad(jnp.array(x)))\n\n# --- Gráfico ---\nplt.figure(figsize=(7,4))\nplt.plot(x, df_fd/df_real - 1,   \"--\", label=\"Diferencias finitas (np.gradient)\")\nplt.plot(x, df_ad/df_real - 1,   \":\", label=\"Autodiff con JAX (grad)\")\n\nplt.xlabel(\"x\")\nplt.ylabel(\"derivada\")\nplt.title(\"Error relativo de la derivada de cos(x)\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# --- Errores L2 ---\ndef error_L2(a, b):\n    return np.sqrt(np.mean((a - b)**2))\n\nprint(\"Error L2 comparado con -sin(x):\")\nprint(f\"  Diferencias finitas : {error_L2(df_fd, df_real):.3e}\")\nprint(f\"  Autodiff (JAX)      : {error_L2(df_ad, df_real):.3e}\")\n\n\n\n\n\n\n\n\nError L2 comparado con -sin(x):\n  Diferencias finitas : 1.120e-03\n  Autodiff (JAX)      : 6.453e-08\n\n\n¿Qué pasa cuando tenemos una función más complicada? En ese caso usamos la regla de la cadena. Por ejemplo, si tenemos una función \\(f(w(x), v(x))\\) y queremos calcular la derivada respecto a \\(x\\) hacemos\n\\[\n\\frac{d}{dx}f = \\frac{\\partial f}{\\partial w}\\frac{dw}{dx} + \\frac{\\partial f}{\\partial v}\\frac{dv}{dx}\\,.\n\\]\nPara poner un ejemplo más concreto, si queremos derivar \\(f(x) = \\cos(x)e^x + \\sin(x)\\), usamos\n\\[\n\\frac{d}{dx} (f + g) = \\frac{d}{dx} f + \\frac{d}{dx} g\\,,\n\\]\n\\[\n\\frac{d}{dx}(fg) = f \\frac{d}{dx} g + g \\frac{d}{dx} f\\,,\n\\]\n\\[\n\\frac{d}{dx}\\cos(x) = -\\sin(x)\\,,\\quad \\frac{d}{dx}\\sin(x) = \\cos(x)\\,,\\quad \\frac{d}{dx}e^x = e^x\\,.\n\\]\nEntonces\n\\[\n\\frac{d}{dx}((\\cos(x)e^x) + \\sin(x)) = \\frac{d}{dx}(\\cos(x)e^x) + \\frac{d}{dx}(\\sin(x))\\,,\n\\]\nAhora seguimos aplicando la regla de la cadena\n\\[\n\\frac{d}{dx}(\\cos(x)e^x + \\sin(x)) = \\cos(x)\\frac{d}{dx}e^x + e^x\\frac{d}{dx}\\cos(x) + \\cos(x) = e^x\\cos(x) - \\sin(x)e^x + \\cos(x)\\,,\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#autodiferenciación-en-modo-directo",
    "href": "16_derivadas.html#autodiferenciación-en-modo-directo",
    "title": "Derivadas numéricas",
    "section": "Autodiferenciación en modo directo",
    "text": "Autodiferenciación en modo directo\nLa autodiferenciación se usa cuando tenemos que calcular un gran número de derivadas. Esto ocurre por ejemplo en la solución numérica de ecuaciones diferenciales parciales, o en el aprendizaje automático donde se toma el gradiente de una función de costo respecto a miles de millones de parámetros.\nEn general, estos problemas se reducen a tomar la derivada del vector \\(\\vec{f} = (f_1, f_2, \\ldots, f_n)\\) con respecto a muchos parámetros \\(\\vec{x} = (x_1, x_2, \\ldots, x_m)\\), esto es\n\\[\n\\frac{\\partial \\vec{f}}{\\partial \\vec{x}} = \\begin{pmatrix}\n\\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\ldots & \\frac{\\partial f_1}{\\partial x_m}\\\\\n\\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\ldots & \\frac{\\partial f_2}{\\partial x_m}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n\\frac{\\partial f_n}{\\partial x_1} & \\frac{\\partial f_n}{\\partial x_2} & \\ldots & \\frac{\\partial f_n}{\\partial x_m}\n\\end{pmatrix}\\,.\n\\]\nEsta \\(f\\) puede ser por ejemplo una red neuronal. En general, esta es una función complicada que se expresa como la composición de varias funciones simples, por ejemplo \\(\\vec{f}(w_1(\\vec{x}), w_2(\\vec{x}), \\ldots, w_\\ell(\\vec{x}))\\). Entonces nuestra derivada toma la forma\n\\[\n\\frac{\\partial f_i}{\\partial x_j} = \\sum_k\\frac{\\partial f_i}{\\partial w_k}\\frac{\\partial w_k}{\\partial x_j}\\,.\n\\]\nEsta no es otra que una multiplicación de matrices. En general\n\\[\n\\frac{\\partial \\vec{f}}{\\partial \\vec{x}} = \\frac{\\partial \\vec{f}}{\\partial \\vec{w}^{(1)}}\\frac{\\partial \\vec{w}^{(1)}}{\\partial \\vec{w}^{(2)}}\\ldots\\frac{\\partial \\vec{w}^{(s)}}{\\partial \\vec{x}}\\,.\n\\]\nEsto parece un ejemplo artificial, pero algo así puede ocurrir en ecuaciones diferenciales. Por ejemplo supongamos que queremos modelar algunas características de un fluido \\(\\vec{f}\\) (presión, temperatura, etc) que a su vez van a depender de una serie de variables termodinámicas \\(\\vec{w}\\), que a su vez dependen de la posición del elemento de fluido \\(\\vec{x}\\) que depende del tiempo \\(t\\). Por simplicidad tomemos \\(\\vec{f}, \\vec{w}\\) y \\(\\vec{x}\\) como vectores de dimensión 3. Queremos calcular la derivada\n\\[\n\\frac{d\\vec{f}}{dt} =\n\\underbrace{\\frac{\\partial \\vec{f}}{\\partial \\vec{w}}}_{3\\times 3}\n\\;\\underbrace{\\frac{\\partial \\vec{w}}{\\partial \\vec{x}}}_{3\\times 3}\n\\;\\underbrace{\\frac{d\\vec{x}}{dt}}_{3\\times 1}\n\\]\nComo estamos estudiando métodos numéricos, queremos minimizar la cantidad de operaciones. Cada fila por columna de una multiplicación matricial son \\(3\\) multiplicaciones y \\(3\\) sumas.\nLa manera más eficiente sería multiplicar primero la matriz por el vector a la derecha. De esta forma tenemos un nuevo vector para multiplicar por la matriz restante. El total de operaciones es \\(3\\times 6 + 3\\times 6 = 36\\). En cambio si empezamos por multiplicar las dos matrices de la izquierda, el total de operaciones sería \\(3\\times 3\\times 6 + 3\\times 6 = 72\\). La diferencia es más pronunciada aún si aumentamos el número de variables o dimensiones.\nEmpezar por la derecha se llama “autodiferenciación en modo directo” (forward mode autodiff). Es el modo más eficiente si tenemos una función de muchos componentes (\\(\\vec{f}\\) en nuestro caso) que depende de pocos parámetros (\\(t\\) en nuestro caso). Además usa menos RAM que el modo inverso.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#autodiferenciación-en-modo-inverso",
    "href": "16_derivadas.html#autodiferenciación-en-modo-inverso",
    "title": "Derivadas numéricas",
    "section": "Autodiferenciación en modo inverso",
    "text": "Autodiferenciación en modo inverso\nEn aprendizaje automático tenemos usualmente lo contrario: Una función de pocas componentes que depende de muchos parámetros. En este caso es más eficiente multiplicar desde la derecha, lo que se llama autodiferenciación en modo inverso (reverse mode autodiff). Para un ejemplo sencillo, supongamos que \\(f\\) (con una sola componente) depende de tres cantidades \\(\\vec{w}^{(1)}\\) que a su vez dependen de otras tres cantidades \\(\\vec{w}^{(2)}\\) que a su vez dependen de tres entradas \\(\\vec{x}\\)\n\\[\n\\frac{\\partial f}{\\partial\\vec{x}} =\n\\underbrace{\\frac{\\partial f}{\\partial\\vec{w}^{(1)}}}_{1\\times 3}\n\\underbrace{\\frac{\\partial\\vec{w}^{(1)}}{\\partial\\vec{w}^{(2)}}}_{3\\times 3}\n\\underbrace{\\frac{\\partial\\vec{w}^{(2)}}{\\partial\\vec{x}}}_{3\\times 3}\\,.\n\\]\nVemos que en este caso es más eficiente ultipicar primero por la derecha, obteniendo \\(36\\) operaciones en vez de \\(72\\). Cuando aumenta el número de variables y parámetros la diferencia es aún mayor. La autodiferenciación en modo inverso es más eficiente cuando tenemos una función de pocos componentes que depende de muchas variables o parámetros. Por ejemplo en redes neuronales pueden ser miles de millones de parámetros tal que aplicar el modo inverso es crucial.\nSin embargo hay una dificultad. Para entenderla, consideremos la función compuesta \\(f(g(h(x)))\\). Cuando la queremos evaluar empezamos desde la derecha, es decir evaluamos primero \\(z = h(x)\\), luego \\(y = g(z)\\) y finalmente \\(f(y)\\). Es decir, evualuamos la función desde la derecha.\nPara derivar aplicamos la regla de la cadena\n\\[\n\\frac{d}{dx} f(g(h(x))) = f'(g(h(x)))\\times g'(h(x))\\times h'(x)\\,.\n\\]\nVemos que si queremos efectuar diferenciación en modo incerso, necesitamos primero calcular \\(f'(g(h(x)))\\), para lo cual necesitamos \\(g(h(x))\\). Después debemos calcular \\(g'(h(x))\\) para lo cual necesitamos saber \\(h(x)\\), y así sucesivamente. En pocas palabras, necesitamos los pasos intermedios de la evaluación de la función compuesta.\nPara lograrlo, primero hacemos un paso hacia adelante (“forward pass”) donde evaluamos \\(f(g(h(x)))\\). En este, guatdamos en memoria todos los resultados intermedios (\\(g(h(x)), h(x),\\)) en la memoria (en una estructura llamada “tape”). Luego hacemos un paso hacia atrás (“reverse pass”) donde evaluamos \\(f'(g(h(x)))\\) usando los resultados guardados en la memoria.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#tarea-8.1",
    "href": "16_derivadas.html#tarea-8.1",
    "title": "Derivadas numéricas",
    "section": "Tarea 8.1",
    "text": "Tarea 8.1\nLos siguientes datos corresponden al cálculo numérico de una cierta propiedad estadística de la distribución de materia en el universo (el espectro de potencias) \\(P(k)\\) (segunda columna) en función del modo de Fourier \\(k\\) (primera columna).\nUse la derivada numérica para encontrar \\(d\\ln P/d\\ln k\\) en cada punto (es decir, la derivada del logaritmo de \\(P\\) respecto a \\(y\\) donde \\(y = \\ln k\\)).\nPara estimar el error cometido en esta derivada numérica compare el resultado de la fórmula a tres puntos con el resultado de la fórmula a cinco puntos. Será necesario usar las fórmulas a tres y cinco puntos en los extremos que se encuentran en este mismo notebook.\n\ndatos = np.array([       [5.531683013105e-04,       1.070304113861e+12], \n       [5.910227121702e-04,       1.139622191891e+12], \n       [6.315688849627e-04,       1.213481232452e+12], \n       [6.750065137883e-04,       1.292169597309e+12], \n       [7.215301959429e-04,       1.375954296780e+12], \n       [7.713235180257e-04,       1.465069697719e+12], \n       [8.245525173319e-04,       1.559705507566e+12], \n       [8.813589235833e-04,       1.659994890361e+12], \n       [9.418537183337e-04,       1.766003776663e+12], \n       [1.006111625261e-03,       1.877722471320e+12], \n       [1.074167130425e-03,       1.995060685935e+12], \n       [1.146012510269e-03,       2.117846703996e+12], \n       [1.221598126720e-03,       2.245831037960e+12], \n       [1.300834972303e-03,       2.378694410099e+12], \n       [1.383599172303e-03,       2.516052095865e+12], \n       [1.469737934874e-03,       2.657475892684e+12], \n       [1.559076324033e-03,       2.802524407596e+12], \n       [1.651424225675e-03,       2.950729179407e+12], \n       [1.746582964833e-03,       3.101618970269e+12], \n       [1.844351177716e-03,       3.254730780491e+12], \n       [1.944529704896e-03,       3.409618695392e+12], \n       [2.046925420592e-03,       3.565860320889e+12], \n       [2.151354028418e-03,       3.723061333248e+12], \n       [2.257641930146e-03,       3.880858018481e+12] ])",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#tarea-8.2",
    "href": "16_derivadas.html#tarea-8.2",
    "title": "Derivadas numéricas",
    "section": "Tarea 8.2",
    "text": "Tarea 8.2\nEncuentre la separación óptima entre puntos para el ejemplo con ruido hecho en clase.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#tarea-8.3",
    "href": "16_derivadas.html#tarea-8.3",
    "title": "Derivadas numéricas",
    "section": "Tarea 8.3",
    "text": "Tarea 8.3\nConsidere la función:\n\\[\nf(x, y) = \\ln(xy) + x^2 y - \\cos(y)\n\\]\n\nConstruya el grafo computacional que representa la función.\nRealice una pasada hacia adelante para calcular los valores de todas las variables intermedias en el punto $ x = 2 $, $ y = 1 $.\nSimultáneamente, calcule las derivadas con respecto a $ x $ en cada nodo utilizando las reglas de autodiferenciación en modo directo.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#tarea-8.4",
    "href": "16_derivadas.html#tarea-8.4",
    "title": "Derivadas numéricas",
    "section": "Tarea 8.4",
    "text": "Tarea 8.4\nDada la función:\n\\[\nf(u, v) = e^{uv} + u \\sin(v) + v^3\n\\]\n\nConstruya el grafo computacional con nodos para cada operación, indicando claramente las dependencias y descomponiéndolo en nodos.\nRealice una pasada hacia adelante en el punto \\(u = 0\\) \\(v = \\pi/2\\), calcule y registre el valor de cada nodo.\nRealice una pasada hacia atrás, inicializando la derivada del nodo de salida en el resultado obtenido en el paso anterior y propagando gradientes hacia atrás a través del grafo utilizando la regla de la cadena.\nCalcule los valores finales de $ $ y $ $.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "16_derivadas.html#tarea-8.5",
    "href": "16_derivadas.html#tarea-8.5",
    "title": "Derivadas numéricas",
    "section": "Tarea 8.5",
    "text": "Tarea 8.5\nConsidere los siguientes datos que son el resultado de cinco simulaciones muy costosas.\n\n\n\n\\(\\sigma\\)\n\\(n\\)\n\n\n\n\n\\(0.75\\)\n\\(1.1324\\times 10^{-3}\\)\n\n\n\\(0.77\\)\n\\(1.1376\\times 10^{-3}\\)\n\n\n\\(0.79\\)\n\\(1.1386\\times 10^{-3}\\)\n\n\n\\(0.81\\)\n\\(1.1454\\times 10^{-3}\\)\n\n\n\\(0.83\\)\n\\(1.1474\\times 10^{-3}\\)\n\n\n\nEstime la derivada de \\(n\\) respecto a \\(\\sigma\\) así como el error cometido en \\(\\sigma = 0.79\\).\nPara estimar la derivada, use la fórmula a tres puntos dada en clase.\nPara estimar el error use la fórmula de error. Esta fórmula del error contiene una tercera derivada. Esta tercera derivada se puede obtener a partir de una fórmula a cinco puntos para la tercera derivada.\nPara encontrar la expresión para la tercera derivada a cinco puntos use la expansión en Taylor de \\(f(x_o + h)\\), \\(f(x_o - h)\\), \\(f(x_o + 2h)\\) y \\(f(x_o - 2h)\\).\nAdemás considere el hecho que \\(n\\) tiene un ruido (\\(\\Delta n = 10^{-6}\\)). Compare con lo anterior para saber si el tamaño \\(h\\) del paso fue el adecuado. ¿Es necesario un paso más pequeño o más grande?",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Derivadas numéricas"
    ]
  },
  {
    "objectID": "07_distribuciones.html",
    "href": "07_distribuciones.html",
    "title": "Distribuciones de Probabilidad",
    "section": "",
    "text": "Consideremos un experimento que puede dar un resultado positivo con probabilidad \\(p\\) o negativo con probabilidad \\(1 - p\\). Preguntamos cuál es la probabilidad de obtener \\(s\\) resultados positivos cuando se realiza el experimento \\(n\\) veces de manera independiente.\nA manera de ejemplo preguntemos primero cuál es la probabilidad de obtener \\(3\\) positivos cuando se realiza el experimento \\(4\\) veces. Estos tres resultados positivos pueden aparecer de las siguientes maneras \\[\n\\text{+++-},\\,\\text{++-+},\\,\\text{+-++},\\,\\text{-+++}\\,.\n\\] La probabilidad de obtener el primer resultado es \\[\np\\times p\\times p\\times (1-p) = p^3 (1-p)\\,.\n\\] La probabilidad de las otras tres posibilidades es igual y entonces \\[\nP(3;4,p) = 4 p^3(1-p)\\,.\n\\]\nLa fórmula general es\n\\[\nP(s;n,p) = \\frac{n!}{s!(n-s)!} p^s (1-p)^{n - s}\n\\]\n\nfrom scipy.special import comb\n\ndef binomial(s, n, p):\n    return comb(n, s)*p**s*(1-p)**(n - s)\n\n\nimport matplotlib.pyplot as plt\n\n\ndef probs(n, p):\n    return [binomial(s, n, p) for s in range(n+1)]\n\n\nfig = plt.figure(figsize=(8,20), dpi= 100)\n\nax1 = fig.add_subplot(8,2,1)\nax2 = fig.add_subplot(8,2,2)\nax3 = fig.add_subplot(8,2,3)\nax4 = fig.add_subplot(8,2,4)\nax5 = fig.add_subplot(8,2,5)\nax6 = fig.add_subplot(8,2,6)\nax7 = fig.add_subplot(8,2,7)\nax8 = fig.add_subplot(8,2,8)\n\nax1.bar(range(4+1), probs(4,0.5))\nax2.bar(range(5+1), probs(5,0.5))\nax3.bar(range(15+1), probs(15,0.5))\nax4.bar(range(50+1), probs(50,0.5))\nax5.bar(range(5+1), probs(5,0.1))\nax6.bar(range(15+1), probs(15,0.1))\nax7.bar(range(5+1), probs(5,0.9))\nax8.bar(range(15+1), probs(15,0.9))\n        \nax1.set_title('s = 4, p = 0.5')\nax2.set_title('s = 5, p = 0.5')\nax3.set_title('s = 15, p = 0.5')\nax4.set_title('s = 50, p = 0.5')\nax5.set_title('s = 5, p = 0.1')\nax6.set_title('s = 15, p = 0.1')\nax7.set_title('s = 5, p = 0.9')\nax8.set_title('s = 15, p = 0.9')\n\nfig.tight_layout(pad=2.0)\n\n\nfig.show()\n\n\n\n\n\n\n\n\n\nValor esperado: \\(\\langle n \\rangle = rp\\)\nVarianza: \\(\\sigma^2 = np(1-p)\\)\n\n\nimport random\nimport numpy as np\n\ndef realizacion(r, p):\n    probs = np.random.rand(r)\n    return probs &lt; p\n\ndef num_exitos(num_realizaciones, r, p):\n    # probando me dí cuenta que al sumar me regresa el número\n    # de elementos que son True\n    return np.array([sum(realizacion(r, p)) for i in range(num_realizaciones)])\n\n\nnum_exitos(3, 10, 0.2).mean()\n\nnp.float64(1.6666666666666667)\n\n\n\nnum_exitos(10000, 10, 0.2).mean()\n\nnp.float64(1.9851)\n\n\n\nnum_exitos(10000, 10, 0.2).std()\n\nnp.float64(1.2755754426924344)\n\n\n\nnp.sqrt(10*0.2*0.8)\n\nnp.float64(1.2649110640673518)",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Distribuciones de probabilidad"
    ]
  },
  {
    "objectID": "07_distribuciones.html#tarea-3.6",
    "href": "07_distribuciones.html#tarea-3.6",
    "title": "Distribuciones de Probabilidad",
    "section": "Tarea 3.6",
    "text": "Tarea 3.6\nUn cierto sensor se deja abierto por un segundo. El sensor consiste en \\(r\\) pixeles y en promedio el sensor es golpeado por \\(2\\) partículas por segundo, tal que la probabilidad de detectar una partícula en un pixel dado es de \\(2/r\\) (para \\(r \\gg 2\\)). Grafique la distribución de probabilidad de observar \\(n\\) partículas para un pixel dado, en función de \\(n\\), para diferentes valores de \\(r\\):\n\nUsando la distribución binomial.\n¿Cuándo es posible usar la distribución de Poisson?",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Distribuciones de probabilidad"
    ]
  },
  {
    "objectID": "07_distribuciones.html#tarea-3.7",
    "href": "07_distribuciones.html#tarea-3.7",
    "title": "Distribuciones de Probabilidad",
    "section": "Tarea 3.7",
    "text": "Tarea 3.7\nEn ausencia de una señal, un cierto detector de partículas en promedio detecta \\(2\\) impactos por segundo debidos a una contaminación de fondo. Durante una medición se obtienen las siguientes observaciones (esta es una lista del número de señales por cada segundo de duración del experimento):\n\nmediciones = [2, 3, 3, 3, 0, 1, 2, 2, 0, 4, 10, 0, 2, 4, 6, 3, 2, 1, 1, 1]\n\nCompare estos resultados con la distribución de Poisson. Discuta en cuáles intervalos cree usted que se detectó una señal que no es contaminación.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Distribuciones de probabilidad"
    ]
  },
  {
    "objectID": "07_distribuciones.html#tarea-3.8",
    "href": "07_distribuciones.html#tarea-3.8",
    "title": "Distribuciones de Probabilidad",
    "section": "Tarea 3.8",
    "text": "Tarea 3.8\nUn sensor recibe en promedio \\(50\\) partículas por minuto. Ese sensor está diseñado tal que puede detectar si fue impactado por al menos una partícula, pero no tiene ninguna información sobre cuántas partículas lo impactaron.\nEl sensor se encendió durante un segundo e indicó impacto. Grafique la distribución de probabilidad de que ese pixel haya sido impactado por \\(n\\) partículas.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Distribuciones de probabilidad"
    ]
  },
  {
    "objectID": "07_distribuciones.html#tarea-3.9",
    "href": "07_distribuciones.html#tarea-3.9",
    "title": "Distribuciones de Probabilidad",
    "section": "Tarea 3.9",
    "text": "Tarea 3.9\nConsidere los siguientes conjuntos de mediciones de una cierta cantidad que tiene un valor verdadero de \\(10\\) y la medición tiene un error gaussiano de \\(\\pm 0.1\\) a un nivel de confiaza del \\(68\\%\\). ¿Cuál de ellos es anómalo? ¿Por qué? ¿Qué interpretación le da?\n\n# Conjunto 1\nc1 = [10.09728388, 14.00677546,  9.97330124, 10.03403577, 10.11014852,\n        9.85702412, 10.06725561, 10.08586217,  9.99805356, 10.09222044,\n        9.96873542, 10.0603082 ,  9.78777855, 10.01658336, 10.12528138,\n       14.1191067 ,  14.88058074,  9.93142885, 10.36578158, 10.09212493,\n        9.88930781,  9.9849203 , 10.02020365, 10.06761813, 10.00167307,\n       14.14360885,  9.97572225, 10.15246422,  9.99133822,  9.90424116,\n       10.10501793,  9.91869535, 10.07039047, 10.06006262, 10.01032325,\n       10.00433072,  9.94767238,  9.93286478, 10.03173287,  9.92066554,\n        9.97108415,  9.83034826,  9.94135165,  9.97791295, 10.16112762,\n       10.06797202, 10.0263643 ,  9.97961471,  9.78969763, 10.05166943,\n        9.91131264,  9.98634534,  9.97974543, 10.07362277,  9.88424591,\n        9.99315227, 13.08325547, 10.02539059, 10.1065997 ,  9.83627837,\n        9.96746961, 10.11354781,  9.98733076,  9.86269556, 10.06259149,\n        9.73748286, 10.12718777, 10.02529891,  9.96605039, 10.03798876,\n       10.02311967, 14.09473823,  9.9550051 , 10.17043078, 10.09425491,\n       10.09005108, 10.01950653, 14.02402728,  9.89166114,  9.89202929,\n        9.84356976,  9.95499455,  9.98309913,  9.9321069 , 10.02759998,\n       10.01884409,  9.93640317,  9.84393786, 10.0192927 , 10.17990282,\n        9.89937182, 10.02106925, 10.01263725,  9.89573905, 10.11424838,\n       10.08980671, 15.03267925,  9.84762111,  9.96499894,  9.91684104]\n\n# Conjunto 2\nc2 = [10.13630034,  9.97264447, 10.04529035, 10.09188684, 10.00855386,\n        9.90416116, 10.06281985, 10.10757175,  9.91838149, 10.0493961 ,\n       10.02446199, 10.10448656,  9.77283484,  9.85600398,  9.90039543,\n        9.82106987, 10.04031262, 10.06144001, 10.10988717,  9.74308934,\n        9.99702215,  9.9859704 ,  9.89807371,  9.99585103,  9.93988323,\n        9.89990546, 10.05643454,  9.94774945, 10.05428393,  9.88404769,\n       10.00726402,  9.92586135,  9.961164  , 10.01782874,  9.92329839,\n       10.06092894,  9.95886161,  9.89049626, 10.07754125,  9.83061899,\n       10.13919176,  9.96898158, 10.06438291, 10.02476394,  9.81875984,\n       10.0655806 , 10.00193677,  9.96395486,  9.89494378,  9.98505133,\n        9.95691616,  9.97416592, 10.10692325, 10.18250899, 10.10749261,\n       10.1037641 ,  9.86450491,  9.85218941, 10.02603336,  9.89537915,\n        9.89940417,  9.91235537, 10.05523101, 10.08142251, 10.01086045,\n        9.96034572, 10.1482815 ,  9.99360685,  9.91925958, 10.10239163,\n       10.03106757,  9.93136713, 10.01773794, 10.05200499, 10.10178781,\n        9.87483023,  9.94272878,  9.9671527 ,  9.99712438,  9.91594426,\n        9.99679193,  9.88884633, 10.07940955,  9.90776214, 10.0123038 ,\n        9.96426746, 10.01747625, 10.0392178 , 10.05489883,  9.67062975,\n       10.06149946, 10.09805716,  9.83077801, 10.00208448, 10.02687927,\n        9.99354725,  9.96120681,  9.94538711,  9.96279696,  9.86707357]\n\n# Conjunto 3\nc3 = [ 9.9032974 , 10.06746832,  9.98360179, 10.02011113, 10.01317417,\n       10.09982861,  9.93307724, 10.04944268,  9.9000297 ,  9.96237539,\n        9.91807876, 10.00338938,  9.99543713, 10.04674212, 10.08063919,\n        9.99627534, 10.04558084, 10.06576491, 10.01787305,  9.90861284,\n        9.99567107,  9.92934922, 10.07999909, 10.04248524, 10.04884959,\n        9.90839636, 10.04266824,  9.98720842,  9.92392857, 10.00288059,\n        9.96299254, 10.06967059,  9.94880142,  9.92020426, 10.07145123,\n        9.91179764,  9.95914293,  9.98200017,  9.93190323,  9.92372118,\n        9.90601205, 10.09884219, 10.04411164,  9.91673593, 10.09883873,\n       10.06399646, 10.05061298, 10.02253924, 10.00159467,  9.98862911,\n        9.99792681,  9.96149526,  9.93018115,  9.95211   ,  9.94530659,\n        9.9713637 ,  9.91789999, 10.06730498, 10.02326566, 10.06438782,\n        9.9794271 , 10.06077859,  9.99556797,  9.98272556, 10.01617789,\n        9.95166775, 10.00406298, 10.02627066,  9.98342611, 10.03584277,\n        9.98478095, 10.0834946 , 10.01403125, 10.04629496, 10.01444209,\n       10.02043805, 10.01325408,  9.96317469,  9.93915936, 10.04026662,\n       10.06055512,  9.98923231, 10.07144049, 10.09482468,  9.94512088,\n       10.07417098, 10.00802839, 10.01338588,  9.96553168,  9.96240508,\n        9.9963694 ,  9.96827214,  9.91378322,  9.96249148, 10.02461909,\n        9.98179311,  9.95811448,  9.9903446 , 10.01001352, 10.06304347]",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Distribuciones de probabilidad"
    ]
  },
  {
    "objectID": "07_distribuciones.html#tarea-3.10",
    "href": "07_distribuciones.html#tarea-3.10",
    "title": "Distribuciones de Probabilidad",
    "section": "Tarea 3.10",
    "text": "Tarea 3.10\nUn cierto detector de partículas es golpeado por \\(100\\) partículas cada minuto, todas con la misma velocidad de \\(0.99 c\\) donde \\(c\\) es la velocidad de la luz. El detector mide la velocidad de lás partículas con un error de \\(0.01 c\\).\nEscriba un código que simule la distribución de velocidades observadas por el detector en 10 segundos. (Pista: Consulte cómo extraer un número aleatorio de una distribución discreta).\nGrafique la distribuciòn de velocidades simulada.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Distribuciones de probabilidad"
    ]
  },
  {
    "objectID": "plan.html",
    "href": "plan.html",
    "title": "Métodos Numéricos y Probabilidades",
    "section": "",
    "text": "Las (los) físicas (os) siempre han llevado la punta de lanza del desarrollo tecnológico. Desde la revolución industrial hasta el desarrollo de la computación cuántica, los (las) físicos (as) han tenido un manejo profundo de la tecnología que les permite hacer nuevos descubrimientos o inventos. Esto es aún más cierto en el siglo XXI, en el cual la mayoría de las (los) licenciadas (os) en física de los países de alto desarrollo tecnológico trabajan en el sector privado creando y mejorando las herramientas informáticas, financieras y estadísticas que usamos todos los días. Esto se debe a que a lo largo de sus carreras adquieren un conocimiento íntimo de la tecnología de punta al intentar aplicarla a problemas científicos abiertos.\nSon muy pocos los problemas que admiten una solución sencilla de lápiz y papel. Para la mayoría de nuevos desarrollos es necesario usar el computador. Esto es verdad tanto para analizar los datos obtenidos en los experimentos, como para resolver las ecuaciones diferenciales que aparecen en la física teórica. Incluso quienes hacen un trabajo puramente analítico se apoyan en herramientas computacionales para los cálculos que son cada vez más complejos.\nEn este curso aprenderemos a usar las herramientas numéricas disponibles para atacar problemas físicos y al hacerlo aprenderemos a usar plataformas, paquetes y lenguajes de programación modernos.\n\n\n\n\nR. L. Burden, D. J. Faires, A. M. Burden, “Numerical Analysis”, 10ma edición, Cengage Learning, 2016 (NA)\nT. A. Driscoll, R. J. Braun, “Funamentals of Numerical Computation”, 2da edición, SIAM, 2022 (FNC)\nB. R. Martin, “Statistics for Physical Sciences”. Elsevier, 2012 (S)\nA. B. Downey, “Think Python,” 2da edición, O’Reilly, 2015. (TP)\n\n\n\n\nSe indican las fechas y temas de cada clase, junto con las secciones de los libros a las que corresponden.\n1- Introducción\n\n¿Cómo funciona una CPU?, 7 de agosto.\nRepaso de Python, 12 de agosto.\nNumpy y arrays, 14 de agosto.\nRepresentación binaria de números decimales, número de condicionamiento 19 de agosto\nAlgoritmos y estabilidad 21 de agosto\n\n2- Probabilidades\n\nPropiedades básicas de la probabilidad, 26 de agosto\nDistribuciones de probabilidad, 28 de agosto\nVarias variables aleatorias, 2 de septiembre\nSuma de muchas variables aleatorias y teorema central del límite, 4 de septiembre\nInformación y entropía, 9 de septiembre\n\nPrueba: 23 de septiembre\n3- Cálculo numérico\n\nSolución de sistemas de ecuaciones lineales: Inversión de matrices, 11 de septiembre\nBúsqueda de raíces: Métodos de bisección y Newton, 25 de septiembre\nInterpolación, 30 de septiembre\nDerivadas numéricas y autodiferenciación, 2 de octubre\nIntegración numérica simple y adaptativa, 7 de octubre\nIntegración numérica por método de Gauss, 9 de octubre\n\nPrueba: 16 de octubre\n4- Solución numérica de ecuaciones diferenciales ordinarias\n\nMétodos de Euler y Taylor, 14 de octubre\nMétodo de Runge Kutta, 21 de octubre\nMétodo de Runge Kutta adaptativo, 23 de octubre\nMétodos de múltiples pasos y método de Adams, 4 de noviembre\nSistemas de ecuaciones diferenciales y ecuaciones de alto orden, 6 de noviembre\n\nPrueba: 13 de noviembre\n5- Optimización y otros algoritmos importantes\n\nAjuste de curvas y bondad de ajuste, 11 de noviembre\nOptimización por descenso de gradiente, 18 de noviembre\nIntroducción a las redes neuronales, 20 de noviembre\nMétodos de Monte Carlo y/o transformada rápida de Fourier, 25 de noviembre\n\nRecuperativa: 27 de noviembre Examen: Definido por Instituto\n\n\n\nLa evaluación se hará por tareas y pruebas.\nAl final de cada clase habrán 5 tareas para un total de 10 tareas cada dos clases. De estas 10 tareas se le asignará de forma aleatoria una tarea a cada estudiante. De esta manera el estudiante deberá entregar aproximadamente 11 tareas a lo largo del curso. El 50% de la nota final es el promedio de las notas de las tareas.\nLas tareas se entregan dos clases después de haber sido asignadas.\nSe evaluará lo siguiente:\nEl código funciona (4 puntos): Si el código pedido hace lo que deberíacumplir sin errores en ningún caso, la estudiante obtendrá los 4 puntos. Si existen casos especiales en los cuales el código no funciona, pero funciona en la mayoría de los casos, la estudiante obtendrá 3 puntos. Si el código no funciona pero el error es menor (algún detalle de sintaxis, alguna variable mal nombrada, alguna excepción de Python difícil de prever), el estudiante obtendrá 2 puntos. Si el código no funciona el estudiante obtendrá 1 punto. Si no entrega la tarea el estudiante obtendrá 0 puntos.\nEl código es legible (+2 puntos): Si el código está comentado en cada paso el estudiante obtendrá +1 punto. Si el código es fácil de entender, está bien organizado, las variables tienen nombres que corresponden a lo que representan la estudiante obtendrá +1 punto.\nLa nota de la tarea = # de puntos + 1.\nLa otra mitad de la nota será el promedio de tres pruebas realizadas a lo largo del semestre. Las pruebas consisten en ejercicios sencillos basados en lo visto en clase y en las tareas.\nLas siguientes son las fechas de las pruebas:\nPrueba: 10 de septiembre Prueba: 5 de noviembre Prueba: 25 de noviembre Recuperativa: 26 de noviembre Examen: 10 de diciembre\n\n\n\nLos estudiantes no están obligados a ir a las ayudantías, pero obviamente quien asista estará mejor preparado para las pruebas y los exámenes porque sabrá cuáles son los problemas que entran. Las tareas se entregarán en formato electrónico por medio de la plataforma GitHub. Se usa esta en vez del Aula Virtual dado su uso extenso en el mundo profesional.\nHágale preguntas al profesor a la dirección jorge.norena@pucv.cl, o en el horario de atención. Hacer preguntas ayuda a aprender y hace más ameno el trabajo del profesor. La clase empieza puntual si hay al menos un estudiante presente, por respeto a los que llegan a tiempo.\n\n\n\nPOR FAVOR HAGAN PREGUNTAS DURANTE LA CLASE, LAS AYUDANTÍAS, POR CORREO ELECTRÓNICO, EN LOS HORARIOS DE ATENCIÓN Y POR CUALQUIER OTRO MEDIO QUE PUEDA.\nSi quiere conversar hágalo por chat en su teléfono para que el ruido no distraiga a los demás. Use el teléfono para tomarle fotos a la pizarra cuando quiera recordar algo.\n\n\n\nPuede en cualquier momento hacer preguntas por correo electrónico.\nCorreo electrónico profesor: jorge.norena@pucv.cl Correo electrónico de la ayudante:\nTambién puede pasar por la oficina del profesor en cualquier momento.\nEl horario de atención reservado es una hora después de cada clase."
  },
  {
    "objectID": "plan.html#motivación",
    "href": "plan.html#motivación",
    "title": "Métodos Numéricos y Probabilidades",
    "section": "",
    "text": "Las (los) físicas (os) siempre han llevado la punta de lanza del desarrollo tecnológico. Desde la revolución industrial hasta el desarrollo de la computación cuántica, los (las) físicos (as) han tenido un manejo profundo de la tecnología que les permite hacer nuevos descubrimientos o inventos. Esto es aún más cierto en el siglo XXI, en el cual la mayoría de las (los) licenciadas (os) en física de los países de alto desarrollo tecnológico trabajan en el sector privado creando y mejorando las herramientas informáticas, financieras y estadísticas que usamos todos los días. Esto se debe a que a lo largo de sus carreras adquieren un conocimiento íntimo de la tecnología de punta al intentar aplicarla a problemas científicos abiertos.\nSon muy pocos los problemas que admiten una solución sencilla de lápiz y papel. Para la mayoría de nuevos desarrollos es necesario usar el computador. Esto es verdad tanto para analizar los datos obtenidos en los experimentos, como para resolver las ecuaciones diferenciales que aparecen en la física teórica. Incluso quienes hacen un trabajo puramente analítico se apoyan en herramientas computacionales para los cálculos que son cada vez más complejos.\nEn este curso aprenderemos a usar las herramientas numéricas disponibles para atacar problemas físicos y al hacerlo aprenderemos a usar plataformas, paquetes y lenguajes de programación modernos."
  },
  {
    "objectID": "plan.html#lecturas-sugeridas",
    "href": "plan.html#lecturas-sugeridas",
    "title": "Métodos Numéricos y Probabilidades",
    "section": "",
    "text": "R. L. Burden, D. J. Faires, A. M. Burden, “Numerical Analysis”, 10ma edición, Cengage Learning, 2016 (NA)\nT. A. Driscoll, R. J. Braun, “Funamentals of Numerical Computation”, 2da edición, SIAM, 2022 (FNC)\nB. R. Martin, “Statistics for Physical Sciences”. Elsevier, 2012 (S)\nA. B. Downey, “Think Python,” 2da edición, O’Reilly, 2015. (TP)"
  },
  {
    "objectID": "plan.html#programa",
    "href": "plan.html#programa",
    "title": "Métodos Numéricos y Probabilidades",
    "section": "",
    "text": "Se indican las fechas y temas de cada clase, junto con las secciones de los libros a las que corresponden.\n1- Introducción\n\n¿Cómo funciona una CPU?, 7 de agosto.\nRepaso de Python, 12 de agosto.\nNumpy y arrays, 14 de agosto.\nRepresentación binaria de números decimales, número de condicionamiento 19 de agosto\nAlgoritmos y estabilidad 21 de agosto\n\n2- Probabilidades\n\nPropiedades básicas de la probabilidad, 26 de agosto\nDistribuciones de probabilidad, 28 de agosto\nVarias variables aleatorias, 2 de septiembre\nSuma de muchas variables aleatorias y teorema central del límite, 4 de septiembre\nInformación y entropía, 9 de septiembre\n\nPrueba: 23 de septiembre\n3- Cálculo numérico\n\nSolución de sistemas de ecuaciones lineales: Inversión de matrices, 11 de septiembre\nBúsqueda de raíces: Métodos de bisección y Newton, 25 de septiembre\nInterpolación, 30 de septiembre\nDerivadas numéricas y autodiferenciación, 2 de octubre\nIntegración numérica simple y adaptativa, 7 de octubre\nIntegración numérica por método de Gauss, 9 de octubre\n\nPrueba: 16 de octubre\n4- Solución numérica de ecuaciones diferenciales ordinarias\n\nMétodos de Euler y Taylor, 14 de octubre\nMétodo de Runge Kutta, 21 de octubre\nMétodo de Runge Kutta adaptativo, 23 de octubre\nMétodos de múltiples pasos y método de Adams, 4 de noviembre\nSistemas de ecuaciones diferenciales y ecuaciones de alto orden, 6 de noviembre\n\nPrueba: 13 de noviembre\n5- Optimización y otros algoritmos importantes\n\nAjuste de curvas y bondad de ajuste, 11 de noviembre\nOptimización por descenso de gradiente, 18 de noviembre\nIntroducción a las redes neuronales, 20 de noviembre\nMétodos de Monte Carlo y/o transformada rápida de Fourier, 25 de noviembre\n\nRecuperativa: 27 de noviembre Examen: Definido por Instituto"
  },
  {
    "objectID": "plan.html#evaluación",
    "href": "plan.html#evaluación",
    "title": "Métodos Numéricos y Probabilidades",
    "section": "",
    "text": "La evaluación se hará por tareas y pruebas.\nAl final de cada clase habrán 5 tareas para un total de 10 tareas cada dos clases. De estas 10 tareas se le asignará de forma aleatoria una tarea a cada estudiante. De esta manera el estudiante deberá entregar aproximadamente 11 tareas a lo largo del curso. El 50% de la nota final es el promedio de las notas de las tareas.\nLas tareas se entregan dos clases después de haber sido asignadas.\nSe evaluará lo siguiente:\nEl código funciona (4 puntos): Si el código pedido hace lo que deberíacumplir sin errores en ningún caso, la estudiante obtendrá los 4 puntos. Si existen casos especiales en los cuales el código no funciona, pero funciona en la mayoría de los casos, la estudiante obtendrá 3 puntos. Si el código no funciona pero el error es menor (algún detalle de sintaxis, alguna variable mal nombrada, alguna excepción de Python difícil de prever), el estudiante obtendrá 2 puntos. Si el código no funciona el estudiante obtendrá 1 punto. Si no entrega la tarea el estudiante obtendrá 0 puntos.\nEl código es legible (+2 puntos): Si el código está comentado en cada paso el estudiante obtendrá +1 punto. Si el código es fácil de entender, está bien organizado, las variables tienen nombres que corresponden a lo que representan la estudiante obtendrá +1 punto.\nLa nota de la tarea = # de puntos + 1.\nLa otra mitad de la nota será el promedio de tres pruebas realizadas a lo largo del semestre. Las pruebas consisten en ejercicios sencillos basados en lo visto en clase y en las tareas.\nLas siguientes son las fechas de las pruebas:\nPrueba: 10 de septiembre Prueba: 5 de noviembre Prueba: 25 de noviembre Recuperativa: 26 de noviembre Examen: 10 de diciembre"
  },
  {
    "objectID": "plan.html#normas",
    "href": "plan.html#normas",
    "title": "Métodos Numéricos y Probabilidades",
    "section": "",
    "text": "Los estudiantes no están obligados a ir a las ayudantías, pero obviamente quien asista estará mejor preparado para las pruebas y los exámenes porque sabrá cuáles son los problemas que entran. Las tareas se entregarán en formato electrónico por medio de la plataforma GitHub. Se usa esta en vez del Aula Virtual dado su uso extenso en el mundo profesional.\nHágale preguntas al profesor a la dirección jorge.norena@pucv.cl, o en el horario de atención. Hacer preguntas ayuda a aprender y hace más ameno el trabajo del profesor. La clase empieza puntual si hay al menos un estudiante presente, por respeto a los que llegan a tiempo."
  },
  {
    "objectID": "plan.html#recomendaciones",
    "href": "plan.html#recomendaciones",
    "title": "Métodos Numéricos y Probabilidades",
    "section": "",
    "text": "POR FAVOR HAGAN PREGUNTAS DURANTE LA CLASE, LAS AYUDANTÍAS, POR CORREO ELECTRÓNICO, EN LOS HORARIOS DE ATENCIÓN Y POR CUALQUIER OTRO MEDIO QUE PUEDA.\nSi quiere conversar hágalo por chat en su teléfono para que el ruido no distraiga a los demás. Use el teléfono para tomarle fotos a la pizarra cuando quiera recordar algo."
  },
  {
    "objectID": "plan.html#horarios-de-atención-y-contacto",
    "href": "plan.html#horarios-de-atención-y-contacto",
    "title": "Métodos Numéricos y Probabilidades",
    "section": "",
    "text": "Puede en cualquier momento hacer preguntas por correo electrónico.\nCorreo electrónico profesor: jorge.norena@pucv.cl Correo electrónico de la ayudante:\nTambién puede pasar por la oficina del profesor en cualquier momento.\nEl horario de atención reservado es una hora después de cada clase."
  },
  {
    "objectID": "05_algoritmos_y_estabilidad.html",
    "href": "05_algoritmos_y_estabilidad.html",
    "title": "Algoritmos y estabilidad",
    "section": "",
    "text": "Evaluamos los algoritmos según tres criterios: Eficiencia, convergencia y estabilidad.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Algoritmos y estabilidad"
    ]
  },
  {
    "objectID": "05_algoritmos_y_estabilidad.html#tarea-2.6",
    "href": "05_algoritmos_y_estabilidad.html#tarea-2.6",
    "title": "Algoritmos y estabilidad",
    "section": "Tarea 2.6",
    "text": "Tarea 2.6\nDiscuta la estabilidad de los problemas presentados en las tareas 2.3 y 2.4.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Algoritmos y estabilidad"
    ]
  },
  {
    "objectID": "05_algoritmos_y_estabilidad.html#tarea-2.7",
    "href": "05_algoritmos_y_estabilidad.html#tarea-2.7",
    "title": "Algoritmos y estabilidad",
    "section": "Tarea 2.7",
    "text": "Tarea 2.7\nA partir de los siguientes códigos, explique si el número de pasos es \\(\\mathcal{O}(n^c)\\) (y cuánto vale \\(c\\)), \\(\\mathcal{O}(\\log_2 n)\\) o \\(\\mathcal{O}(2^n)\\) y por qué. Pista: Para el último código aumente n y vea cómo cambia el número de pasos s. Grafique n contra s e intente deducir a qué corresponde.\nn = 1000\ns = 0 \nfor i in range(n):\n    for j in range(n):\n        if i &lt; j:\n            s = s + i + j\nn = 1000\ns = 0\nfor i in range(n):\n    for j in range(i):\n        s = s + i + j\nCuidado, consulte en internet lo que hace el enunciado sum() antes de responder\nn = 1000\ns = 0\nfor i in range(n):\n    s = s + i + sum(range(n))\n\nn = 100000\nsmall = 0\np = 146\nattempt = n//2\nnot_found = True\ns = 0\nwhile not_found:\n    s = s + 1\n    if attempt &gt; p:\n        n = attempt\n    elif attempt &lt; p:\n        small = attempt\n    else:\n        print('Encontré', attempt, 'luego de', s, 'pasos')\n        break\n    attempt = (n + small)//2\n\nEncontré 146 luego de 11 pasos",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Algoritmos y estabilidad"
    ]
  },
  {
    "objectID": "05_algoritmos_y_estabilidad.html#tarea-2.8",
    "href": "05_algoritmos_y_estabilidad.html#tarea-2.8",
    "title": "Algoritmos y estabilidad",
    "section": "Tarea 2.8",
    "text": "Tarea 2.8\nEjercicio 1.4.1 del libro “Fundamentals of Numerical Computation: Julia Edition” de Driscoll y Braun.\nLas dos fórmulas siguientes son matemáticamente equivalentes\n\\[\n  f(x) = \\frac{1 - \\cos(x)}{\\sin(x)}\\,,\\quad g(x) = \\frac{2\\sin^2(x/2)}{\\sin(x)}\\,.\n\\]\nSin embargo sugieren algoritmos para su cálculo que se comportan de manera distinta en aritmética de punto flotante.\n\nEncuentre el número de condicionamiento de \\(f(x)\\) respecto a pequeños cambios en \\(x\\). Como son equivalentes, este es el mismo para \\(g(x)\\).\nCalcule \\(f(10^{-6})\\) usando una cadena de cuatro operaciones elementales (sumas, restas, multiplicaciones, divisiones, funciones trigonométricas). Calcule el número de condicionamiento de cada una.\nRepita lo mismo para \\(g(10^{-6})\\), que requiere seis operaciones elementales.\nBasado en lo anterior, compare ambos resultados y discuta cuál es más preciso.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Algoritmos y estabilidad"
    ]
  },
  {
    "objectID": "05_algoritmos_y_estabilidad.html#tarea-2.9",
    "href": "05_algoritmos_y_estabilidad.html#tarea-2.9",
    "title": "Algoritmos y estabilidad",
    "section": "Tarea 2.9",
    "text": "Tarea 2.9\nEjercicio 1.4.2 del libro “Fundamentals of Numerical Computation: Julia Edition” de Driscoll y Braun.\nSea \\(f(x) = \\frac{e^x - 1}{x}\\).\n\nEncuentre el número de condicionamiento. ¿Cuál es su máximo entre \\(-1 \\leq x \\leq 1\\)?\nUse el algoritmo obvio\n(e**x - 1)/x\npara calcular \\(f(x)\\) para \\(x = 10^{-2}, 10^{-3}, 10^{-4}, ..., 10^{-8}\\).\nRepita lo mismo usando en cambio los primeros ocho términos de la serie de Taylor \\[\nf(x) \\approx 1 + \\frac{1}{2}x + \\frac{1}{3!}x^3 + \\dots + \\frac{1}{8!}x^7\\,.\n\\]\nHaga una tabla de las diferencias relativas entre ambos métodos. ¿Cuál es más preciso y por qué?",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Algoritmos y estabilidad"
    ]
  },
  {
    "objectID": "05_algoritmos_y_estabilidad.html#tarea-2.10",
    "href": "05_algoritmos_y_estabilidad.html#tarea-2.10",
    "title": "Algoritmos y estabilidad",
    "section": "Tarea 2.10",
    "text": "Tarea 2.10\nCompare la convergencia de dos algoritmos para aproximar \\(\\sqrt{2}\\) resolviendo \\(f(x) = x^2 − 2 = 0\\)\nBisección en el intervalo [1, 2]: Este método lo veremos más adelante, aquí hay una implementación:\nN = 20\nf = lambda x: x**2 - 2.0\ntrue = np.sqrt(2)\n\n# Método de bisección\na, b = 1.0, 2.0\nerr_bis = np.empty(N)\nx_bis_hist = []\n\nfor k in range(N):\n    c = 0.5*(a + b)\n    x_bis_hist.append(c)\n    err_bis[k] = abs(c - true)\n    if f(a)*f(c) &lt;= 0:\n        b = c\n    else:\n        a = c\nLa aproximación se guarda en x_bis_hist para cada iteración.\nNewton (método babilónico): El resultado de la iteración \\(k+1\\) se calcula a partir de la anterior de esta manera: \\(x_{k+1} = \\frac{1}{2}(x_k + \\frac{2}{x_k})\\)\n\nImplemente el método babilónico partiendo desde \\(x_0 = 2.0\\) y guarde la aproximación en cada iteración.\nCalcule el error absoluto \\(|x_k − \\sqrt{2}|\\) para ambos métodos y grafíquelo en una escala apropiada que nos permita compararlos.\nComente por qué el error del método de Newton/Babilónico deja de disminuir durante las últimas iteraciones.",
    "crumbs": [
      "Inicio",
      "Unidad 1: Introducción",
      "Algoritmos y estabilidad"
    ]
  },
  {
    "objectID": "10_entropia.html",
    "href": "10_entropia.html",
    "title": "Entropía",
    "section": "",
    "text": "Esta clase está basada en las siguientes fuentes:",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "10_entropia.html#el-principio-de-máxima-entropía-y-la-distribución-de-boltzmann",
    "href": "10_entropia.html#el-principio-de-máxima-entropía-y-la-distribución-de-boltzmann",
    "title": "Entropía",
    "section": "El principio de máxima entropía y la distribución de Boltzmann",
    "text": "El principio de máxima entropía y la distribución de Boltzmann\nEn general es difícil asignar una distribución de probabilidad. Un principio que funciona en mecánica estadística es el de “máxima entropía”. Es decir, basados en la información que tenemos sobre el sistema, escogemos la distribución de probabilidad que maximiza le entropía de Shannon.\nJaynes arguyó que este principio se puede aplicar a otros contextos. Corresponde a admitir la ignorancia. La máxima entropía corresponde a la máxima ignorancia sobre el sistema, es decir corresponde a ganar la cantidad máxima de información en promedio con cada observación.\nA partir de este principio se puede deducir la distribución de Boltzmann.\nSupongamos que conocemos el promedio de alguna cantidad \\(A\\). Queremos encontrar la distribución que maximiza la entropía bajo la condición \\(\\langle A \\rangle = \\sum_i p_i A_i = c\\) fijo.\nSi vemos \\(\\langle A \\rangle\\) como una función de las variables \\(p_i\\), queremos maximizar \\(H(\\mathbf{p})\\) en el espacio dado por las coordenadas \\((p_1, ..., p_n)\\) sobre la superficie \\(g(\\mathbf{p}) = \\sum_i p_i A_i\\) constante.\nEl gradiente \\(\\nabla g\\) siempre es ortogonal a la superficie \\(g\\) constante.\nEl gradiente \\(\\nabla H\\) es ortogonal a la superficie \\(g\\) constante en los puntos donde \\(H\\) es un mínimo o máximo sobre la superficie. Si no fuera así podríamos movernos en la dirección del gradiente proyectado sobre la superficie y hacer que \\(H\\) sea un poco más pequeño o grande.\nEntonces los dos gradientes son proporcionales en el punto extremo de \\(H\\), es decir \\(\\nabla H = \\lambda \\nabla g\\) o en otras palabras tenemos que encontrar \\[\n\\nabla (H - \\lambda g) = 0\\,.\n\\] Aquí \\(\\lambda\\) se llama un multiplicador de Lagrange.\n\\[\n\\nabla_j H = -\\nabla_j \\sum_i p_i \\ln p_i = -\\sum_i (1 + \\ln p_i) \\nabla_j p_i = -\\ln \\frac{p_j}{p_1}\\,,\n\\]\n\\[\n\\nabla_j g = \\nabla_j \\sum_i A_i p_i = \\sum_i A_i \\nabla_j p_i = A_j - A_1\\,,\n\\]\nJuntando estas expresiones tenemos\n\\[\n0 = \\ln\\frac{p_j}{p_1} + \\lambda (A_j - A_1)\\,,\n\\]\nes decir\n\\[\n\\frac{p_i}{p_1} = \\frac{e^{-\\lambda A_i}}{e^{-\\lambda A_1}}\n\\]\nNormalizando adecuadamente\n\\[\np_i = \\left(\\frac{1}{\\sum_{i=1}^n e^{-\\lambda A_i}}\\right) e^{-\\lambda A_i}\\,.\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "10_entropia.html#el-teorema-original",
    "href": "10_entropia.html#el-teorema-original",
    "title": "Entropía",
    "section": "El teorema original",
    "text": "El teorema original\nShannon era un informático (más apropiadamente un científico de la información) que introdujo su concepto de entropía para demostrar un teorema sobre comunicaciones en redes.\nLa pregunta es cuánto podemos comprimir la información producida por un computador para enviarla de manera eficiente a otro computador. Todos hemos usado archivos .zip. La pregunta es cuánto podemos comprimir una serie de bits.\nDefinimos la compresión como un mapa \\(C^n\\) entre las posibles secuencias \\((x_1,...,x_n)\\) y una cadena de bits de longitud \\(nR\\). Entonces la razón de compresión de este mapa es \\(R\\).\nLa descompresión del mensjae es un mapa \\(D^n\\) que toma una cadena de bits de longitud \\(nR\\) y produce \\((x_1,...,x_n)\\).\nUn mecanismo de compresión y descompresión es confiable si \\(D^n(C^n(x)) = x\\) con probabilidad \\(1\\) cuando \\(n\\) tiende a infinito.\nEl teorema dice (asumiendo que el logaritmo en la definición de \\(H\\) es base \\(2\\))\nTeorema del canal sin ruido de Shannon: Suponga que \\(X_i\\) es una serie de variables i.i.d (independientes e idénticamente distribuidas) sacadas de una distribución discreta de probabilidad con entropía \\(H(X)\\). Sea \\(R &gt; H\\), entonces existe un mecanismo de compresión confiable con razón de compresión \\(R\\). Por el contrario sea \\(R &lt; H\\), entonces no existe un tal mecanismo confiable.\nLamentablemente no tenemos el tiempo necesario para introducir los conceptos previos necesarios para demostrar este teorema.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "10_entropia.html#un-par-de-consideraciones-intuitivas",
    "href": "10_entropia.html#un-par-de-consideraciones-intuitivas",
    "title": "Entropía",
    "section": "Un par de consideraciones intuitivas",
    "text": "Un par de consideraciones intuitivas\nConsideremos una fuente que sólo produce la letra “c”. Esta fuente no contiene ninguna información, no necesitamos comprimir nada.\nAhora supongamos que unos días la fuente produce la palabra “azul” y otros días la fuente produce la palabra “rojo”. En este caso podemos representar la palabra “azul” con 0 y la palabra rojo con “1”. De hecho la entropía es \\(1\\), necesitamos un solo bit.\nEn el otro extremo, supongamos que la fuente produce una cadena completamente aleatoria de “1” y “0” de longitud \\(n\\). No tenemos manera de comprimirla si es completamente aleatoria, la entropía es \\[\nH = -n\\sum_{i=0}^1 \\frac{1}{2}\\log\\frac{1}{2} = n\\,,\n\\] y necesitamos todos los \\(n\\) bits. Esta cadena tiene la máxima cantidad de información, no se puede comprimir.\nAquí vemos que la estadística de la fuente es importante, por eso la información está relacionada con la estadísitica.\nAhora pensemos en una fuente que transmite un mensaje en español. Resulta que los 33 caracteres del español no ocurren con igual probabilidad, las vocales son mucho más probables. Igualmente para las palabras, algunas palabras son más comunes. Idem para las parejas de palabras o frases.\nPara acercarnos a ese caso, ahora pensemos en una cadena de “0” y “1” tal que el “1” aparece con probabilidad \\(0.8\\). Una tal cadena es \\[\n111101110101111\n\\] Parecería que no podemos comprimir esta cadena, después de todo para el cero necesitamos el símbolo “0” y para el uno necesitamos el símbolo “1”. Esto parecería contradecir la intuición que hemos construído de entropía \\[\nH = -n\\left(0.8\\log 0.8 + 0.2 \\log 0.2\\right) \\approx 0.5\\,.\n\\] Pero en realidad podemos tomar cadenas de caracteres, por ejemplo de cinco caracteres. Las cinco cadenas “11110”, “11101”, “11011”, “10111”, “01111” ocurren con mucha más frecuencia que las otras, tal que podemos usar un par de bits para representarlas en vez de cinco. Jugando de esta manera nos podemos acercar a comprimir esos mensajes por un \\(50\\%\\).",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "10_entropia.html#un-ejemplo-de-compresión",
    "href": "10_entropia.html#un-ejemplo-de-compresión",
    "title": "Entropía",
    "section": "Un ejemplo de compresión",
    "text": "Un ejemplo de compresión\nAhora supongamos que tenemos un alfabeto de 8 caracteres que queremos comprimir, llamémoslos \\(\\{1,2,3,4,5,6,7,8\\}\\). De forma ingenua podemos representar cada caracter con 3 bits. ¿Podemos comprimirlo?\nSi los 8 caracteres ocurren con igual probabilidad \\(1/8\\) no podemos hacer mucho \\[\nH = -n\\sum \\frac{1}{8}\\log\\frac{1}{8} = n\\log 8 = 3n\\,.\n\\] Es decir, necesitamos \\(3n\\) bits para representar un mensaje de longitud \\(n\\).\nPero si ocurren con probabilidad diferente, podemos hacer algo mejor. Supongamos que las probabilidades son \\[\n\\{p_1 = 0.5, p_2 = 0.3, p_3 = 0.1, p_4 = 0.05, p_5 = 0.025, p_6 = 0.0125, p_7 = 0.0065, p_8 = 0.006\\}\\,.\n\\] Entonces un esquema debido a Fano consiste en:\n\nOrdenar las probabilidades de forma decreciente (como ya hemos hecho)\nDividir en dos conjuntos que tengan aproximadamente la misma probabilidad. Para nosotros serán \\[\n\\{0.5\\}\\,,\\quad \\{0.3, 0.1, 0.05, 0.025, 0.0125, 0.0065, 0.006\\}\\,.\n\\]\nLos caracteres del primer conjunto se representan con el dígito \\(0\\), los del segundo con el dígito \\(1\\). \\[\n``0\" = 1\\,,\\quad ``1\" = \\{p_2 = 0.3, p_3 = 0.1, p_4 = 0.05, p_5 = 0.025, p_6 = 0.0125, p_7 = 0.0065, p_8 = 0.006\\}\\,,\n\\]\nRepetimos hasta terminar \\[\n``0\" = 1\\,,\\quad ``10\" = 2\\,,\\quad ``11\" = \\{p_3 = 0.1, p_4 = 0.05, p_5 = 0.025, p_6 = 0.0125, p_7 = 0.0065, p_8 = 0.006\\}\\,,\n\\] \\[\n``0\" = 1\\,,\\quad ``10\" = 2\\,,\\quad ``110\" = \\{p_3 = 0.1, p_4 = 0.05\\}\\,,\\quad ``111\" = \\{p_5 = 0.025, p_6 = 0.0125, p_7 = 0.0065, p_8 = 0.006\\}\\,,\n\\] \\[\n``0\" = 1\\,,\\quad ``10\" = 2\\,,\\quad ``1100\" = 3\\,,\\quad ``1101\"= 4\\,,\\quad ``1110\" = 5\\,,\\quad ``1111\" = \\{p_6 = 0.0125, p_7 = 0.0065, p_8 = 0.006\\}\\,,\n\\] \\[\n``0\" = 1\\,,\\quad ``10\" = 2\\,,\\quad ``1100\" = 3\\,,\\quad ``1101\"= 4\\,,\\quad ``1110\" = 5\\,,\\quad ``11110\" = 6\\,,\\quad ``11111\" = \\{p_7 = 0.0065, p_8 = 0.006\\}\\,,\n\\] \\[\n``0\" = 1\\,,\\quad ``10\" = 2\\,,\\quad ``1100\" = 3\\,,\\quad ``1101\"= 4\\,,\\quad ``1110\" = 5\\,,\\quad ``11110\" = 6\\,,\\quad ``111110\" = 7\\,,\\quad ``111111\" = 8\\,.\n\\] Es verdad que los símbolos menos probables son representados por más de 3 bits. Pero en promedio un mensaje tendrá longitud\n\n\n0.5*1+0.3*2+0.1*3+0.05*3+0.025*4+0.0125*5+0.0065*6+0.006*6\n\n1.7875000000000003\n\n\nLa entropía es\n\n-0.5*np.log(0.5)-0.3*np.log(0.3)-0.1*np.log(0.1)-0.05*np.log(0.05)-0.025*np.log(0.025)-0.0125*np.log(0.0125)\\\n    -0.0065*np.log(0.0065)-0.006*np.log(0.006)\n\nnp.float64(1.2982375438631775)\n\n\nEl esquema descrito arriba se acerca a esta entropía.\nEn general, aplicando un esquema como el que vimos la longitud de cada caracter será aproximadamente \\(-\\log p\\) y como este ocurre con frecuencia \\(p\\), la longitud promedio de un mensaje en bits será cercana a la entropía \\[\n-n\\sum_i p_i\\log p_i\\,.\n\\]",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "10_entropia.html#section",
    "href": "10_entropia.html#section",
    "title": "Entropía",
    "section": "5.1",
    "text": "5.1\n\nSi dos variables aleatorias \\(x\\), \\(y\\) son independientes, demuestre que su entropía conjunta satisface \\[\nH(x,y) = H(x) + H(y)\\,,\n\\] donde \\(H(x,y)\\) se calcula con la distribución de probabilidad conjunta \\(p(x,y)\\) y \\(H(x)\\), \\(H(y)\\) se calculan con las distribuciones de probabilidad \\(p(x)\\), \\(p(y)\\) respectivamente.\nDemuestre que \\(H(x) \\leq H(x,y)\\).",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "10_entropia.html#section-1",
    "href": "10_entropia.html#section-1",
    "title": "Entropía",
    "section": "5.2",
    "text": "5.2\nConsidere una variable aleatoria \\(x\\) que puede tomar valores enteros con probabilidades \\(p_i\\). Suponga que a priori conocemos sólo la varianza de \\(x\\) y que su media es cero. Calcule la distribución de probabilidad de \\(x\\) basándose en el principio de máxima entropía.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "10_entropia.html#section-2",
    "href": "10_entropia.html#section-2",
    "title": "Entropía",
    "section": "5.3",
    "text": "5.3\nLa distribución de uso de letras en el español es (en porcentajes y orden alfabético):\n\n[12.53,1.42,4.68,5.86,13.68,0.69,1.01,0.70,6.25,0.44,0.02,4.97,3.15,6.71,0.31,8.68,2.51,0.88,6.87,7.98,4.63,3.93,0.90,0.01,0.22,0.90,0.52]\n\n[12.53,\n 1.42,\n 4.68,\n 5.86,\n 13.68,\n 0.69,\n 1.01,\n 0.7,\n 6.25,\n 0.44,\n 0.02,\n 4.97,\n 3.15,\n 6.71,\n 0.31,\n 8.68,\n 2.51,\n 0.88,\n 6.87,\n 7.98,\n 4.63,\n 3.93,\n 0.9,\n 0.01,\n 0.22,\n 0.9,\n 0.52]\n\n\n(Sacado de Wikipedia).\n\nCalcule la entropía de Shannon del español como si fuera sólo una distribución de letras.\nIgnorando comas, espacios y la diferencia entre mayúsculas y minúsculas, explique por qué es posible comprimir el siguiente poema con una razón de compresión mayor a la entropía calculada en el numeral anterior\n\nEntre menesteres, el ser envejece,\nteje redes, perece\nreverdece en el refleje breve\nde este presente. Cede.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "10_entropia.html#section-3",
    "href": "10_entropia.html#section-3",
    "title": "Entropía",
    "section": "5.4",
    "text": "5.4\nLa entropía de Shannon de una distribución discreta que tiene absoluta certeza de obtener un resultado dado es cero.\nEn el continuo es un poco más complicado. Considere la siguiente función de densidad de probabilidad \\[\n\\rho(x) = \\begin{cases} \\frac{1}{L} & -L/2 \\leq x \\leq L/2 \\\\ 0 & x &lt; -L/2\\quad\\text{o}\\quad x &gt; L/2 \\end{cases}\n\\]\n\nCalcule la entropía de Shannon de esta distribución de probabilidad.\nTome el límite \\(L \\rightarrow 0\\) en el cual esta distribución tiende a una delta de Dirac.\nEn el límite anterior estamos absolutamente seguros de que la variable tiene el valor \\(0\\). ¿Por qué la entropía no nos da igual a cero? De una interpretación de este hecho más allá del simple hecho que la fórmula para el continuo es diferente.",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "10_entropia.html#section-4",
    "href": "10_entropia.html#section-4",
    "title": "Entropía",
    "section": "5.5",
    "text": "5.5\nCalcule la entropía de Shannon de la distribución binomial para un número grande de eventos \\(n\\).",
    "crumbs": [
      "Inicio",
      "Unidad 2: Probabilidad",
      "Entropía de Shannon"
    ]
  },
  {
    "objectID": "13_interpolacion.html",
    "href": "13_interpolacion.html",
    "title": "Interpolación",
    "section": "",
    "text": "Las funciones genéricas son difíciles de integrar o derivar. Una manera de simplificar los cálculos es aproximar la función por medio de un polinomio cuyas derivadas e integrales son casi triviales.\nPor otro lado, en muchos casos calcular una función es numéricamente costoso. Podemos entonces calcularla en un número de puntos limitado y asumiendo que es lo suficientemente suave, obtener valores aproximados para cualquier otro punto. A esto se lo llama interpolar la función.\nUno podría pensar que los polinomios de Taylor proveen una buena aproximación a las funciones.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nx = np.linspace(0.2, 4, 100)\nex = 1/x\ntay0 = np.full(100, 1)\ntay1 = 1 - (x - 1)\ntay2 = 1 - (x - 1) + (x - 1)**2\ntay3 = 1 - (x - 1) + (x - 1)**2 - (x - 1)**3\n\nplt.plot(x, ex, label = 'exacta')\nplt.plot(x, tay0, label = 'Taylor 0')\nplt.plot(x, tay1, label = 'Taylor 1')\nplt.plot(x, tay2, label = 'Taylor 2')\nplt.plot(x, tay3, label = 'Taylor 3')\n\nplt.legend()",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Interpolación"
    ]
  },
  {
    "objectID": "13_interpolacion.html#diferencias-divididas",
    "href": "13_interpolacion.html#diferencias-divididas",
    "title": "Interpolación",
    "section": "Diferencias divididas",
    "text": "Diferencias divididas\nQueremos obtener una lista de los coeficientes del polinomio de la forma\n\\[\nP(x) = a_o + a_1 (x - x_o) + a_2 (x - x_o)(x - x_1) + ... + a_n (x - x_o)...(x - x_{n - 1})\n\\]\nClaramente\n\\[\na_o = P(x_o) = f(x_o)\n\\]\ncontinuando\n\\[\nf(x_1) = P(x_1) = a_o + a_1 (x_1 - x_o)\n\\]\ntal que\n\\[\na_1 = \\frac{f(x_1) - f(x_o)}{x_1 - x_o} \\equiv f[x_o, x_1]\n\\]\ntambién\n\\[\nf(x_2) = P(x_2) = a_o + a_1 (x_2 - x_o) + a_2 (x_2 - x_1)(x_2 - x_o)\n\\]\ntal que\n\\[\na_2 = \\frac{f(x_2) - f(x_o) - (f(x_1) - f(x_o))(x_2 - x_o)/(x_1 - x_o)}{(x_2 - x_1)(x_2 - x_o)}\n\\]\nsimplificando\n\\[\na_2 = \\frac{(f(x_2) - f(x_o))/(x_2 - x_o) - (f(x_1) - f(x_o))/(x_1 - x_o)}{(x_2 - x_1)} = \\frac{f[x_o, x_2] - f[x_o, x_1]}{(x_2 - x_1)} \\equiv f[x_o, x_1, x_2]\n\\]\nSe puede demostrar que\n\\[\na_k = f[x_o, x_1, ..., x_k] \\equiv \\frac{f[x_o, x_1,...,x_{k-2}, x_k] - f[x_o, x_1,...,x_{k-2},x_{k-1}]}{(x_k - x_{k-1})}\n\\]\n\ndef difer(puntos):\n    \n    n = len(puntos) - 1\n    Fs = [np.zeros(n + 1)]\n    for i in range(n + 1):\n        Fs[0][i] = puntos[i][1]\n    for i in range(1, n + 1):\n        Fs.append(np.zeros(n + 1 - i))\n        for j in range(1, i + 1):\n            Fs[j][i-j] = (Fs[j-1][i-j+1] - Fs[j-1][i-j])/(puntos[i][0] - puntos[i-j][0])\n    \n    return [Fs[i][0] for i in range(n + 1)]\n\n\npuntos = np.array([[1, 0.7651977], [1.3, 0.6200860], [1.6, 0.4554022], [1.9, 0.2818186], [2.2, 0.1103623]])\n\n\ncoef = difer(puntos)\n\n\nnp.prod([i for i in range(0)])\n\nnp.float64(1.0)\n\n\n\ndef poly(x, coefs):\n    return sum(coef[n]*np.prod([(x - puntos[i,0]) for i in range(n)]) for n in range(len(coefs)))\n\n\nx = np.linspace(0, 5, 100)\nplt.plot(x, [poly(xi, coef) for xi in x])\nplt.scatter(puntos[:,0], puntos[:,1], color='red')",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Interpolación"
    ]
  },
  {
    "objectID": "13_interpolacion.html#tarea-6.6",
    "href": "13_interpolacion.html#tarea-6.6",
    "title": "Interpolación",
    "section": "Tarea 6.6",
    "text": "Tarea 6.6\nUse cinco puntos equidistantes para encontrar un polinomio interpolante de la función \\(f(x) = \\sinh(x)\\) entre \\(x = -5\\) y \\(x = 5\\). Grafique el polinomio. Estime el error cometido para cada \\(x\\), usando la fórmula de error de los polinomios de Legendre. Luego grafique \\(|f(x) - P(x)|\\) y compare con el error estimado.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Interpolación"
    ]
  },
  {
    "objectID": "13_interpolacion.html#tarea-6.7",
    "href": "13_interpolacion.html#tarea-6.7",
    "title": "Interpolación",
    "section": "Tarea 6.7",
    "text": "Tarea 6.7\nUse \\(10\\) puntos equidistantes para encontrar un polinomio interpolante de la función \\(f(x) = \\tanh(x)\\) entre \\(x = -10\\) y \\(x = 10\\). Compare el polinomio con la función obtenida. Explique.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Interpolación"
    ]
  },
  {
    "objectID": "13_interpolacion.html#tarea-6.8",
    "href": "13_interpolacion.html#tarea-6.8",
    "title": "Interpolación",
    "section": "Tarea 6.8",
    "text": "Tarea 6.8\nUse una función interpolante para encontrar una buena aproximación a una gaussiana con \\(\\sigma = 1\\) y \\(\\mu = 0\\) entre \\(x = 0\\) y \\(x = 2\\). ¿Se puede usar ese mismo polinomio para aproximar la gaussiana en \\(x = 3\\)? De una respuesta cuantitativa y argumente.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Interpolación"
    ]
  },
  {
    "objectID": "13_interpolacion.html#tarea-6.9",
    "href": "13_interpolacion.html#tarea-6.9",
    "title": "Interpolación",
    "section": "Tarea 6.9",
    "text": "Tarea 6.9\nEscriba un código similar a la interpolación lineal de la clase, pero que realice una interpolación cuadrática. Es decir, este código interpola usando una parábola para cada trío de puntos. Grafique sus resultados para el mismo ejemplo usado en la interpolación lineal.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Interpolación"
    ]
  },
  {
    "objectID": "13_interpolacion.html#tarea-6.10",
    "href": "13_interpolacion.html#tarea-6.10",
    "title": "Interpolación",
    "section": "Tarea 6.10",
    "text": "Tarea 6.10\nConsidere la función \\(f(x) = 4 x^3 - 3x^2 + x -5\\). Use sólo los dos puntos \\(x = -1\\) y \\(x = 1\\) para interpolar usando una spline cúbica entre \\(x =-1\\) y \\(x = 1\\). Explique por qué la spline cúbica es diferente del polinomio original si ambos son polinomios cúbicos que pasan por los mismos puntos en \\(x = -1\\) y \\(x = 1\\). Ahora repita la comparación usando la interpolación de splines por intervalos con \\(4\\) puntos equidistantes en el mismo intervalo.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Interpolación"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html",
    "href": "22_descenso_de_gradiente.html",
    "title": "Decenso de Gradiente",
    "section": "",
    "text": "En esta clase discutiremos uno de los algoritmos de optimización más usados actualmente: El descenso de gradiente.\nEste algoritmo se usa con éxito para ajustar modelos con billones de parámetros.\nNosotros, más humildemente, lo usaremos para hacer un ajuste de mínimos cuadrados.\nPara lograrlo, usaremos una de las librerías más usadas actualmente: JAX.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#ventajas-de-jax",
    "href": "22_descenso_de_gradiente.html#ventajas-de-jax",
    "title": "Decenso de Gradiente",
    "section": "Ventajas de JAX",
    "text": "Ventajas de JAX\n\nCompatibilidad con Numpy: Tiene varias funciones similares a las de Numpy con la misma sintaxis. Para usarlas se importa jax.numpy.\nDiferenciación automática: Puede calcular el gradiente de funciones de python arbitrarias usando grad.\nCompilación justo a tiempo (JIT): El código de python es lento porque es interpretado. JAX permite compilar código para hacerlo más rápido.\nSoporte de GPU: Permite realizar algunos cálculos en la GPU para mayor eficiencia.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#trabajando-con-arrays-de-jax",
    "href": "22_descenso_de_gradiente.html#trabajando-con-arrays-de-jax",
    "title": "Decenso de Gradiente",
    "section": "Trabajando con arrays de JAX",
    "text": "Trabajando con arrays de JAX\n\nimport jax.numpy as jnp\n\n#Crear arrays\nx = jnp.array([1, 2, 3])\ny = jnp.array([4, 5, 6])\n\n\n#Sumar arrays\nz = x + y\nprint(z)\n\n[5 7 9]\n\n\n\n#Producto punto\na = jnp.dot(x, y)\nprint(a)\n\n32\n\n\nAsí mismo, muchas de las cosas que hace numpy con sus arrays se pueden hacer con JAX, cambiando np por jnp.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#diferenciación-automática-con-grad",
    "href": "22_descenso_de_gradiente.html#diferenciación-automática-con-grad",
    "title": "Decenso de Gradiente",
    "section": "Diferenciación automática con grad",
    "text": "Diferenciación automática con grad\n\nimport jax\n\n#Defina una función\ndef f(x):\n    return x**2 + 2*x + 1\n\n#Calcule la derivada\ndf_dx = jax.grad(f)\n\n\ndf_dx(3.0)\n\nArray(8., dtype=float32, weak_type=True)\n\n\nTambién podemos calcular gradientes de funciones de varios parámetros:\n\ndef g(x, y):\n    return x**2 + y**2 + x*y\n\ngrad_g = jax.grad(g, argnums=(0,1))\n\ngrad_x, grad_y = grad_g(3.0, 4.0)\nprint(grad_x, grad_y)\n\n10.0 11.0",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#acelerar-código-con-jit",
    "href": "22_descenso_de_gradiente.html#acelerar-código-con-jit",
    "title": "Decenso de Gradiente",
    "section": "Acelerar código con JIT",
    "text": "Acelerar código con JIT\n\ndef f(x):\n    return jnp.sin(x) + jnp.cos(x)\n\nf_jit = jax.jit(f)\n\n\nimport time\nx = jnp.linspace(0, 10, 100_000_000)\n\n\n# Se necesita ejecutar la función una vez para obligarla a compilar\nf_jit(x)\n\nArray([ 1.       ,  1.0000001,  1.0000002, ..., -1.3830926, -1.3830926,\n       -1.3830926], dtype=float32)\n\n\n\n# Sin JIT\nstart = time.time()\nf(x)\nprint(f\"Sin JIT: {time.time() - start}\")\n\nSin JIT: 0.6554825305938721\n\n\n\n# Con JIT\nstart = time.time()\nf_jit(x)\nprint(f\"Con JIT: {time.time() - start}\")\n\nCon JIT: 0.0010113716125488281\n\n\nNota: Esta no es la manera más precisa para medir tiempos. Es sólo para ilustrar que el código compilado es más rápido.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#minimización",
    "href": "22_descenso_de_gradiente.html#minimización",
    "title": "Decenso de Gradiente",
    "section": "Minimización",
    "text": "Minimización\nDefinimos primero la función a minimizar:\n\ndef suma_cuadrados(theta, x, y):\n    predicciones = modelo(x, theta)\n    return jnp.sum((y - predicciones)**2)\n\nEl siguiente es un algoritmo sencillo de minimización por descenso de gradiente:\n\ngradiente = jax.grad(suma_cuadrados)\n\ndef gradient_descent(theta, x, y, learning_rate=0.01, iterations=1000):\n    for i in range(iterations):\n        gradients = gradiente(theta, x, y)\n        theta = theta - learning_rate * gradients\n        \n        # Imprimimos el resultado cada 100 iteraciones\n        if i % 100 == 0:\n            loss = suma_cuadrados(theta, x, y)\n            print(f\"Iteración {i}, Suma cuadrados: {loss}\")\n    return theta\n\n\n# Parámetros iniciales\ntheta_init = jnp.array([1.0, 1.0, 1.0])\n\n# Descenso de gradiente\ntheta_opt = gradient_descent(theta_init, x_data, y_data, learning_rate=0.001, iterations=3000)\n\n# Parámetros encontrados\nprint(\"Parámetros optimizados:\", theta_opt)\n\nIteración 0, Suma cuadrados: 2.8259427547454834\nIteración 100, Suma cuadrados: 0.9898320436477661\nIteración 200, Suma cuadrados: 0.9269558191299438\nIteración 300, Suma cuadrados: 0.9178450703620911\nIteración 400, Suma cuadrados: 0.9157513976097107\nIteración 500, Suma cuadrados: 0.9152856469154358\nIteración 600, Suma cuadrados: 0.9151836037635803\nIteración 700, Suma cuadrados: 0.9151614308357239\nIteración 800, Suma cuadrados: 0.9151566028594971\nIteración 900, Suma cuadrados: 0.9151556491851807\nIteración 1000, Suma cuadrados: 0.9151554107666016\nIteración 1100, Suma cuadrados: 0.915155291557312\nIteración 1200, Suma cuadrados: 0.915155291557312\nIteración 1300, Suma cuadrados: 0.915155291557312\nIteración 1400, Suma cuadrados: 0.915155291557312\nIteración 1500, Suma cuadrados: 0.915155291557312\nIteración 1600, Suma cuadrados: 0.915155291557312\nIteración 1700, Suma cuadrados: 0.915155291557312\nIteración 1800, Suma cuadrados: 0.915155291557312\nIteración 1900, Suma cuadrados: 0.915155291557312\nIteración 2000, Suma cuadrados: 0.915155291557312\nIteración 2100, Suma cuadrados: 0.915155291557312\nIteración 2200, Suma cuadrados: 0.915155291557312\nIteración 2300, Suma cuadrados: 0.915155291557312\nIteración 2400, Suma cuadrados: 0.915155291557312\nIteración 2500, Suma cuadrados: 0.915155291557312\nIteración 2600, Suma cuadrados: 0.915155291557312\nIteración 2700, Suma cuadrados: 0.915155291557312\nIteración 2800, Suma cuadrados: 0.915155291557312\nIteración 2900, Suma cuadrados: 0.915155291557312\nParámetros optimizados: [1.1409745  0.56464535 1.        ]\n\n\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(x_data, y_data, label=\"Datos\")\nplt.plot(x_data, modelo(x_data, theta_opt), color=\"red\", label=\"Modelo ajustado\")\nplt.legend()\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Ajuste de mínimos cuadrados no lineal con descenso de gradiente')\nplt.show()",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#momentum",
    "href": "22_descenso_de_gradiente.html#momentum",
    "title": "Decenso de Gradiente",
    "section": "Momentum",
    "text": "Momentum\nCuando se minimizan funciones de varias dimensiones, con frecuencia tienen múltiples mínimos locales.\nEl descenso de gradiente mostrado arriba se quedará atascado en esos mínimos locales.\nPara evitarlo, podemos imaginar una bolita que rueda por una pendiente. Esta no se atasca en pequeños huecos porque su momentum la ayuda a continuar. Podemos agregarle también un momentum a la velocidad del descenso de gradiente:\n\\[\n\\vec{m}_{t+1} = \\beta\\vec{m}_t - \\eta \\nabla f(\\vec{\\theta_t})\\,,\n\\] \\[\n\\vec{\\theta}_{t+1} = \\vec{\\theta}_t + \\vec{m}_{t+1}\\,.\n\\]\nEscribamos un código que lo implemente en JAX\n\ndef gradient_descent_momentum(theta, x, y, learning_rate=0.001, momentum=0.9, iterations=1000):\n    velocity = jnp.zeros_like(theta)  # Inicializar el término de velocidad\n    \n    for i in range(iterations):\n        gradients = gradiente(theta, x, y)\n        \n        velocity = momentum * velocity - learning_rate * gradients\n        theta = theta + velocity\n        \n        if i % 100 == 0:\n            loss = suma_cuadrados(theta, x, y)\n            print(f\"Iteración {i}, Suma cuadrados: {loss}\")\n    \n    return theta\n\n\n# Parámetros iniciales\ntheta_init = jnp.array([1.0, 1.0])\n\n# Descenso de gradiente\ntheta_opt = gradient_descent_momentum(theta_init, x_data, y_data, learning_rate=0.001, iterations=3000)\n\n# Parámetros encontrados\nprint(\"Parámetros optimizados:\", theta_opt)\n\nplt.scatter(x_data, y_data, label=\"Datos\")\nplt.plot(x_data, modelo(x_data, theta_opt), color=\"red\", label=\"Modelo ajustado\")\nplt.legend()\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Ajuste de mínimos cuadrados no-lineal con momentum')\nplt.show()\n\nIteración 0, Suma cuadrados: 21042.046875\nIteración 100, Suma cuadrados: 3676.298583984375\nIteración 200, Suma cuadrados: 3676.298583984375\nIteración 300, Suma cuadrados: 3676.298583984375\nIteración 400, Suma cuadrados: 3676.298583984375\nIteración 500, Suma cuadrados: 3676.298583984375\nIteración 600, Suma cuadrados: 3676.298583984375\nIteración 700, Suma cuadrados: 3676.298583984375\nIteración 800, Suma cuadrados: 3676.298583984375\nIteración 900, Suma cuadrados: 3676.298583984375\nIteración 1000, Suma cuadrados: 3676.298583984375\nIteración 1100, Suma cuadrados: 3676.298583984375\nIteración 1200, Suma cuadrados: 3676.298583984375\nIteración 1300, Suma cuadrados: 3676.298583984375\nIteración 1400, Suma cuadrados: 3676.298583984375\nIteración 1500, Suma cuadrados: 3676.298583984375\nIteración 1600, Suma cuadrados: 3676.298583984375\nIteración 1700, Suma cuadrados: 3676.298583984375\nIteración 1800, Suma cuadrados: 3676.298583984375\nIteración 1900, Suma cuadrados: 3676.298583984375\nIteración 2000, Suma cuadrados: 3676.298583984375\nIteración 2100, Suma cuadrados: 3676.298583984375\nIteración 2200, Suma cuadrados: 3676.298583984375\nIteración 2300, Suma cuadrados: 3676.298583984375\nIteración 2400, Suma cuadrados: 3676.298583984375\nIteración 2500, Suma cuadrados: 3676.298583984375\nIteración 2600, Suma cuadrados: 3676.298583984375\nIteración 2700, Suma cuadrados: 3676.298583984375\nIteración 2800, Suma cuadrados: 3676.298583984375\nIteración 2900, Suma cuadrados: 3676.298583984375\nParámetros optimizados: [-730.93976 4131.1123 ]",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#rmsprop",
    "href": "22_descenso_de_gradiente.html#rmsprop",
    "title": "Decenso de Gradiente",
    "section": "RMSProp",
    "text": "RMSProp\nA veces el gradiente sigue la dirección más empinada. Pero esto puede hacer que termine oscilando alrededor de un “valle”.\nPara evitar eso, se introdujo un término que reduce la dirección más empinada:\n\\[\n\\begin{align}\n\\vec{s}_{i+1} &= \\rho\\vec{s}_i + (1 - \\rho)\\nabla_{\\vec{\\theta}}f \\otimes  \\nabla_{\\vec{\\theta}}f\\,,\\\\\n\\vec{\\theta} &\\leftarrow \\vec{\\theta} - \\eta\\nabla_{\\vec{\\theta}}f\\oslash\\sqrt{\\vec{s} \\oplus \\epsilon}\\,,\n\\end{align}\n\\]\ndonde \\(\\otimes\\), \\(\\oplus\\) \\(\\oslash\\) son la suma, multiplicación y división elemento por elemento de cada array.\n\nEl vector \\(\\vec{s}\\) actúa reduciendo el tamaño del gradiente. Esta reducción es mayor para las direcciones empinadas.\nAquí el parámetro \\(\\rho\\) controla cuánto se modifica \\(\\vec{s}\\) a cada paso. Para \\(\\rho\\) cercano a 1, se modifica muy poco y tiene una “memoria larga”. Para \\(\\rho\\) pequeño se modifica mucho pero tiene una “memoria corta” ya que su valor cambia rápidamente.\nEl \\(\\epsilon\\) sirve solamente a que no haya divisiones por cero cuando alguna componente de \\(\\vec{s}\\) es cero.\n\n\ndef gradient_descent_rmsprop(theta, x, y, learning_rate=0.001, beta=0.9, epsilon=1e-8, iterations=1000):\n\n    cache = jnp.zeros_like(theta)\n    for i in range(iterations):\n        grads = gradiente(theta, x, y)\n        cache = beta * cache + (1 - beta) * (grads ** 2)  # Actualizar la media móvil de los gradientes al cuadrado\n        theta = theta - learning_rate * grads / (jnp.sqrt(cache) + epsilon)  # Actualizar los parámetros\n        \n        if i % 100 == 0:\n            loss = suma_cuadrados(theta, x, y)\n            print(f\"Iteración {i}, Suma cuadrados: {loss}\")\n    return theta\n\n\n# Parámetros iniciales\ntheta_init = jnp.array([1.0, 1.0, 1.0])\n\n# Descenso de gradiente\ntheta_opt = gradient_descent_rmsprop(theta_init, x_data, y_data, learning_rate=0.001, iterations=3000)\n\n# Parámetros encontrados\nprint(\"Parámetros optimizados:\", theta_opt)\n\nplt.scatter(x_data, y_data, label=\"Datos\")\nplt.plot(x_data, modelo(x_data, theta_opt), color=\"red\", label=\"Modelo ajustado\")\nplt.legend()\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Ajuste de mínimos cuadrados no-lineal con momentum')\nplt.show()\n\nIteración 0, Suma cuadrados: 3429.28564453125\nIteración 100, Suma cuadrados: 3235.61865234375\nIteración 200, Suma cuadrados: 2916.4580078125\nIteración 300, Suma cuadrados: 2370.6962890625\nIteración 400, Suma cuadrados: 1490.12548828125\nIteración 500, Suma cuadrados: 401.747802734375\nIteración 600, Suma cuadrados: 90.45286560058594\nIteración 700, Suma cuadrados: 51.82493591308594\nIteración 800, Suma cuadrados: 25.270719528198242\nIteración 900, Suma cuadrados: 9.871788024902344\nIteración 1000, Suma cuadrados: 4.352239608764648\nIteración 1100, Suma cuadrados: 4.078448295593262\nIteración 1200, Suma cuadrados: 4.078287601470947\nIteración 1300, Suma cuadrados: 4.078277587890625\nIteración 1400, Suma cuadrados: 4.07828426361084\nIteración 1500, Suma cuadrados: 4.07828426361084\nIteración 1600, Suma cuadrados: 4.07828426361084\nIteración 1700, Suma cuadrados: 4.078278064727783\nIteración 1800, Suma cuadrados: 4.078278064727783\nIteración 1900, Suma cuadrados: 4.07828426361084\nIteración 2000, Suma cuadrados: 4.07828426361084\nIteración 2100, Suma cuadrados: 4.07828426361084\nIteración 2200, Suma cuadrados: 4.07828426361084\nIteración 2300, Suma cuadrados: 4.07828426361084\nIteración 2400, Suma cuadrados: 4.078278064727783\nIteración 2500, Suma cuadrados: 4.078278064727783\nIteración 2600, Suma cuadrados: 4.07828426361084\nIteración 2700, Suma cuadrados: 4.07828426361084\nIteración 2800, Suma cuadrados: 4.07828426361084\nIteración 2900, Suma cuadrados: 4.07828426361084\nParámetros optimizados: [1.9981217  0.50082964 1.        ]",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#adam",
    "href": "22_descenso_de_gradiente.html#adam",
    "title": "Decenso de Gradiente",
    "section": "Adam",
    "text": "Adam\nEste y sus derivados es uno de los algoritmos más usados actualmente.\nEste método adaptativo combina momentum con RMSprop\n\\[\n\\begin{align}\n\\vec{m}_{i+1} &= \\beta_1 \\vec{m}_i - (1 - \\beta_1) \\nabla_{\\vec{\\theta}}f(\\vec{\\theta})\\,,\\\\\n\\vec{s}_{i+1} &= \\beta_2\\vec{s}_i + (1 - \\beta_2)\\nabla_{\\vec{\\theta}}f \\otimes  \\nabla_{\\vec{\\theta}}f\\,,\\\\\n\\hat{\\vec{m}}_{i+1} & = \\frac{\\vec{m}_{i+1}}{1 - (\\beta_1)^i}\\,,\\\\\n\\hat{\\vec{s}}_{i+1} & = \\frac{\\vec{s}_{i+1}}{1 - (\\beta_2)^i}\\,,\\\\\n\\vec{\\theta}_{i+1} &= \\vec{\\theta}_i - \\eta\\hat{\\vec{m}}_{i+1}\\oslash\\sqrt{\\hat{\\vec{s}}_{i+1} \\oplus \\epsilon}\n\\end{align}\n\\]\nEl tercer y cuarto pasos sirven para hacer que \\(\\vec{m}\\) y \\(\\vec{s}\\) no sean demasiado pequeños durante las primeras iteraciones. De otra forma tenderán a estar cercanos a \\(0\\) ya que ese es su valor inicial.\n\ndef gradient_descent_adam(theta, x, y, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, iterations=1000):\n    m, v = jnp.zeros_like(theta), jnp.zeros_like(theta)\n    for t in range(1, iterations + 1):\n        grads = gradiente(theta, x, y)\n        m = beta1 * m + (1 - beta1) * grads  \n        v = beta2 * v + (1 - beta2) * (grads ** 2)  \n        m_hat = m / (1 - beta1 ** t)  \n        v_hat = v / (1 - beta2 ** t)  \n        theta = theta - learning_rate * m_hat / (jnp.sqrt(v_hat) + epsilon)  \n        \n        if t % 100 == 0:\n            loss = suma_cuadrados(theta, x, y)\n            print(f\"Iteración {t}, Suma cuadrados: {loss}\")\n    return theta\n\n\n# Parámetros iniciales\ntheta_init = jnp.array([1.0, 1.0, 1.0])\n\n# Descenso de gradiente\ntheta_opt = gradient_descent_adam(theta_init, x_data, y_data, learning_rate=0.001, iterations=3000)\n\n# Parámetros encontrados\nprint(\"Parámetros optimizados:\", theta_opt)\n\nplt.scatter(x_data, y_data, label=\"Datos\")\nplt.plot(x_data, modelo(x_data, theta_opt), color=\"red\", label=\"Modelo ajustado\")\nplt.legend()\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Ajuste de mínimos cuadrados no-lineal con momentum')\nplt.show()\n\nIteración 100, Suma cuadrados: 3247.58837890625\nIteración 200, Suma cuadrados: 2781.543701171875\nIteración 300, Suma cuadrados: 1436.5238037109375\nIteración 400, Suma cuadrados: 125.83804321289062\nIteración 500, Suma cuadrados: 108.08612060546875\nIteración 600, Suma cuadrados: 91.434326171875\nIteración 700, Suma cuadrados: 76.28626251220703\nIteración 800, Suma cuadrados: 62.861900329589844\nIteración 900, Suma cuadrados: 51.22735595703125\nIteración 1000, Suma cuadrados: 41.34318161010742\nIteración 1100, Suma cuadrados: 33.09861755371094\nIteración 1200, Suma cuadrados: 26.34052085876465\nIteración 1300, Suma cuadrados: 20.89399528503418\nIteración 1400, Suma cuadrados: 16.57768440246582\nIteración 1500, Suma cuadrados: 13.214640617370605\nIteración 1600, Suma cuadrados: 10.639381408691406\nIteración 1700, Suma cuadrados: 8.702418327331543\nIteración 1800, Suma cuadrados: 7.272414684295654\nIteración 1900, Suma cuadrados: 6.237038612365723\nIteración 2000, Suma cuadrados: 5.502582550048828\nIteración 2100, Suma cuadrados: 4.992691516876221\nIteración 2200, Suma cuadrados: 4.646664619445801\nIteración 2300, Suma cuadrados: 4.4174346923828125\nIteración 2400, Suma cuadrados: 4.26937198638916\nIteración 2500, Suma cuadrados: 4.176309108734131\nIteración 2600, Suma cuadrados: 4.119433879852295\nIteración 2700, Suma cuadrados: 4.085715293884277\nIteración 2800, Suma cuadrados: 4.066339492797852\nIteración 2900, Suma cuadrados: 4.055578231811523\nIteración 3000, Suma cuadrados: 4.049808025360107\nParámetros optimizados: [1.9952817  0.49972048 1.        ]",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#tarea-11.1",
    "href": "22_descenso_de_gradiente.html#tarea-11.1",
    "title": "Decenso de Gradiente",
    "section": "Tarea 11.1",
    "text": "Tarea 11.1\nConsidere la función \\(y_{\\theta}(x) = (\\theta x)^2\\).\nGeneramos datos ficticios con el siguiente código:\n\nnp.random.seed(0)\nx_data = np.linspace(0, 10, 30)\ny_true = (x_data/2)**2\ny_data = y_true + np.random.normal(0, 0.2, size=x_data.shape)\n\nRealice un descenso de gradiente para ajustar el valor de \\(\\theta\\) empezando desde el punto \\(\\theta = 1\\) y de nuevo desde el punto \\(\\theta = -1\\). Explique la diferencia entre los resultados.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#tarea-11.2",
    "href": "22_descenso_de_gradiente.html#tarea-11.2",
    "title": "Decenso de Gradiente",
    "section": "Tarea 11.2",
    "text": "Tarea 11.2\nConsidere la función \\(y_{\\theta}(x) = \\cos(\\theta x)\\).\nGeneramos datos ficticios con el siguiente código:\n\nnp.random.seed(0)\nx_data = np.linspace(0, 10, 100)\ny_true = np.cos(2*x_data)\ny_data = y_true + np.random.normal(0, 0.2, size=x_data.shape)\n\nIntente encontrar el valor de \\(\\theta\\) ajustando los datos con mínimos cuadrados y descenso de gradiente partiendo del punto \\(\\theta=-1\\).\nGrafique la función de pérdida y explique el origen de la dificultad.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#tarea-11.3",
    "href": "22_descenso_de_gradiente.html#tarea-11.3",
    "title": "Decenso de Gradiente",
    "section": "Tarea 11.3",
    "text": "Tarea 11.3\nPara un cierto sistema el volumen está dado por \\[\nV(\\theta_1, \\theta_2) = \\sinh(\\theta_1^4 + \\theta_2^2) - 1\\,,\n\\] donde \\(\\theta_1, \\theta_2 \\geq 0\\).\nEncuentre los valores de los parámetros para los cuales el volumen es mínimo.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#tarea-11.4",
    "href": "22_descenso_de_gradiente.html#tarea-11.4",
    "title": "Decenso de Gradiente",
    "section": "Tarea 11.4",
    "text": "Tarea 11.4\nConsidere la función \\(y_{\\theta}(x) = (\\theta x)^2 + 50\\theta x\\).\nGeneramos datos ficticios con el siguiente código:\n\nnp.random.seed(0)\nx_data = np.linspace(0, 10, 30)\ny_true = (x_data/2)**2 + 50*x_data/2\ny_data = y_true + np.random.normal(0, 0.2, size=x_data.shape)\n\nRealice un descenso de gradiente para ajustar el valor de \\(\\theta\\) empezando desde el punto \\(\\theta = 2\\) y de nuevo desde el punto \\(\\theta = -9\\). Explique la diferencia entre los resultados.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "22_descenso_de_gradiente.html#tarea-11.5",
    "href": "22_descenso_de_gradiente.html#tarea-11.5",
    "title": "Decenso de Gradiente",
    "section": "Tarea 11.5",
    "text": "Tarea 11.5\nConsidere la función \\(y_{\\theta}(x) = (\\theta_0 x)^2 + (\\theta_1x)^{-3}\\).\nGeneramos datos ficticios con el siguiente código:\n\nnp.random.seed(0)\nx_data = np.linspace(1, 10, 30)\ny_true = (x_data/2)**-3 + x_data**2\ny_data = y_true + np.random.normal(0, 0.2, size=x_data.shape)\n\nRealice un descenso de gradiente con varios métodos (gradiente sencillo y Adam) y explique la diferencia.",
    "crumbs": [
      "Inicio",
      "Unidad 5: Tópicos",
      "Descenso de gradiente"
    ]
  },
  {
    "objectID": "18_runge_kutta.html",
    "href": "18_runge_kutta.html",
    "title": "EDOs - Runge Kutta",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nLos métodos de Taylor de alto orden son muy precisos pero requieren conocer las derivadas de alto orden de la función \\(f\\). Como esto puede ser inconveniente, no se usan mucho en la práctica.\nLos métodos de Runge-Kutta logran el error de truncación local de alto orden sin necesitar esas derivadas.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Runge-Kutta"
    ]
  },
  {
    "objectID": "18_runge_kutta.html#tarea-9.1",
    "href": "18_runge_kutta.html#tarea-9.1",
    "title": "EDOs - Runge Kutta",
    "section": "Tarea 9.1",
    "text": "Tarea 9.1\nModifique los métodos rkf y rk4 introducidos para imprimir el número de evaluaciones. Resuelva el problema de valor inicial\n\\[\ny'(t) = te^{3t} - 2y\\,,\\quad 0\\leq t \\leq 1\\,,\\quad y(0) = 0\\,,\n\\]\ncuya solución exacta es \\(y(t) = \\frac{1}{5}te^{3t} - \\frac{1}{25}e^{3t} + \\frac{1}{25}e^{-2t}\\). Obtenga un error similar (y menor a \\(10^{-6}\\)) con ambos métodos y compare el número de evaluaciones. Discuta cuál es preferible y por qué.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Runge-Kutta"
    ]
  },
  {
    "objectID": "18_runge_kutta.html#tarea-9.2",
    "href": "18_runge_kutta.html#tarea-9.2",
    "title": "EDOs - Runge Kutta",
    "section": "Tarea 9.2",
    "text": "Tarea 9.2\nResuelva el siguiente problema de valor inicial usando el método de Runge-Kutta de orden 4 y el método de Taylor de orden 4.\n\\[\ny'(t) = 1 + (t - y)^2\\,,\\quad 2 \\leq t \\leq 3\\,,\\quad y(2) = 1\\,,\n\\]\nque tiene solución exacta \\(y(t) = t + 1/(1-t)\\). Compare los errores y el número de evaluaciones necesarias. ¿Cuál es preferible y por qué?",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Runge-Kutta"
    ]
  },
  {
    "objectID": "18_runge_kutta.html#tarea-9.3",
    "href": "18_runge_kutta.html#tarea-9.3",
    "title": "EDOs - Runge Kutta",
    "section": "Tarea 9.3",
    "text": "Tarea 9.3\nModifique el método de Runge-Kutta-Fehlberg para quedarse con la solución de orden 5 en vez de la solución de orden 4. La solución de orden 5 está dada por\n\\[\nw_{i+1} = w_i + \\frac{16}{135}k_1 + \\frac{6656}{12825}k_3 + \\frac{28561}{56430}k_4 - \\frac{9}{50}k_5 + \\frac{2}{55}k_6\n\\]\nÚselo para resolver el siguiente problema de valor inicial con una tolerancia de \\(10^{-6}\\)\n\\[\ny'(t) = \\frac{2 - 2ty}{t^2 + 1}\\,,\\quad 0\\leq t\\leq 3\\,,\\quad y(0) = 1\\,,\n\\]\nque tiene una solución exacta \\(y(t) = (2t + 1)/(t^2 + 1)\\). Compare con el método usual y discuta por qué se usa la solución de orden 4.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Runge-Kutta"
    ]
  },
  {
    "objectID": "18_runge_kutta.html#tarea-9.4",
    "href": "18_runge_kutta.html#tarea-9.4",
    "title": "EDOs - Runge Kutta",
    "section": "Tarea 9.4",
    "text": "Tarea 9.4\nEjercicio 5.4.28, libro de Burden\nEl agua fluye desde un tanque cónico invertido con un orificio circular en su punta a la razón\n\\[\n\\frac{dx}{dt} = -0.6\\pi r^2 \\sqrt{2g}\\frac{\\sqrt{x}}{A(x)}\n\\]\ndonde \\(r\\) es el radio del orificio, \\(x\\) es la altura del líquido desde el vértice del cono y \\(A(x)\\) es el área de la sección transversal del cono a \\(x\\) unidades sobre el orificio (el área de la superficie del agua). Supponga que \\(r = 0.03\\) m, \\(g = 9.81\\,\\text{m}/\\text{s}^2\\), y el tanque tiene un nivel de agua inicial de \\(2.7\\) m y un volumen inicial de \\(170(\\pi/3)\\,\\text{m}^3\\). Use el método de Runge-Kutta de orden 4 para encontrar lo siguiente\n\nEl agua luego de 10 minutos con h=20 s.\nCuándo estará vacío el tanque, a una precisión de 1 minuto.\n\n(Pista: Yo resolví el segundo numeral modificando el código del Runge Kutta tal que termina cuando encuentra un valor no válido de \\(w\\), ya que eso indica niveles de agua negativos y arroja un NaN cuando se toman raíces.)",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Runge-Kutta"
    ]
  },
  {
    "objectID": "18_runge_kutta.html#tarea-9.5",
    "href": "18_runge_kutta.html#tarea-9.5",
    "title": "EDOs - Runge Kutta",
    "section": "Tarea 9.5",
    "text": "Tarea 9.5\nConsidere el problema de valor inicial\n\\[\ny'(t) = 10y(t)- 10t^{-2} - 2t^{-3}\\,,\\quad 1 \\leq t \\leq 2\n\\]\nResuleva este problema para las siguientes condiciones iniciales usando el método de Runge-Kutta-Fehlberg para las tolerancias \\(0.01, 0.001, 0.0001, 10^{-5}\\).\n\n\\(y(1) = 2\\)\n\\(y(1) = 1\\)\n\\(y(1) = 0.1\\)\n\nPara cada caso discuta: ¿Son consistentes las soluciones con diferentes tolerancias? Explique lo que ocurre.",
    "crumbs": [
      "Inicio",
      "Unidad 4: Ecuaciones Diferenciales",
      "Métodos de Runge-Kutta"
    ]
  },
  {
    "objectID": "12_newton_y_biseccion.html",
    "href": "12_newton_y_biseccion.html",
    "title": "El método de bisección y el método de Newton",
    "section": "",
    "text": "En muchos casos de interés queremos resolver una ecuación de una variable y la solución no se puede obtener de forma analítica. Por ejemplo al calcular las bandas de energía en un sólido de una dimensión se resuelve la siguiente ecuación\n\\[\nf(z) = \\cos(z) - \\frac{\\sin(z)}{z}\n\\]\nLa energía permitida satisface \\(-1 \\leq f(z) \\leq 1\\). Entonces para encontrar las bandas de energía basta encontrar los lugares que satisfacen \\(f(z) = \\pm 1\\). Pero no es posible hacerlo de forma analítica.\nEste tipo de problemas se pueden reducir a encontrar dónde una función es cero. Veremos algunas técnicas para lograrlo.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Ecuaciones No Lineales"
    ]
  },
  {
    "objectID": "12_newton_y_biseccion.html#tarea-6.1",
    "href": "12_newton_y_biseccion.html#tarea-6.1",
    "title": "El método de bisección y el método de Newton",
    "section": "Tarea 6.1",
    "text": "Tarea 6.1\nUse el método de bisección para encontrar un cero de la función\n\\[\nf(x) = 1 - \\cos(x) -\\frac{\\sin(x)}{x}\n\\]\nentre \\(-6.5\\) y \\(-6.0\\). Grafique el error relativo requerido al calcular el cero en función del número de iteraciones que necesita el método para converger. Compare con la cota teórica.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Ecuaciones No Lineales"
    ]
  },
  {
    "objectID": "12_newton_y_biseccion.html#tarea-6.2",
    "href": "12_newton_y_biseccion.html#tarea-6.2",
    "title": "El método de bisección y el método de Newton",
    "section": "Tarea 6.2",
    "text": "Tarea 6.2\nEncuentre un cero de la función\n\\[\nf(x) = 1 - \\cos(x) -\\frac{\\sin(x)}{x}\n\\]\nentre \\(-6.4\\) y \\(-6.0\\) usando el método de Newton y el método de bisección. Grafique el número de iteraciones requerido así como el tiempo requerido en función de la precisión para ambos métodos.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Ecuaciones No Lineales"
    ]
  },
  {
    "objectID": "12_newton_y_biseccion.html#tarea-6.3",
    "href": "12_newton_y_biseccion.html#tarea-6.3",
    "title": "El método de bisección y el método de Newton",
    "section": "Tarea 6.3",
    "text": "Tarea 6.3\nBusque un ejemplo de una función tal que el método de bisección con la condición \\(|p_n - p_{n-1}|/|p_n| &lt; \\epsilon\\) converge siempre a un valor que no es un cero de la función.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Ecuaciones No Lineales"
    ]
  },
  {
    "objectID": "12_newton_y_biseccion.html#tarea-6.4",
    "href": "12_newton_y_biseccion.html#tarea-6.4",
    "title": "El método de bisección y el método de Newton",
    "section": "Tarea 6.4",
    "text": "Tarea 6.4\nIntente escribir su propia versión del método de Newton, haciéndola lo más rápida posible. Luego compare el tiempo que tarda en resolver el ejemplo de clase (el cero de la función \\(f(x) = x - \\cos(x)\\)) con el tiempo que tarda el método de Newton que se encuentra en scipy.",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Ecuaciones No Lineales"
    ]
  },
  {
    "objectID": "12_newton_y_biseccion.html#tarea-6.5",
    "href": "12_newton_y_biseccion.html#tarea-6.5",
    "title": "El método de bisección y el método de Newton",
    "section": "Tarea 6.5",
    "text": "Tarea 6.5\nEjercicio 2.3.25, libro de Burden:\nEl modelo logístico de crecimimiento de poblaciones está descrito por una ecuación de la forma:\n\\[\nP(t) = \\frac{P_L}{1 - ce^{-k t}}\\,.\n\\]\nUse los datos correspondientes a 1960, 1970 y 1980 de la siguiente tabla para encontrar \\(c\\), \\(k\\) y \\(P_L\\) usando el método de la secante. Luego prediga los valores para 1990 y 2020. Compare la predicción para 1990 con los datos reales de la tabla.\n\n\n\nPoblación\nAño\n\n\n\n\n179 323\n1960\n\n\n203 302\n1970\n\n\n226 542\n1980\n\n\n249 633\n1990\n\n\n281 422\n2000\n\n\n308 746\n2010",
    "crumbs": [
      "Inicio",
      "Unidad 3: Cálculo Numérico",
      "Solución de Ecuaciones No Lineales"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Acerca de este sitio",
    "section": "",
    "text": "Versión: 0.0.1 (trabajo en progreso)\nEstas son las notas de clases del curso de Métodos Numéricos y Probabilidades 2025. El curso es parte del plan de estudios de la licenciatura en física de la Pontificia Universidad Católica de Valparaíso, Chile. Dictado por el profesor Jorge Noreña, el curso cubre temas fundamentales de métodos numéricos y probabilidad aplicados a la física.\nUna pequeña parte de estos apuntes fue escrita con la ayuda de inteligencia artificial, revisado y corregido por el profesor."
  }
]